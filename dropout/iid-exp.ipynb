{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11620100,"sourceType":"datasetVersion","datasetId":7289711},{"sourceId":11680004,"sourceType":"datasetVersion","datasetId":7180861},{"sourceId":11721921,"sourceType":"datasetVersion","datasetId":7270261}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q lightning flwr wandb hydra-core","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T03:35:36.179610Z","iopub.execute_input":"2025-06-05T03:35:36.179845Z","iopub.status.idle":"2025-06-05T03:37:02.025117Z","shell.execute_reply.started":"2025-06-05T03:35:36.179827Z","shell.execute_reply":"2025-06-05T03:37:02.024127Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m51.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.8 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom pathlib import Path\nimport nibabel as nib\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T03:37:10.455958Z","iopub.execute_input":"2025-06-05T03:37:10.456243Z","iopub.status.idle":"2025-06-05T03:37:10.460745Z","shell.execute_reply.started":"2025-06-05T03:37:10.456220Z","shell.execute_reply":"2025-06-05T03:37:10.459939Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nsecret_label = \"wandb-key\"\nWANDB_APIKEY = UserSecretsClient().get_secret(secret_label)\n\nROOT_PATH = '/kaggle/input/mri-dataset/datasetzip/not_skull_stripped'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T03:37:10.880693Z","iopub.execute_input":"2025-06-05T03:37:10.881143Z","iopub.status.idle":"2025-06-05T03:37:11.147198Z","shell.execute_reply.started":"2025-06-05T03:37:10.881121Z","shell.execute_reply":"2025-06-05T03:37:11.146479Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"label = pd.read_json('/kaggle/input/mri-dataset/mri_dataset.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T03:57:10.674717Z","iopub.execute_input":"2025-06-05T03:57:10.674977Z","iopub.status.idle":"2025-06-05T03:57:10.705510Z","shell.execute_reply.started":"2025-06-05T03:57:10.674960Z","shell.execute_reply":"2025-06-05T03:57:10.704973Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import re \n\nclass MRIDataset(Dataset) :\n\n    def __init__(self, root_dir: str, label_path: str = None, transform = None, label_df: pd.DataFrame = None, is_3d: bool = False):\n        self.root_dir = Path(root_dir)\n        self.transform = transform\n        self.is_3d = is_3d\n        if label_df is None:\n          self.labels_df = pd.read_csv(label_path)\n          \n        else :\n          self.labels_df = label_df\n\n        self.labels_df['subject_id'] = self.labels_df['subject_id'].astype(str)\n        self.labels_df = self.labels_df[self.labels_df['subject_dx'] == 'control']\n\n        \n        fail_set = set([\n            \"sub-BrainAge005600_T1w.nii\" \n        ])\n        \n        valid_subjects = set(self.labels_df['subject_id'].astype(str).values)\n        subject_pattern = re.compile(r\"sub-([A-Za-z0-9]+)\")\n    \n        self.file_paths = sorted([\n            fp for fp in self.root_dir.rglob(\"*.nii\")\n            if fp.is_file()\n            and fp.name not in fail_set\n            and (match := subject_pattern.search(str(fp))) \n            and match.group(1) in valid_subjects\n        ])\n\n\n\n    def __len__(self):\n        return len(self.file_paths)\n\n\n    def preprocessing_datapoint(self, img_data):\n\n        mid_x = img_data.shape[0] // 2\n        mid_y = img_data.shape[1] // 2\n        mid_z = img_data.shape[2] // 2\n\n        axial_slice = img_data[:, :, mid_z]\n        coronal_slice = img_data[:, mid_y, :]\n        sagittal_slice = img_data[mid_x, :, :]\n\n\n        combined_data = np.stack([axial_slice, coronal_slice, sagittal_slice], axis=0)\n        combined_data = torch.from_numpy(combined_data).float()\n\n        if self.transform : combined_data = self.transform(combined_data)\n\n        return combined_data\n\n\n\n\n    def __getitem__(self, idx):\n        img_path = self.file_paths[idx]\n        file_path_str = str(img_path)\n\n        subject_id = None\n        valid_subjects_set = set(self.labels_df['subject_id'].values)\n\n\n        for sid in valid_subjects_set:\n            if sid in file_path_str:\n                subject_id = sid\n                break\n\n        if subject_id is None:\n            raise ValueError(f\"Không tìm thấy subject_id cho file: {img_path}\")\n\n        metadata = self.labels_df.loc[self.labels_df['subject_id'] == subject_id].iloc[0].to_dict()\n\n        img_data = nib.load(img_path).get_fdata()\n\n        img_data = torch.from_numpy(img_data).float()\n\n        label = 0\n        if metadata['subject_sex'] == 'm' : label = 1\n\n        if not self.is_3d:\n            img_data = self.preprocessing_datapoint(img_data)\n\n        return img_data,  label\n\n\n\ndef visualize_sample(dataset, idx):\n    mri_data, label = dataset[idx]\n    title = f\"Label: {label}\\n\"\n    plt.close('all')\n    fig = plt.figure(figsize = (18, 6))\n\n    if isinstance(mri_data, torch.Tensor):\n        data = mri_data.squeeze().numpy()\n    else:\n        data = mri_data\n\n\n    ax1 = fig.add_subplot(1, 3, 1)\n    plt.imshow(data[0, :, :].T, cmap='gray', origin='lower')\n\n    ax2 = fig.add_subplot(1, 3, 2)\n    ax2.imshow(data[1, :, :].T, cmap='gray', origin='lower')\n\n    ax3 = fig.add_subplot(1, 3, 3)\n    ax3.imshow(data[2, :, :].T, cmap='gray', origin='lower')\n\n    plt.suptitle(title)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T04:01:13.388036Z","iopub.execute_input":"2025-06-05T04:01:13.388542Z","iopub.status.idle":"2025-06-05T04:01:13.400106Z","shell.execute_reply.started":"2025-06-05T04:01:13.388521Z","shell.execute_reply":"2025-06-05T04:01:13.399563Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"dataset = MRIDataset(root_dir= '/kaggle/input/mri-dataset' , label_path = '/kaggle/input/mri-label/label.csv', is_3d = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T04:01:30.396516Z","iopub.execute_input":"2025-06-05T04:01:30.396777Z","iopub.status.idle":"2025-06-05T04:03:09.832263Z","shell.execute_reply.started":"2025-06-05T04:01:30.396758Z","shell.execute_reply":"2025-06-05T04:03:09.831724Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"dataset[0][0].shape ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:09.732297Z","iopub.execute_input":"2025-06-04T17:06:09.732473Z","iopub.status.idle":"2025-06-04T17:06:09.893234Z","shell.execute_reply.started":"2025-06-04T17:06:09.732458Z","shell.execute_reply":"2025-06-04T17:06:09.892463Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([130, 130, 130])"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Data splitting","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split \n\ndef preprocessing_labels(df: pd.DataFrame, root_dir: str = ROOT_PATH):\n    \n    subject_list = []\n    for root, dirs, files in os.walk(root_dir):\n      for dir_name in dirs:\n        if dir_name.startswith(\"sub-BrainAge\"):\n            subject_list.append(dir_name)\n\n\n    return df[df['subject_id'].isin(subject_list)]\n\n\ndef prepare_data(data: pd.DataFrame):\n\n  df = data.copy()\n  df['age_group'] = pd.qcut(df['subject_age'], q = min(5, len(df)), labels = False)\n  df['key'] = df.apply(lambda row : f\"{row['age_group']}_{row['subject_sex']}\", axis = 1)\n  return df\n\n\ndef sampling_data(data, size, random_state ):\n\n  samples = data.groupby('key', group_keys = False)\n\n\n  samples = samples.apply(lambda x: x.sample(\n      n = min(int(size / len(data['key'].unique())), len(x)),\n      replace = len(x) < int(size / len(data['key'].unique())),\n      random_state =  random_state\n  ))\n\n\n  if len(samples) < size:\n    additional_samples = data.drop(samples.index).sample(\n        n = min(size - len(samples), len(data) - len(samples)),\n        replace = True,\n        random_state = random_state\n    )\n\n    samples = pd.concat([samples, additional_samples])\n  return samples\n\n\ndef create_train_test(sample_labels: list, val_ratio: float = 0.2, root_dir: str = ROOT_PATH, is_3d: bool = False):\n\n  client_datasets = []\n  for label_df in sample_labels:\n    dataset = MRIDataset(root_dir=root_dir, label_df = label_df, is_3d = is_3d)\n    \n    train_dataset, val_dataset = random_split(dataset, [1 - val_ratio, val_ratio])\n    client_datasets.append((train_dataset, val_dataset))\n  return client_datasets\n\n\ndef distributed_data_to_clients(data: pd.DataFrame, num_clients: int, overlap_ratio: float):\n\n  df = prepare_data(data)\n\n  n_samples = len(df)\n  samples_per_client = int(n_samples / (num_clients * (1 - overlap_ratio) + overlap_ratio))\n\n  client_datasets = []\n  selected_samples = {}\n\n  # Tạo các client datasets với sự phân bố cân bằng\n  for client_idx in range(num_clients):\n\n      if client_idx == 0:\n          client_data = df.sample(n=samples_per_client, random_state=42+client_idx)\n      else:\n          # overlap size\n          overlap_size = int(samples_per_client * overlap_ratio)\n          non_overlap_size = samples_per_client - overlap_size\n\n          # building overlap\n          all_previous_samples = pd.DataFrame()\n          for prev_client_idx in range(client_idx):\n              all_previous_samples = pd.concat([all_previous_samples, selected_samples[prev_client_idx]])\n\n          # sampling\n          if len(all_previous_samples) > 0:\n              overlap_samples = sampling_data(all_previous_samples, overlap_size, client_idx * 100 + 42)\n          else:\n              overlap_samples = pd.DataFrame(columns=df.columns)\n\n          # Lấy mẫu mới (không overlap)\n          remaining_indices = df.index.difference(all_previous_samples.index)\n          if len(remaining_indices) > 0:\n              remaining_df = df.loc[remaining_indices]\n              non_overlap_samples = sampling_data(remaining_df, non_overlap_size, client_idx * 100 + 42)\n          else:\n\n              non_overlap_samples = df.sample(n=non_overlap_size, replace=True, random_state=42+client_idx*300)\n\n\n          client_data = pd.concat([overlap_samples, non_overlap_samples])\n\n\n      selected_samples[client_idx] = client_data\n      client_datasets.append(client_data.drop(['age_group', 'key'], axis=1))\n\n  return client_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:09.894245Z","iopub.execute_input":"2025-06-04T17:06:09.894755Z","iopub.status.idle":"2025-06-04T17:06:09.906476Z","shell.execute_reply.started":"2025-06-04T17:06:09.894727Z","shell.execute_reply":"2025-06-04T17:06:09.905908Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n\ndef iid_client_split(dataset, num_client = 3,  val_ratio = 0.2):\n\n    client_datasets = []\n    sample_per_client = len(dataset) // num_client\n\n\n    for i in range(num_client):\n        start_idx = i * sample_per_client\n        end_idx = (i + 1) * sample_per_client if i < num_client - 1 else len(dataset)\n        indecies = list(range(start_idx, end_idx))\n\n        client_dataset = torch.utils.data.Subset(dataset, indecies)\n        train_dataset, val_dataset = random_split(client_dataset, [1 - val_ratio, val_ratio])\n\n        client_datasets.append((train_dataset, val_dataset))\n    return client_datasets\n\n\n\n\n\ndef same_distribution_client_split(labels_path, num_client, val_ratio = 0.2, overlap_ratio = 0.2, root_dir = ROOT_PATH, is_3d = False):\n    \"\"\"\n    Split the dataset into clients with the same distribution of labels.\n    \"\"\"\n    labels_df = pd.read_csv(labels_path)\n    labels_df = preprocessing_labels(labels_df, root_dir = root_dir)    \n    labels_df = prepare_data(labels_df)\n\n    client_datasets = distributed_data_to_clients(labels_df, num_clients=num_client, overlap_ratio=overlap_ratio)\n\n    client_datasets = create_train_test(client_datasets, val_ratio=val_ratio, root_dir=root_dir, is_3d = is_3d)\n\n    return client_datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:09.907239Z","iopub.execute_input":"2025-06-04T17:06:09.907494Z","iopub.status.idle":"2025-06-04T17:06:09.927812Z","shell.execute_reply.started":"2025-06-04T17:06:09.907472Z","shell.execute_reply":"2025-06-04T17:06:09.927046Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"#  Model","metadata":{}},{"cell_type":"markdown","source":"## 3D DenseNet","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn \nimport torch \nimport torch.nn.functional as F\nfrom collections import OrderedDict\nfrom typing import List, Tuple\nfrom torchsummary import summary\n\n\nclass _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super().__init__()\n        self.add_module('norm1', nn.BatchNorm3d(num_input_features))\n        self.add_module('relu1', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv1',\n            nn.Conv3d(num_input_features,\n                      bn_size * growth_rate,\n                      kernel_size=1,\n                      stride=1,\n                      bias=False))\n        self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate))\n        self.add_module('relu2', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv2',\n            nn.Conv3d(bn_size * growth_rate,\n                      growth_rate,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1,\n                      bias=False))\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super().forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features,\n                                     p=self.drop_rate,\n                                     training=self.training)\n        return torch.cat([x, new_features], 1)\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super().__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features + i * growth_rate,\n                                growth_rate, bn_size, drop_rate)\n            self.add_module('denselayer{}'.format(i + 1), layer)\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super().__init__()\n        self.add_module('norm', nn.BatchNorm3d(num_input_features))\n        self.add_module('relu', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv',\n            nn.Conv3d(num_input_features,\n                      num_output_features,\n                      kernel_size=1,\n                      stride=1,\n                      bias=False))\n        self.add_module('pool', nn.AvgPool3d(kernel_size=2, stride=2))\n\nclass DenseNet(nn.Module):\n    def __init__(self,\n                 n_input_channels=1,\n                 conv1_t_size=7,\n                 conv1_t_stride=1,\n                 no_max_pool=False,\n                 growth_rate=16,\n                 block_config=(4, 8, 16, 12),\n                 num_init_features=32,\n                 bn_size=4,\n                 drop_rate=0,\n                 num_classes=1):\n        super().__init__()\n\n        # First convolution\n        self.features = [('conv1',\n                          nn.Conv3d(n_input_channels,\n                                    num_init_features,\n                                    kernel_size=(conv1_t_size, 7, 7),\n                                    stride=(conv1_t_stride, 2, 2),\n                                    padding=(conv1_t_size // 2, 3, 3),\n                                    bias=False)),\n                         ('norm1', nn.BatchNorm3d(num_init_features)),\n                         ('relu1', nn.ReLU(inplace=True))]\n        if not no_max_pool:\n            self.features.append(\n                ('pool1', nn.MaxPool3d(kernel_size=3, stride=2, padding=1)))\n        self.features = nn.Sequential(OrderedDict(self.features))\n\n        # Each denseblock\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            block = _DenseBlock(num_layers=num_layers,\n                                num_input_features=num_features,\n                                bn_size=bn_size,\n                                growth_rate=growth_rate,\n                                drop_rate=drop_rate)\n            self.features.add_module('denseblock{}'.format(i + 1), block)\n            num_features = num_features + num_layers * growth_rate\n            if i != len(block_config) - 1:\n                trans = _Transition(num_input_features=num_features,\n                                    num_output_features=num_features // 2)\n                self.features.add_module('transition{}'.format(i + 1), trans)\n                num_features = num_features // 2\n\n        self.features.add_module('norm5', nn.BatchNorm3d(num_features))\n        self.classifier = nn.Linear(num_features, num_classes)\n\n        # Khởi tạo trọng số\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm3d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        features = self.features(x)\n        out = F.relu(features, inplace=True)\n        out = F.adaptive_avg_pool3d(out, output_size=(1, 1, 1)).view(features.size(0), -1)\n        logits = self.classifier(out)\n        return logits\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:09.928561Z","iopub.execute_input":"2025-06-04T17:06:09.928804Z","iopub.status.idle":"2025-06-04T17:06:09.948926Z","shell.execute_reply.started":"2025-06-04T17:06:09.928788Z","shell.execute_reply":"2025-06-04T17:06:09.948173Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import lightning as pl\nimport torch.nn as nn \nfrom torchmetrics import Accuracy, F1Score, Precision, Recall, MeanMetric\nimport torch.optim as optim \nimport torch \n\n\n\nclass DenseNetModule(pl.LightningModule):\n    def __init__(self, net, learning_rate=1e-3, weight_decay = 1e-2, batch_size = 32):\n        super().__init__()\n        self.model = net\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.batch_size = batch_size\n        # how confidence model is in it prediction\n        # tức model có thể rất tự tin trong quyết định nhưng thực tế lại sai\n        # BCE = y*log(y_pred) + (1 - y)*log(1 - y_pred)\n        self.criterion = nn.BCEWithLogitsLoss()\n        \n        self.train_accuracy = Accuracy(task=\"binary\", num_classes=1)\n        self.val_accuracy = Accuracy(task=\"binary\", num_classes=1)\n        self.test_accuracy = Accuracy(task=\"binary\", num_classes=1)\n\n\n        self.val_precision = Precision(task=\"binary\", num_classes=1)\n        self.test_precision = Precision(task=\"binary\", num_classes=1)\n\n        self.val_recall = Recall(task=\"binary\", num_classes=1)\n        self.test_recall = Recall(task=\"binary\", num_classes=1)\n\n        self.val_f1 = F1Score(task=\"binary\", num_classes=1)\n        self.test_f1 = F1Score(task=\"binary\", num_classes=1)\n\n    \n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        # x.shape  = (batch_size, in_channel, height, width, depth), y.shape = (batch_size)\n        logits = self(x.unsqueeze(1))\n        \n        loss = self.criterion(logits, y.float().unsqueeze(1))\n        \n        acc = self.train_accuracy((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n\n        \n        self.log('train/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('train/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x.unsqueeze(1))\n        \n        loss = self.criterion(logits, y.float().unsqueeze(1))\n        acc = self.val_accuracy((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        f1 = self.val_f1((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        precision = self.val_precision((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        recall = self.val_recall((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        \n        self.log('val/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/precision', precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/recall', recall, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n\n\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x.unsqueeze(1))\n        \n        loss = self.criterion(logits, y.float().unsqueeze(1))\n        acc = self.test_accuracy((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        f1 = self.test_f1((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        precision = self.test_precision((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        recall = self.test_recall((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n\n        \n\n\n\n        self.log('test/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/precision', precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/recall', recall, on_step=False, on_epoch=True, prog_bar=True)\n        return loss\n\n\n\n\n    def configure_optimizers(self):\n        optimizer =  torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay = self.weight_decay)\n        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n\n        return {\n           \"optimizer\": optimizer,\n           \"lr_scheduler\": {\n               \"scheduler\": scheduler,\n               \"monitor\": \"val_loss\",\n           },\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:09.952028Z","iopub.execute_input":"2025-06-04T17:06:09.952317Z","iopub.status.idle":"2025-06-04T17:06:18.593190Z","shell.execute_reply.started":"2025-06-04T17:06:09.952301Z","shell.execute_reply":"2025-06-04T17:06:18.592595Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 2D model ","metadata":{}},{"cell_type":"code","source":"class BrainMRINet(nn.Module):\n    def __init__(self, num_classes=2, input_size=(130, 130)):\n        super(BrainMRINet, self).__init__()\n\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),  \n\n            # Block 2\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),  \n\n            # Block 3\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),  \n            \n            # Block 4 \n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2), \n            \n            # Block 5 \n            nn.AdaptiveAvgPool2d((1, 1))  # Output: 128 x 1 x 1\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),  # Output: 128\n            nn.Linear(128, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:18.593799Z","iopub.execute_input":"2025-06-04T17:06:18.594349Z","iopub.status.idle":"2025-06-04T17:06:18.601315Z","shell.execute_reply.started":"2025-06-04T17:06:18.594329Z","shell.execute_reply":"2025-06-04T17:06:18.600463Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class BrainMRILightningModule(pl.LightningModule): \n    \n    def __init__(self, net: nn.Module,  learning_rate=1e-3, weight_decay = 1e-2, batch_size = 32 ):\n        super().__init__()\n\n        self.save_hyperparameters(ignore=['net'])\n\n        self.model = net \n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.batch_size = batch_size\n\n\n        self.train_acc = Accuracy(task= \"multiclass\",  num_classes=net.classifier[-1].out_features)\n        self.val_acc = Accuracy(task= \"multiclass\", num_classes=net.classifier[-1].out_features)\n        \n        self.test_acc = Accuracy(task= \"multiclass\",  num_classes=net.classifier[-1].out_features)\n        \n        # F1 score \n        self.val_f1 = F1Score(task=\"multiclass\", num_classes=net.classifier[-1].out_features)\n        self.test_f1 = F1Score(task=\"multiclass\", num_classes=net.classifier[-1].out_features)\n        # Precision\n        self.val_precision = Precision(task=\"multiclass\", num_classes=net.classifier[-1].out_features)   \n        self.test_precision = Precision(task=\"multiclass\", num_classes=net.classifier[-1].out_features)\n        # Recall\n        self.val_recall = Recall(task=\"multiclass\", num_classes=net.classifier[-1].out_features)\n        self.test_recall = Recall(task=\"multiclass\", num_classes=net.classifier[-1].out_features)\n\n        self.criterion = nn.CrossEntropyLoss()\n\n\n    def forward(self, x):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        optimizer =  optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n        return {\n            \"optimizer\": optimizer,\n            \"gradient_clip_val\": 1.0,  # Adjust value as needed\n        }\n    \n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        \n        loss = nn.CrossEntropyLoss()(outputs, y)\n        preds = torch.argmax(outputs, dim=1)\n        \n        # Update metrics\n        acc = self.train_acc(preds, y)\n        \n\n        self.log(\"train/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"train/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n        \n        return loss\n    \n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        \n        loss = self.criterion(outputs, y)\n        preds = torch.argmax(outputs, dim=1)\n        \n        # Update metrics\n       \n        acc =  self.val_acc(preds, y)\n        f1 =  self.val_f1(preds, y)\n        precision =  self.val_precision(preds, y)\n        recall =  self.val_recall(preds, y)\n        \n        # Log metrics\n        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/precision\", precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/recall\", recall, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n    \n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        \n        loss = self.criterion(outputs, y)\n        preds = torch.argmax(outputs, dim=1)\n        \n        # Update metrics\n        acc = self.test_acc(preds, y)\n        f1 = self.test_f1(preds, y)\n        precision = self.test_precision(preds, y)\n        recall = self.test_recall(preds, y)\n        \n        # Log metrics\n        self.log(\"test/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/precision\", precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/recall\", recall, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:18.602234Z","iopub.execute_input":"2025-06-04T17:06:18.602552Z","iopub.status.idle":"2025-06-04T17:06:18.636897Z","shell.execute_reply.started":"2025-06-04T17:06:18.602529Z","shell.execute_reply":"2025-06-04T17:06:18.636038Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Client","metadata":{}},{"cell_type":"code","source":"import torch \nfrom collections import OrderedDict\nfrom flwr.client import NumPyClient\nfrom flwr.common import  Context\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn \nimport logging \nimport lightning as pl\nimport warnings \nfrom lightning.pytorch.loggers.wandb import WandbLogger\nfrom lightning.pytorch.callbacks import ModelCheckpoint\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:18.637740Z","iopub.execute_input":"2025-06-04T17:06:18.638023Z","iopub.status.idle":"2025-06-04T17:06:31.231824Z","shell.execute_reply.started":"2025-06-04T17:06:18.638000Z","shell.execute_reply":"2025-06-04T17:06:31.231259Z"}},"outputs":[{"name":"stderr","text":"2025-06-04 17:06:20.375417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749056780.571058      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749056780.623766      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"class FlowerLightningClient(NumPyClient):\n\n\n    def __init__(self, model: pl.LightningModule, train_dataloader, val_dataloader, epochs, batch_size, device, client_id): \n\n        self.model = model\n        self.train_dataloader = train_dataloader\n        self.val_dataloader = val_dataloader\n        self.epochs = epochs\n        self.device = device \n        self.client_id = client_id\n        self.batch_size = batch_size\n    \n    def get_parameters(self, config):\n\n        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        if not parameters:\n            return\n\n        params_dict = zip(self.model.state_dict().keys(), parameters)\n        state_dict = OrderedDict()\n        for k, v in params_dict:\n            state_dict[k] = torch.tensor(v)\n            \n\n        if state_dict:\n            self.model.load_state_dict(state_dict, strict=False)\n\n        \n    def fit(self, parameters, config):\n\n        self.set_parameters(parameters)\n        \n        checkpoint_callback = ModelCheckpoint(\n            dirpath=f\"./checkpoints/client_{self.client_id}\",\n            filename=f\"round_{config.get('round_num', 0)}\" + \"-{epoch:02d}\",\n            save_top_k=1,\n            monitor=\"val/loss\",\n            mode=\"min\"\n        )\n\n        trainer = pl.Trainer(\n            max_epochs=self.epochs,\n            accelerator=\"auto\",\n            devices=1,\n            callbacks=[checkpoint_callback],\n            enable_progress_bar=False, \n            log_every_n_steps=1\n        )\n\n        trainer.fit(self.model, train_dataloaders=self.train_dataloader, val_dataloaders=self.val_dataloader)\n\n        callback_metrics = trainer.callback_metrics\n\n        train_loss = callback_metrics.get(\"train/loss\", 0)\n        train_accuracy = callback_metrics.get(\"train/acc\", 0)\n        val_loss = callback_metrics.get(\"val/loss\", 0)\n        val_accuracy = callback_metrics.get(\"val/acc\", 0)\n        val_precision = callback_metrics.get(\"val/precision\", 0)\n        val_recall = callback_metrics.get(\"val/recall\", 0)\n        val_f1 = callback_metrics.get(\"val/f1\", 0)\n\n\n\n        metrics = {\n            \"train_loss\": train_loss.item() if isinstance(train_loss, torch.Tensor) else float(train_loss),\n            \"train_accuracy\": train_accuracy.item() if isinstance(train_accuracy, torch.Tensor) else float(train_accuracy),\n            \"val_loss\": val_loss.item() if isinstance(val_loss, torch.Tensor) else float(val_loss),\n            \"val_accuracy\": val_accuracy.item() if isinstance(val_accuracy, torch.Tensor) else float(val_accuracy),\n            \"val_precision\": val_precision.item() if isinstance(val_precision, torch.Tensor) else float(val_precision),\n            \"val_recall\": val_recall.item() if isinstance(val_recall, torch.Tensor) else float(val_recall),\n            \"val_f1\": val_f1.item() if isinstance(val_f1, torch.Tensor) else float(val_f1)\n        }\n\n\n\n        return self.get_parameters(config={}), len(self.train_dataloader.dataset), metrics\n\n\n    def evaluate(self, parameters, config):\n\n        self.set_parameters(parameters)\n\n       \n        trainer = pl.Trainer(\n            accelerator=\"auto\",\n            devices=1 ,\n            enable_progress_bar=False\n        )\n\n        results = trainer.test(self.model, dataloaders=self.val_dataloader)\n        \n        callback_metrics = trainer.callback_metrics\n\n        test_loss = callback_metrics.get(\"test/loss\", 0)\n        test_accuracy = callback_metrics.get(\"test/acc\", 0)\n        test_f1 = callback_metrics.get(\"test/f1\", 0)\n        test_precision = callback_metrics.get(\"test/precision\", 0)\n        test_recall = callback_metrics.get(\"test/recall\", 0)\n        \n        # Additional metrics\n        metrics = {\n            \"test_loss\": test_loss.item() if isinstance(test_loss, torch.Tensor) else float(test_loss),\n            \"test_accuracy\": test_accuracy.item() if isinstance(test_accuracy, torch.Tensor) else float(test_accuracy),\n            \"test_f1\": test_f1.item() if isinstance(test_f1, torch.Tensor) else float(test_f1),\n            \"test_precision\": test_precision.item() if isinstance(test_precision, torch.Tensor) else float(test_precision),\n            \"test_recall\": test_recall.item() if isinstance(test_recall, torch.Tensor) else float(test_recall)\n        }\n\n       \n        return float(test_loss), len(self.val_dataloader.dataset), metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:31.232554Z","iopub.execute_input":"2025-06-04T17:06:31.232808Z","iopub.status.idle":"2025-06-04T17:06:31.246266Z","shell.execute_reply.started":"2025-06-04T17:06:31.232787Z","shell.execute_reply":"2025-06-04T17:06:31.245574Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def create_lightning_client_fn(device, epochs, client_datasets, batch_size, num_workers, pl_model):\n\n    def client_fn(context: Context):\n        \n        \n        client_id = context.node_config['partition-id']\n        train_dataset, val_dataset = client_datasets[client_id]\n\n        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = num_workers)\n        val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n        return FlowerLightningClient(pl_model, train_dataloader, val_dataloader, epochs, batch_size, device, client_id).to_client()\n\n    return client_fn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:31.246995Z","iopub.execute_input":"2025-06-04T17:06:31.247283Z","iopub.status.idle":"2025-06-04T17:06:31.279710Z","shell.execute_reply.started":"2025-06-04T17:06:31.247260Z","shell.execute_reply":"2025-06-04T17:06:31.279154Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import random\nimport numpy as np\nfrom typing import Dict, List, Optional, Tuple, Union\nimport flwr as fl\nfrom flwr.common import (\n    EvaluateRes,\n    FitIns,\n    FitRes,\n    Parameters,\n    EvaluateIns,\n)\nfrom flwr.server.client_proxy import ClientProxy\nfrom flwr.server.client_manager import ClientManager\nfrom flwr.server.strategy import FedAvg\nfrom flwr.common.parameter import parameters_to_ndarrays\nimport numpy as np \nimport torch\nfrom collections import OrderedDict\nimport wandb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:31.280272Z","iopub.execute_input":"2025-06-04T17:06:31.280485Z","iopub.status.idle":"2025-06-04T17:06:33.446760Z","shell.execute_reply.started":"2025-06-04T17:06:31.280470Z","shell.execute_reply":"2025-06-04T17:06:33.446114Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class DropoutFedAvg(FedAvg):\n    \"\"\"FedAvg strategy with client dropout simulation and metrics tracking.\"\"\"\n\n    def __init__( self, net, dropout_rate_training: float = 0.3, dropout_rate_eval: float = 0.3, fixed_clients: Optional[List[int]] = None, dropout_pattern_train: str = \"random\", dropout_pattern_eval: str = \"random\", **kwargs):\n    \n        if \"fit_metrics_aggregation_fn\" not in kwargs:\n            kwargs[\"fit_metrics_aggregation_fn\"] = self.weighted_average\n        if \"evaluate_metrics_aggregation_fn\" not in kwargs:\n            kwargs[\"evaluate_metrics_aggregation_fn\"] = self.weighted_average\n\n        super().__init__(**kwargs)\n        self.dropout_rate_training = dropout_rate_training\n        self.dropout_rate_eval = dropout_rate_eval\n        self.fixed_clients = fixed_clients or []\n        self.dropout_pattern_train = dropout_pattern_train\n        self.dropout_pattern_eval = dropout_pattern_eval\n        self.current_round = 0\n        self.dropped_clients_history_training: Dict[int, List[int]] = {}\n        self.dropped_clients_history_evaluation: Dict[int, List[int]] = {}\n\n        # For tracking metrics\n        self.fit_metrics_history: List[Dict[str, float]] = []\n        self.eval_metrics_history: List[Dict[str, float]] = []\n\n        self.net = net\n    \n\n\n    def weighted_average(self, metrics: List[Tuple[int, Dict]]) -> Dict:\n        \"\"\"Aggregate metrics using weighted average based on number of samples.\"\"\"\n        if not metrics:\n            return {}\n\n        total_examples = sum([num_examples for num_examples, _ in metrics])\n        weighted_metrics = {}\n\n        for metric_key in metrics[0][1].keys():\n            weighted_sum = sum(\n                metric_dict[metric_key] * num_examples\n                for num_examples, metric_dict in metrics\n                if metric_key in metric_dict\n            )\n            weighted_metrics[metric_key] = weighted_sum / total_examples if total_examples > 0 else 0\n\n        return weighted_metrics\n\n\n    def configure_fit( self, server_round: int, parameters: Parameters, client_manager: ClientManager) -> List[Tuple[ClientProxy, FitIns]]:\n        \"\"\"Configure the next round of training with client dropout.\"\"\"\n        self.current_round = server_round\n\n    \n        client_fit_instructions = super().configure_fit(\n            server_round, parameters, client_manager\n        )\n\n        if not client_fit_instructions:\n            return []\n\n\n        available_clients = self._apply_dropout(client_fit_instructions, dropout_rate=self.dropout_rate_training, dropout_pattern=self.dropout_pattern_train)\n\n        # Save dropout history for this round\n        client_ids = [int(client.cid) for client, _ in client_fit_instructions]\n        available_client_ids = [int(client.cid) for client, _ in available_clients]\n        dropped_clients = [cid for cid in client_ids if cid not in available_client_ids]\n        self.dropped_clients_history_training[server_round] = dropped_clients\n\n        wandb.log({\n            \"train_dropout_history\"  : len(dropped_clients)\n        })\n\n        print(f\"Round {server_round}: {len(dropped_clients)} clients dropped out of {len(client_ids)} during training\")\n        print(f\"Dropped client IDs: {dropped_clients}\")\n\n        return available_clients\n    \n\n\n\n    def configure_evaluate( self, server_round: int, parameters: Parameters, client_manager: ClientManager) -> List[Tuple[ClientProxy, EvaluateIns]]:\n        self.current_round = server_round\n\n        client_evaluate_instructions = super().configure_evaluate(\n            server_round, parameters, client_manager\n        )\n\n        if not client_evaluate_instructions: return []\n\n        available_clients = self._apply_dropout(client_evaluate_instructions, dropout_rate=self.dropout_rate_eval, dropout_pattern=self.dropout_pattern_eval)\n\n        client_ids = [int(client.cid) for client, _ in client_evaluate_instructions]\n        available_client_ids = [int(client.cid) for client, _ in available_clients]\n        dropped_clients = [cid for cid in client_ids if cid not in available_client_ids]\n\n        self.dropped_clients_history_evaluation[server_round] = dropped_clients\n        wandb.log({\n            \"eval_dropout_history\" : len(dropped_clients) \n        })\n\n        print(f\"Round {server_round}: {len(dropped_clients)} clients dropped out of {len(client_ids)} during evaluation\")\n        print(f\"Dropped client IDs: {dropped_clients}\")\n\n        return available_clients\n\n\n\n\n    def _apply_dropout(self, client_instructions: List[Tuple[ClientProxy, Union[FitIns, EvaluateIns ]]], dropout_pattern: str, dropout_rate: 0.3) -> List[Tuple[ClientProxy, FitIns]]:\n        \"\"\"Apply dropout to clients based on the specified pattern.\"\"\"\n        if len(client_instructions) == 0:\n            return []\n\n        # Get all client IDs\n        all_clients = [(client, ins) for client, ins in client_instructions]\n        all_client_ids = [int(client.cid) for client, _ in all_clients]\n\n        # Determine which clients will drop out\n        dropout_mask = [False] * len(all_clients)\n\n        if dropout_pattern == \"random\":\n           \n            for i, cid in enumerate(all_client_ids):\n                \n                if cid in self.fixed_clients:\n                    continue\n            \n                if random.random() < dropout_rate:\n                    dropout_mask[i] = True\n\n        elif dropout_pattern == \"alternate\":\n         \n            if self.current_round % 2 == 1:  \n                for i, cid in enumerate(all_client_ids):\n                    if cid not in self.fixed_clients:\n                        dropout_mask[i] = True\n\n        elif dropout_pattern == \"fixed\":\n      \n            n_dropout = int(len(all_clients) * dropout_rate)\n            for i in range(n_dropout):\n                if all_client_ids[i] not in self.fixed_clients:\n                    dropout_mask[i] = True\n\n        \n        available_clients = [\n            (client, ins) for i, (client, ins) in enumerate(all_clients)\n            if not dropout_mask[i]\n        ]\n\n        return available_clients\n\n    def aggregate_fit(self, server_round: int, results: List[Tuple[ClientProxy, FitRes]], failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]]):\n    \n        aggregated = super().aggregate_fit(server_round, results, failures)\n\n        if aggregated and aggregated[0] is not None:\n            aggregated_ndarrays: list[np.ndarray] = fl.common.parameters_to_ndarrays(\n                aggregated[0]\n            )\n\n            params_dict = zip(self.net.state_dict().keys(), aggregated_ndarrays)\n            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n            self.net.load_state_dict(state_dict, strict=True)\n\n            torch.save(self.net.state_dict(), f\"model_round_{server_round}.pth\")\n\n        if results:\n            metrics = [(res.num_examples, res.metrics) for _, res in results]\n            aggregated_metrics = self.weighted_average(metrics)\n            self.fit_metrics_history.append(aggregated_metrics)\n\n            wandb.log({\n                \"train_server_round\": server_round, \n                \"train_accuracy\": aggregated_metrics.get(\"train_accuracy\", 0.0), \n                \"train_loss\" : aggregated_metrics.get(\"train_loss\", 0.0)\n            })\n\n\n            print(f\"Round {server_round} training metrics: {aggregated_metrics}\")\n\n        return aggregated\n\n    def aggregate_evaluate( self, server_round: int, results: List[Tuple[ClientProxy, EvaluateRes]],  failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]):\n        \n        aggregated = super().aggregate_evaluate(server_round, results, failures)\n\n        if results:\n            metrics = [(res.num_examples, res.metrics) for _, res in results]\n            aggregated_metrics = self.weighted_average(metrics)\n            self.eval_metrics_history.append(aggregated_metrics)\n\n            print(f\"Round {server_round} evaluation metrics: {aggregated_metrics}\")\n\n            wandb.log({\n                \"server_round_eval\" : server_round,\n                \"test_accuracy\": aggregated_metrics.get(\"test_accuracy\", 0.0), \n                \"test_loss\" : aggregated_metrics.get(\"test_loss\", 0.0), \n                 \"test_f1\": aggregated_metrics.get(\"test_f1\", 0.0), \n                \"test_precision\" : aggregated_metrics.get(\"test_precision\", 0.0), \n                 \"test_recall\": aggregated_metrics.get(\"test_recall\", 0.0), \n            })\n\n        return aggregated\n\n    def get_dropout_history(self) -> Dict[int, List[int]]:\n        return self.dropped_clients_history_training, self.dropped_clients_history_evaluation\n\n    def get_metrics_history(self) -> Tuple[List[Dict[str, float]], List[Dict[str, float]]]: \n        return self.fit_metrics_history, self.eval_metrics_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:33.447556Z","iopub.execute_input":"2025-06-04T17:06:33.447883Z","iopub.status.idle":"2025-06-04T17:06:33.469045Z","shell.execute_reply.started":"2025-06-04T17:06:33.447864Z","shell.execute_reply":"2025-06-04T17:06:33.468120Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from flwr.client import ClientApp\nfrom flwr.server import ServerApp\nfrom flwr.simulation import run_simulation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom typing import Dict, List, Optional\nimport os\nfrom flwr.common import Context\nimport torch \nimport lightning as pl\nfrom typing import Union","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:33.469860Z","iopub.execute_input":"2025-06-04T17:06:33.470158Z","iopub.status.idle":"2025-06-04T17:06:33.537839Z","shell.execute_reply.started":"2025-06-04T17:06:33.470113Z","shell.execute_reply":"2025-06-04T17:06:33.537033Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def run_dropout_experiment(\n    client_fn_creator,\n    pl_model : Union[pl.LightningModule, torch.nn.Module], \n    num_clients: int,\n    num_rounds: int = 5,\n    dropout_rate_training: float = 0.3,\n    dropout_rate_eval: float = 0.3,\n    dropout_pattern_train: str = \"random\",\n    dropout_pattern_eval: str = \"random\",\n    fixed_clients: Optional[List[int]] = None,\n    experiment_name: str = \"dropout_experiment\",\n    save_dir: str = \"model_weights\",\n    num_gpus : int = 0, \n    resource_config : Optional[Dict[str, float]] = None,\n\n):\n    \n      # Configure client app\n    print(f\"\\nStarting experiment: {experiment_name}\")\n    print(f\"Dropout rate training: {dropout_rate_training}, Pattern: {dropout_pattern_train}\")\n    print(f\"Dropout rate evaluation: {dropout_rate_eval}, Pattern: {dropout_pattern_eval   }\")\n    print(f\"Number of GPUs: {num_gpus}\")\n    print(f\"Number of clients: {num_clients}\")\n    print(f\"Number of rounds: {num_rounds}\")\n    print(f\"Fixed clients: {fixed_clients or []}\")\n\n    # Create strategy with dropout\n    strategy = DropoutFedAvg(\n        net=pl_model.model if isinstance(pl_model, pl.LightningModule) else pl_model,\n        dropout_rate_training=dropout_rate_training,\n        dropout_rate_eval=dropout_rate_eval,\n        dropout_pattern_train=dropout_pattern_train,\n        dropout_pattern_eval=dropout_pattern_eval,\n        fixed_clients=fixed_clients or [],\n        fraction_fit=1.0,\n        fraction_evaluate=1.0,\n        min_fit_clients=1,\n        min_evaluate_clients=1,\n        min_available_clients=1,\n\n    )\n\n    # Configure server with strategy\n    def server_fn(server_context: Context):\n        from flwr.server import ServerAppComponents, ServerConfig\n        config = ServerConfig(num_rounds=num_rounds)\n        return ServerAppComponents(strategy=strategy, config=config)\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    epochs = resource_config.get(\"epochs\", 1) if resource_config else 1\n    client_datasets = resource_config.get(\"client_datasets\", {}) if resource_config else {}\n\n    \n    batch_size = resource_config.get(\"batch_size\", 32) if resource_config else 32\n    learning_rate = resource_config.get(\"learning_rate\", 0.001) if resource_config else 0.001\n    num_workers = resource_config.get(\"num_workers\", 1) if resource_config else 1\n    client_fn = client_fn_creator(device=device, epochs=epochs, client_datasets=client_datasets\n                                , batch_size=batch_size, pl_model=pl_model, num_workers=num_workers)\n    \n    # Create client and server apps\n    client_app = ClientApp(client_fn=client_fn)\n    server_app = ServerApp(server_fn=server_fn)\n\n    # Configure backend\n    backend_config = {\n        \"client_resources\": {\n            \"num_cpus\": 1,\n            \"num_gpus\": num_gpus,\n        }\n    }\n    history = strategy.get_dropout_history()\n    # Run simulation\n    try:\n        run_simulation(\n            client_app=client_app,\n            server_app=server_app,\n            num_supernodes=num_clients,\n            backend_config=backend_config,\n        )\n\n        # Get metrics directly from strategy\n        fit_metrics, eval_metrics = strategy.get_metrics_history()\n\n        # Format metrics for plotting\n        rounds = list(range(1, len(eval_metrics) + 1))\n\n        train_accuracy_values = [metrics.get(\"train_accuracy\", 0.0) for metrics in fit_metrics]\n        train_loss_values = [metrics.get(\"train_loss\", 0.0) for metrics in fit_metrics]\n        \n\n        test_accuracy_values = [metrics.get(\"test_accuracy\", 0.0) for metrics in eval_metrics]\n        test_loss_values = [metrics.get(\"test_loss\", 0.0) for metrics in eval_metrics]\n        test_f1_values = [metrics.get(\"test_f1\", 0.0) for metrics in eval_metrics]\n        test_precision_values = [metrics.get(\"test_precision\", 0.0) for metrics in eval_metrics]\n        test_recall_values = [metrics.get(\"test_recall\", 0.0) for metrics in eval_metrics]    \n\n\n        # cleanup_wandb_loggers()\n\n        results = {\n            \"rounds\": rounds,\n            \"train_accuracy\": train_accuracy_values,\n            \"train_loss\": train_loss_values,\n\n            \"test_accuracy\": test_accuracy_values,\n            \"test_loss\": test_loss_values,\n            \"test_f1\": test_f1_values,\n            \"test_precision\": test_precision_values,\n            \"test_recall\": test_recall_values\n        }\n\n        return results, history\n    \n    except Exception as e:\n        print(f\"Error in dropout experiment: {e}\")\n        import traceback\n        traceback.print_exc()\n        return {\"error\": str(e)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:33.538768Z","iopub.execute_input":"2025-06-04T17:06:33.539005Z","iopub.status.idle":"2025-06-04T17:06:33.558944Z","shell.execute_reply.started":"2025-06-04T17:06:33.538988Z","shell.execute_reply":"2025-06-04T17:06:33.558148Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"from typing import List, Dict, Tuple, Optional, Union\nimport torch.nn as nn \nimport hydra \nfrom omegaconf import DictConfig, OmegaConf\nimport logging \nimport wandb \nimport os \nimport warnings\nimport lightning as pl ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:33.559796Z","iopub.execute_input":"2025-06-04T17:06:33.560073Z","iopub.status.idle":"2025-06-04T17:06:33.789840Z","shell.execute_reply.started":"2025-06-04T17:06:33.560056Z","shell.execute_reply":"2025-06-04T17:06:33.789091Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## Config ","metadata":{}},{"cell_type":"code","source":"config = {\n    \"base_path\": \"/kaggle\",\n    \"device\": \"cuda\",  # from train.device\n    \"run_name\": \"dropout_30pct_fixed_train_fixed_eval_0.3_fixed_0.3\",  # resolved using experiment values\n    \"seed\": 42,\n    \"num_clients\": 10,\n    \"num_rounds\": 10,\n    \"gpus\": 1,\n    \n    \"train\": {\n        \"batch_size\": 4,\n        \"learning_rate\": 0.001,\n        \"epochs\": 1,\n        \"device\": \"cuda\",\n        \"num_workers\": 2,\n        \"weight_decay\": 0.0001,\n        \"scheduler\": {\n            \"use\": False,\n            \"type\": \"cosine\",\n            \"warmup_epochs\": 5,\n            \"min_lr\": 0.0001,\n        }\n    },\n\n    \"experiment\": {\n        \"pattern_train\": \"random\",\n        \"pattern_eval\": \"random\",\n        \"dropout_rate_training\": 0.3,\n        \"dropout_rate_eval\": 0.3,\n        \"fixed_clients\": [0, 1, 2],\n        \"name\": \"dropout_30pct_random_train_random_eval\",\n    },\n\n    \"data\": {\n        \"root_path\": \"/kaggle/input/mri-dataset/datasetzip/not_skull_stripped\",\n        \"label_path\": \"/kaggle/input/mri-label/label.csv\",\n        \"val_ratio\": 0.2,\n        \"overlap_ratio\": 0.2,\n        \"distribution\": \"same\",\n    },\n    \"is_3d\": False\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:33.790666Z","iopub.execute_input":"2025-06-04T17:06:33.790942Z","iopub.status.idle":"2025-06-04T17:06:33.796106Z","shell.execute_reply.started":"2025-06-04T17:06:33.790920Z","shell.execute_reply":"2025-06-04T17:06:33.795425Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def run_experiment_with_lightning(cfg_dict: dict) -> None:\n    cfg: DictConfig = OmegaConf.create(cfg_dict)  # convert to DictConfig to retain dot-access\n    logger =  logger = logging.getLogger(__name__)\n    logger.info(f\"Running experiment with config: {cfg.experiment.name}\")\n    logger.info(f\"Config: {OmegaConf.to_yaml(cfg)}\")\n\n    wandb.login(\n        key=WANDB_APIKEY \n    )\n\n    wandb.init(\n        project=\"federated-mri-server\",\n        name=f\"{cfg.experiment.name}\",\n        config=OmegaConf.to_container(cfg, resolve=True),\n        group=\"server\"\n    )\n\n    device = cfg.device\n    epochs = cfg.train.epochs\n\n    logger.info(\"Loading model\")\n\n    net : nn.Module() = BrainMRINet()\n    pl_model : pl.LightningModule = BrainMRILightningModule(net = net )\n\n\n    \n    # net: nn.Module = DenseNet()\n    # pl_model: pl.LightningModule = DenseNetModule(net = net)\n\n    logger.info(\"Loading dataset\")\n    is_3d = True if isinstance(pl_model, DenseNetModule) else False\n    print(f\"Is 3D: {is_3d}\")\n\n   \n    logger.info(f\"Splitting dataset into {cfg.num_clients} clients\")\n\n    if cfg.data.distribution == \"iid\":\n        client_datasets = iid_client_split(\n            full_dataset,\n            num_client=cfg.num_clients,\n            val_ratio=cfg.data.val_ratio\n        )\n    elif cfg.data.distribution == \"same\":\n        client_datasets = same_distribution_client_split(\n            cfg.data.label_path,\n            num_client=cfg.num_clients,\n            val_ratio=cfg.data.val_ratio,\n            overlap_ratio=cfg.data.overlap_ratio,\n            root_dir=cfg.data.root_path,\n            is_3d=is_3d\n        )\n    else:\n        raise ValueError(f\"Unknown distribution type: {cfg.data.distribution}\")\n\n    logger.info(f\"Client datasets created successfully with {len(client_datasets)} clients\")\n\n    resources = {\n        \"client_datasets\": client_datasets,\n        \"device\": device,\n        \"epochs\": epochs,\n        \"batch_size\": cfg.train.batch_size,\n        \"learning_rate\": cfg.train.learning_rate,\n        \"num_workers\": cfg.train.num_workers\n    }\n\n    logger.info(\"Running experiments with PyTorch Lightning\")\n\n    results, history = run_dropout_experiment(\n        client_fn_creator=create_lightning_client_fn,\n        pl_model=pl_model,\n        num_clients=cfg.num_clients,\n        num_rounds=cfg.num_rounds,\n        dropout_rate_training=cfg.experiment.dropout_rate_training,\n        dropout_rate_eval=cfg.experiment.dropout_rate_eval,\n        dropout_pattern_train=cfg.experiment.pattern_train,\n        dropout_pattern_eval=cfg.experiment.pattern_eval,\n        experiment_name=cfg.experiment.name,\n        num_gpus=cfg.gpus,\n        resource_config=resources\n    )\n\n    logger.info(\"Run successfully + wandb tracking\")\n    print(f\"Result is {results}\")\n    wandb.finish()\n\n    logger.info(\"Experiments completed successfully\")\n    logger.info(f\"Client Dropout History: {history}\")\n\n    return results, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:33.796779Z","iopub.execute_input":"2025-06-04T17:06:33.797069Z","iopub.status.idle":"2025-06-04T17:06:33.820808Z","shell.execute_reply.started":"2025-06-04T17:06:33.797054Z","shell.execute_reply":"2025-06-04T17:06:33.820182Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"run_experiment_with_lightning(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:06:33.821526Z","iopub.execute_input":"2025-06-04T17:06:33.821767Z","iopub.status.idle":"2025-06-04T17:42:22.634683Z","shell.execute_reply.started":"2025-06-04T17:06:33.821748Z","shell.execute_reply":"2025-06-04T17:42:22.633989Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n  return LooseVersion(v) >= LooseVersion(check)\n/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_bokeh.py:16: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n  import imp  # pylint: disable=deprecated-module\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtheseventeengv\u001b[0m (\u001b[33mtrungviet17\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py:259: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n  self.scope.user = {\"email\": email}  # noqa\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250604_170640-nkcqdirh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/trungviet17/federated-mri-server/runs/nkcqdirh' target=\"_blank\">dropout_30pct_random_train_random_eval</a></strong> to <a href='https://wandb.ai/trungviet17/federated-mri-server' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/trungviet17/federated-mri-server' target=\"_blank\">https://wandb.ai/trungviet17/federated-mri-server</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/trungviet17/federated-mri-server/runs/nkcqdirh' target=\"_blank\">https://wandb.ai/trungviet17/federated-mri-server/runs/nkcqdirh</a>"},"metadata":{}},{"name":"stdout","text":"Is 3D: False\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n/tmp/ipykernel_35/607595986.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  samples = samples.apply(lambda x: x.sample(\n\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [INIT]\n\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n","output_type":"stream"},{"name":"stdout","text":"\nStarting experiment: dropout_30pct_random_train_random_eval\nDropout rate training: 0.3, Pattern: random\nDropout rate evaluation: 0.3, Pattern: random\nNumber of GPUs: 1\nNumber of clients: 10\nNumber of rounds: 10\nFixed clients: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(pid=452)\u001b[0m 2025-06-04 17:17:51.089640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[36m(pid=452)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n\u001b[36m(pid=452)\u001b[0m E0000 00:00:1749057471.113045     452 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[36m(pid=452)\u001b[0m E0000 00:00:1749057471.120057     452 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 1]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 8 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 1: 2 clients dropped out of 10 during training\nDropped client IDs: [6276042256941164512, 15780236247657851889]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 8 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 1 training metrics: {'train_loss': 0.6915231507606944, 'train_accuracy': 0.5596696986565263, 'val_loss': 0.6897938969482053, 'val_accuracy': 0.5360329833812515, 'val_precision': 0.5360329833812515, 'val_recall': 0.5360329833812515, 'val_f1': 0.5360329833812515}\nRound 1: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [15780236247657851889, 17733881892529882227, 5890663559472525427]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6897362470626831     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6922950148582458     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6913691163063049     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │     0.690703809261322     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6937689185142517     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6906830072402954     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 2]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.23762376606464386    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.23762376606464386    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6952135562896729     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.23762376606464386    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.23762376606464386    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 1 evaluation metrics: {'test_loss': 0.6918848821157899, 'test_accuracy': 0.4452644560719768, 'test_f1': 0.4452644560719768, 'test_precision': 0.4452644560719768, 'test_recall': 0.4452644560719768}\nRound 2: 3 clients dropped out of 10 during training\nDropped client IDs: [6276042256941164512, 15780236247657851889, 4225278872497288944]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 2 training metrics: {'train_loss': 0.6636595545613923, 'train_accuracy': 0.5915622177819381, 'val_loss': 0.7318485005847251, 'val_accuracy': 0.5647094901896004, 'val_precision': 0.5647094901896004, 'val_recall': 0.5647094901896004, 'val_f1': 0.5647094901896004}\nRound 2: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [17733881892529882227, 4225278872497288944, 6276042256941164512]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6915162801742554     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6904582381248474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6935957074165344     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.46666666865348816    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.46666666865348816    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6939370632171631     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.46666666865348816    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.46666666865348816    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6173912882804871     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6173912882804871     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6845664381980896     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6173912882804871     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6173912882804871     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6153846383094788     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6153846383094788     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6968731880187988     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6153846383094788     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6153846383094788     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 3]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.7821782231330872     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.7821782231330872     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6725378036499023     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.7821782231330872     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.7821782231330872     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 2 evaluation metrics: {'test_loss': 0.6894544849096629, 'test_accuracy': 0.5645756509617832, 'test_f1': 0.5645756509617832, 'test_precision': 0.5645756509617832, 'test_recall': 0.5645756509617832}\nRound 3: 1 clients dropped out of 10 during training\nDropped client IDs: [4225278872497288944]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 3 training metrics: {'train_loss': 0.669087836830204, 'train_accuracy': 0.5819169085919575, 'val_loss': 0.7163443028420294, 'val_accuracy': 0.5841246676737684, 'val_precision': 0.5841246676737684, 'val_recall': 0.5841246676737684, 'val_f1': 0.5841246676737684}\nRound 3: 2 clients dropped out of 10 during evaluation\nDropped client IDs: [13303908111421134425, 4225278872497288944]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6950504779815674     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6917746067047119     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6970680356025696     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6873165965080261     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6931046843528748     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │     0.417391300201416     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │     0.417391300201416     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6942514181137085     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │     0.417391300201416     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │     0.417391300201416     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6918261647224426     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 4]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.24752475321292877    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.24752475321292877    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7025436758995056     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.24752475321292877    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.24752475321292877    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 3 evaluation metrics: {'test_loss': 0.6939519975985233, 'test_accuracy': 0.4501607720076335, 'test_f1': 0.4501607720076335, 'test_precision': 0.4501607720076335, 'test_recall': 0.4501607720076335}\nRound 4: 3 clients dropped out of 10 during training\nDropped client IDs: [7041842867620325298, 5890663559472525427, 10026370797255282897]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 4 training metrics: {'train_loss': 0.6536725372184276, 'train_accuracy': 0.6186440663714385, 'val_loss': 0.7246473336696048, 'val_accuracy': 0.590810243500347, 'val_precision': 0.590810243500347, 'val_recall': 0.590810243500347, 'val_f1': 0.590810243500347}\nRound 4: 6 clients dropped out of 10 during evaluation\nDropped client IDs: [17733881892529882227, 8457015012208665922, 10026370797255282897, 13303908111421134425, 15780236247657851889, 6977275890887553587]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6914026737213135     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6938286423683167     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.44999998807907104    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6908472776412964     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 5]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6931952238082886     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 4 evaluation metrics: {'test_loss': 0.6923129401117001, 'test_accuracy': 0.4675052355295457, 'test_f1': 0.4675052355295457, 'test_precision': 0.4675052355295457, 'test_recall': 0.4675052355295457}\nRound 5: 4 clients dropped out of 10 during training\nDropped client IDs: [7041842867620325298, 10026370797255282897, 5890663559472525427, 8457015012208665922]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 5 training metrics: {'train_loss': 0.6523050912218529, 'train_accuracy': 0.6312154784222335, 'val_loss': 0.7069813429239047, 'val_accuracy': 0.5374510710266578, 'val_precision': 0.5374510710266578, 'val_recall': 0.5374510710266578, 'val_f1': 0.5374510710266578}\nRound 5: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [17733881892529882227, 6977275890887553587, 8457015012208665922]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6756569147109985     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6981128454208374     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7163707613945007     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7000567317008972     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6764744520187378     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4434782564640045     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4434782564640045     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7102776169776917     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4434782564640045     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4434782564640045     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 6]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7172592282295227     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 5 evaluation metrics: {'test_loss': 0.6990406974576987, 'test_accuracy': 0.49399038389898264, 'test_f1': 0.49399038389898264, 'test_precision': 0.49399038389898264, 'test_recall': 0.49399038389898264}\nRound 6: 5 clients dropped out of 10 during training\nDropped client IDs: [17733881892529882227, 8457015012208665922, 13303908111421134425, 7041842867620325298, 5890663559472525427]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 6 training metrics: {'train_loss': 0.6304668008433936, 'train_accuracy': 0.6672240726425496, 'val_loss': 0.7027706731870821, 'val_accuracy': 0.6016795151309425, 'val_precision': 0.6016795151309425, 'val_recall': 0.6016795151309425, 'val_f1': 0.6016795151309425}\nRound 6: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [6276042256941164512, 8457015012208665922, 10026370797255282897]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7015886902809143     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4416666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6599775552749634     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6797910928726196     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │     0.681686520576477     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6776263117790222     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6537311673164368     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 7]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7038408517837524     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4017094075679779     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 6 evaluation metrics: {'test_loss': 0.6796625331311243, 'test_accuracy': 0.49462365730261715, 'test_f1': 0.49462365730261715, 'test_precision': 0.49462365730261715, 'test_recall': 0.49462365730261715}\nRound 7: 1 clients dropped out of 10 during training\nDropped client IDs: [5890663559472525427]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 7 training metrics: {'train_loss': 0.5976119376050627, 'train_accuracy': 0.6912181250068576, 'val_loss': 0.741792933827194, 'val_accuracy': 0.549004318496886, 'val_precision': 0.549004318496886, 'val_recall': 0.549004318496886, 'val_f1': 0.549004318496886}\nRound 7: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [17733881892529882227, 8457015012208665922, 15780236247657851889]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6493344902992249     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │     0.67601078748703      │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │            0.5            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7009252309799194     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6772753596305847     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6456667184829712     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7135233283042908     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.40869563817977905    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 8]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 8 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7051441073417664     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.41025641560554504    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 7 evaluation metrics: {'test_loss': 0.680844415552341, 'test_accuracy': 0.48557692447390693, 'test_f1': 0.48557692447390693, 'test_precision': 0.48557692447390693, 'test_recall': 0.48557692447390693}\nRound 8: 2 clients dropped out of 10 during training\nDropped client IDs: [15780236247657851889, 5890663559472525427]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 8 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 8 training metrics: {'train_loss': 0.5868222142510676, 'train_accuracy': 0.6888652169202704, 'val_loss': 0.788716781977713, 'val_accuracy': 0.5789147997924986, 'val_precision': 0.5789147997924986, 'val_recall': 0.5789147997924986, 'val_f1': 0.5789147997924986}\nRound 8: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [15780236247657851889, 4225278872497288944, 5890663559472525427]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6713815331459045     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4833333194255829     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6170927882194519     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6652675271034241     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6166666746139526     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6166666746139526     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6174296736717224     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6166666746139526     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6166666746139526     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.4956521689891815     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.4956521689891815     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │     0.67942214012146      │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.4956521689891815     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.4956521689891815     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │     0.504273533821106     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │     0.504273533821106     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6601505279541016     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │     0.504273533821106     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │     0.504273533821106     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 9]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.39603960514068604    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.39603960514068604    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7513254880905151     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.39603960514068604    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.39603960514068604    │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 8 evaluation metrics: {'test_loss': 0.6639552458039363, 'test_accuracy': 0.5239852479536449, 'test_f1': 0.5239852479536449, 'test_precision': 0.5239852479536449, 'test_recall': 0.5239852479536449}\nRound 9: 3 clients dropped out of 10 during training\nDropped client IDs: [17733881892529882227, 13303908111421134425, 6276042256941164512]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n","output_type":"stream"},{"name":"stdout","text":"Round 9 training metrics: {'train_loss': 0.5479022490686597, 'train_accuracy': 0.7345565755250621, 'val_loss': 0.6425589291509868, 'val_accuracy': 0.6311087535061968, 'val_precision': 0.6311087535061968, 'val_recall': 0.6311087535061968, 'val_f1': 0.6311087535061968}\nRound 9: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [4225278872497288944, 10026370797255282897, 7041842867620325298]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6583333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6583333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │     0.625863254070282     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6583333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6583333611488342     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │           0.75            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │           0.75            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.5882498025894165     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │           0.75            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │           0.75            │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │     0.699999988079071     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │     0.699999988079071     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6093207001686096     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │     0.699999988079071     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │     0.699999988079071     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6833333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6833333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │     0.639034628868103     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6833333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6833333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.7083333134651184     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.7083333134651184     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.5965561270713806     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.7083333134651184     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.7083333134651184     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.7166666388511658     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.7166666388511658     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.5961818099021912     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.7166666388511658     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.7166666388511658     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 10]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6138613820075989     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6138613820075989     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6471306085586548     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6138613820075989     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6138613820075989     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 9 evaluation metrics: {'test_loss': 0.6138671744029501, 'test_accuracy': 0.6918392158890467, 'test_f1': 0.6918392158890467, 'test_precision': 0.6918392158890467, 'test_recall': 0.6918392158890467}\nRound 10: 4 clients dropped out of 10 during training\nDropped client IDs: [8457015012208665922, 17733881892529882227, 10026370797255282897, 6977275890887553587]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=452)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=452)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0  | model          | BrainMRINet         | 131 K  | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 131 K     Total params\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0.526     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 35        Modules in train mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 10 training metrics: {'train_loss': 0.5490410326464662, 'train_accuracy': 0.7340499221575905, 'val_loss': 0.7852130754025403, 'val_accuracy': 0.5787540590300143, 'val_precision': 0.5787540590300143, 'val_recall': 0.5787540590300143, 'val_f1': 0.5787540590300143}\nRound 10: 4 clients dropped out of 10 during evaluation\nDropped client IDs: [17733881892529882227, 6276042256941164512, 6977275890887553587, 5890663559472525427]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.5927899479866028     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6343850493431091     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │           0.625           │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │           0.625           │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6112329959869385     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │           0.625           │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │           0.625           │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │     0.52173912525177      │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │     0.52173912525177      │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │     0.683838963508606     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │     0.52173912525177      │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │     0.52173912525177      │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.5213675498962402     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.5213675498962402     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.6705433130264282     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.5213675498962402     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.5213675498962402     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=452)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [SUMMARY]\n\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 1457.98s\n\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6918848821157899\n\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6894544849096629\n\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.6939519975985233\n\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.6923129401117001\n\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.6990406974576987\n\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.6796625331311243\n\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.680844415552341\n\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.6639552458039363\n\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.6138671744029501\n\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.6611779988414109\n\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n\u001b[92mINFO \u001b[0m:      \t{'train_accuracy': [(1, 0.5596696986565263),\n\u001b[92mINFO \u001b[0m:      \t                    (2, 0.5915622177819381),\n\u001b[92mINFO \u001b[0m:      \t                    (3, 0.5819169085919575),\n\u001b[92mINFO \u001b[0m:      \t                    (4, 0.6186440663714385),\n\u001b[92mINFO \u001b[0m:      \t                    (5, 0.6312154784222335),\n\u001b[92mINFO \u001b[0m:      \t                    (6, 0.6672240726425496),\n\u001b[92mINFO \u001b[0m:      \t                    (7, 0.6912181250068576),\n\u001b[92mINFO \u001b[0m:      \t                    (8, 0.6888652169202704),\n\u001b[92mINFO \u001b[0m:      \t                    (9, 0.7345565755250621),\n\u001b[92mINFO \u001b[0m:      \t                    (10, 0.7340499221575905)],\n\u001b[92mINFO \u001b[0m:      \t 'train_loss': [(1, 0.6915231507606944),\n\u001b[92mINFO \u001b[0m:      \t                (2, 0.6636595545613923),\n\u001b[92mINFO \u001b[0m:      \t                (3, 0.669087836830204),\n\u001b[92mINFO \u001b[0m:      \t                (4, 0.6536725372184276),\n\u001b[92mINFO \u001b[0m:      \t                (5, 0.6523050912218529),\n\u001b[92mINFO \u001b[0m:      \t                (6, 0.6304668008433936),\n\u001b[92mINFO \u001b[0m:      \t                (7, 0.5976119376050627),\n\u001b[92mINFO \u001b[0m:      \t                (8, 0.5868222142510676),\n\u001b[92mINFO \u001b[0m:      \t                (9, 0.5479022490686597),\n\u001b[92mINFO \u001b[0m:      \t                (10, 0.5490410326464662)],\n\u001b[92mINFO \u001b[0m:      \t 'val_accuracy': [(1, 0.5360329833812515),\n\u001b[92mINFO \u001b[0m:      \t                  (2, 0.5647094901896004),\n\u001b[92mINFO \u001b[0m:      \t                  (3, 0.5841246676737684),\n\u001b[92mINFO \u001b[0m:      \t                  (4, 0.590810243500347),\n\u001b[92mINFO \u001b[0m:      \t                  (5, 0.5374510710266578),\n\u001b[92mINFO \u001b[0m:      \t                  (6, 0.6016795151309425),\n\u001b[92mINFO \u001b[0m:      \t                  (7, 0.549004318496886),\n\u001b[92mINFO \u001b[0m:      \t                  (8, 0.5789147997924986),\n\u001b[92mINFO \u001b[0m:      \t                  (9, 0.6311087535061968),\n\u001b[92mINFO \u001b[0m:      \t                  (10, 0.5787540590300143)],\n\u001b[92mINFO \u001b[0m:      \t 'val_f1': [(1, 0.5360329833812515),\n\u001b[92mINFO \u001b[0m:      \t            (2, 0.5647094901896004),\n\u001b[92mINFO \u001b[0m:      \t            (3, 0.5841246676737684),\n\u001b[92mINFO \u001b[0m:      \t            (4, 0.590810243500347),\n\u001b[92mINFO \u001b[0m:      \t            (5, 0.5374510710266578),\n\u001b[92mINFO \u001b[0m:      \t            (6, 0.6016795151309425),\n\u001b[92mINFO \u001b[0m:      \t            (7, 0.549004318496886),\n\u001b[92mINFO \u001b[0m:      \t            (8, 0.5789147997924986),\n\u001b[92mINFO \u001b[0m:      \t            (9, 0.6311087535061968),\n\u001b[92mINFO \u001b[0m:      \t            (10, 0.5787540590300143)],\n\u001b[92mINFO \u001b[0m:      \t 'val_loss': [(1, 0.6897938969482053),\n\u001b[92mINFO \u001b[0m:      \t              (2, 0.7318485005847251),\n\u001b[92mINFO \u001b[0m:      \t              (3, 0.7163443028420294),\n\u001b[92mINFO \u001b[0m:      \t              (4, 0.7246473336696048),\n\u001b[92mINFO \u001b[0m:      \t              (5, 0.7069813429239047),\n\u001b[92mINFO \u001b[0m:      \t              (6, 0.7027706731870821),\n\u001b[92mINFO \u001b[0m:      \t              (7, 0.741792933827194),\n\u001b[92mINFO \u001b[0m:      \t              (8, 0.788716781977713),\n\u001b[92mINFO \u001b[0m:      \t              (9, 0.6425589291509868),\n\u001b[92mINFO \u001b[0m:      \t              (10, 0.7852130754025403)],\n\u001b[92mINFO \u001b[0m:      \t 'val_precision': [(1, 0.5360329833812515),\n\u001b[92mINFO \u001b[0m:      \t                   (2, 0.5647094901896004),\n\u001b[92mINFO \u001b[0m:      \t                   (3, 0.5841246676737684),\n\u001b[92mINFO \u001b[0m:      \t                   (4, 0.590810243500347),\n\u001b[92mINFO \u001b[0m:      \t                   (5, 0.5374510710266578),\n\u001b[92mINFO \u001b[0m:      \t                   (6, 0.6016795151309425),\n\u001b[92mINFO \u001b[0m:      \t                   (7, 0.549004318496886),\n\u001b[92mINFO \u001b[0m:      \t                   (8, 0.5789147997924986),\n\u001b[92mINFO \u001b[0m:      \t                   (9, 0.6311087535061968),\n\u001b[92mINFO \u001b[0m:      \t                   (10, 0.5787540590300143)],\n\u001b[92mINFO \u001b[0m:      \t 'val_recall': [(1, 0.5360329833812515),\n\u001b[92mINFO \u001b[0m:      \t                (2, 0.5647094901896004),\n\u001b[92mINFO \u001b[0m:      \t                (3, 0.5841246676737684),\n\u001b[92mINFO \u001b[0m:      \t                (4, 0.590810243500347),\n\u001b[92mINFO \u001b[0m:      \t                (5, 0.5374510710266578),\n\u001b[92mINFO \u001b[0m:      \t                (6, 0.6016795151309425),\n\u001b[92mINFO \u001b[0m:      \t                (7, 0.549004318496886),\n\u001b[92mINFO \u001b[0m:      \t                (8, 0.5789147997924986),\n\u001b[92mINFO \u001b[0m:      \t                (9, 0.6311087535061968),\n\u001b[92mINFO \u001b[0m:      \t                (10, 0.5787540590300143)]}\n\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n\u001b[92mINFO \u001b[0m:      \t{'test_accuracy': [(1, 0.4452644560719768),\n\u001b[92mINFO \u001b[0m:      \t                   (2, 0.5645756509617832),\n\u001b[92mINFO \u001b[0m:      \t                   (3, 0.4501607720076335),\n\u001b[92mINFO \u001b[0m:      \t                   (4, 0.4675052355295457),\n\u001b[92mINFO \u001b[0m:      \t                   (5, 0.49399038389898264),\n\u001b[92mINFO \u001b[0m:      \t                   (6, 0.49462365730261715),\n\u001b[92mINFO \u001b[0m:      \t                   (7, 0.48557692447390693),\n\u001b[92mINFO \u001b[0m:      \t                   (8, 0.5239852479536449),\n\u001b[92mINFO \u001b[0m:      \t                   (9, 0.6918392158890467),\n\u001b[92mINFO \u001b[0m:      \t                   (10, 0.5396825481114793)],\n\u001b[92mINFO \u001b[0m:      \t 'test_f1': [(1, 0.4452644560719768),\n\u001b[92mINFO \u001b[0m:      \t             (2, 0.5645756509617832),\n\u001b[92mINFO \u001b[0m:      \t             (3, 0.4501607720076335),\n\u001b[92mINFO \u001b[0m:      \t             (4, 0.4675052355295457),\n\u001b[92mINFO \u001b[0m:      \t             (5, 0.49399038389898264),\n\u001b[92mINFO \u001b[0m:      \t             (6, 0.49462365730261715),\n\u001b[92mINFO \u001b[0m:      \t             (7, 0.48557692447390693),\n\u001b[92mINFO \u001b[0m:      \t             (8, 0.5239852479536449),\n\u001b[92mINFO \u001b[0m:      \t             (9, 0.6918392158890467),\n\u001b[92mINFO \u001b[0m:      \t             (10, 0.5396825481114793)],\n\u001b[92mINFO \u001b[0m:      \t 'test_loss': [(1, 0.6918848821157899),\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=452)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=452)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/acc          │    0.3762376308441162     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │          test/f1          │    0.3762376308441162     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │         test/loss         │    0.7969539165496826     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │      test/precision       │    0.3762376308441162     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m │        test/recall        │    0.3762376308441162     │\n\u001b[36m(ClientAppActor pid=452)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 10 evaluation metrics: {'test_loss': 0.6611779988414109, 'test_accuracy': 0.5396825481114793, 'test_f1': 0.5396825481114793, 'test_precision': 0.5396825481114793, 'test_recall': 0.5396825481114793}\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      \t               (2, 0.6894544849096629),\n\u001b[92mINFO \u001b[0m:      \t               (3, 0.6939519975985233),\n\u001b[92mINFO \u001b[0m:      \t               (4, 0.6923129401117001),\n\u001b[92mINFO \u001b[0m:      \t               (5, 0.6990406974576987),\n\u001b[92mINFO \u001b[0m:      \t               (6, 0.6796625331311243),\n\u001b[92mINFO \u001b[0m:      \t               (7, 0.680844415552341),\n\u001b[92mINFO \u001b[0m:      \t               (8, 0.6639552458039363),\n\u001b[92mINFO \u001b[0m:      \t               (9, 0.6138671744029501),\n\u001b[92mINFO \u001b[0m:      \t               (10, 0.6611779988414109)],\n\u001b[92mINFO \u001b[0m:      \t 'test_precision': [(1, 0.4452644560719768),\n\u001b[92mINFO \u001b[0m:      \t                    (2, 0.5645756509617832),\n\u001b[92mINFO \u001b[0m:      \t                    (3, 0.4501607720076335),\n\u001b[92mINFO \u001b[0m:      \t                    (4, 0.4675052355295457),\n\u001b[92mINFO \u001b[0m:      \t                    (5, 0.49399038389898264),\n\u001b[92mINFO \u001b[0m:      \t                    (6, 0.49462365730261715),\n\u001b[92mINFO \u001b[0m:      \t                    (7, 0.48557692447390693),\n\u001b[92mINFO \u001b[0m:      \t                    (8, 0.5239852479536449),\n\u001b[92mINFO \u001b[0m:      \t                    (9, 0.6918392158890467),\n\u001b[92mINFO \u001b[0m:      \t                    (10, 0.5396825481114793)],\n\u001b[92mINFO \u001b[0m:      \t 'test_recall': [(1, 0.4452644560719768),\n\u001b[92mINFO \u001b[0m:      \t                 (2, 0.5645756509617832),\n\u001b[92mINFO \u001b[0m:      \t                 (3, 0.4501607720076335),\n\u001b[92mINFO \u001b[0m:      \t                 (4, 0.4675052355295457),\n\u001b[92mINFO \u001b[0m:      \t                 (5, 0.49399038389898264),\n\u001b[92mINFO \u001b[0m:      \t                 (6, 0.49462365730261715),\n\u001b[92mINFO \u001b[0m:      \t                 (7, 0.48557692447390693),\n\u001b[92mINFO \u001b[0m:      \t                 (8, 0.5239852479536449),\n\u001b[92mINFO \u001b[0m:      \t                 (9, 0.6918392158890467),\n\u001b[92mINFO \u001b[0m:      \t                 (10, 0.5396825481114793)]}\n\u001b[92mINFO \u001b[0m:      \n","output_type":"stream"},{"name":"stdout","text":"Result is {'rounds': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'train_accuracy': [0.5596696986565263, 0.5915622177819381, 0.5819169085919575, 0.6186440663714385, 0.6312154784222335, 0.6672240726425496, 0.6912181250068576, 0.6888652169202704, 0.7345565755250621, 0.7340499221575905], 'train_loss': [0.6915231507606944, 0.6636595545613923, 0.669087836830204, 0.6536725372184276, 0.6523050912218529, 0.6304668008433936, 0.5976119376050627, 0.5868222142510676, 0.5479022490686597, 0.5490410326464662], 'test_accuracy': [0.4452644560719768, 0.5645756509617832, 0.4501607720076335, 0.4675052355295457, 0.49399038389898264, 0.49462365730261715, 0.48557692447390693, 0.5239852479536449, 0.6918392158890467, 0.5396825481114793], 'test_loss': [0.6918848821157899, 0.6894544849096629, 0.6939519975985233, 0.6923129401117001, 0.6990406974576987, 0.6796625331311243, 0.680844415552341, 0.6639552458039363, 0.6138671744029501, 0.6611779988414109], 'test_f1': [0.4452644560719768, 0.5645756509617832, 0.4501607720076335, 0.4675052355295457, 0.49399038389898264, 0.49462365730261715, 0.48557692447390693, 0.5239852479536449, 0.6918392158890467, 0.5396825481114793], 'test_precision': [0.4452644560719768, 0.5645756509617832, 0.4501607720076335, 0.4675052355295457, 0.49399038389898264, 0.49462365730261715, 0.48557692447390693, 0.5239852479536449, 0.6918392158890467, 0.5396825481114793], 'test_recall': [0.4452644560719768, 0.5645756509617832, 0.4501607720076335, 0.4675052355295457, 0.49399038389898264, 0.49462365730261715, 0.48557692447390693, 0.5239852479536449, 0.6918392158890467, 0.5396825481114793]}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_dropout_history</td><td>▃▃▁█▃▃▃▃▃▅</td></tr><tr><td>server_round_eval</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test_accuracy</td><td>▁▄▁▂▂▂▂▃█▄</td></tr><tr><td>test_f1</td><td>▁▄▁▂▂▂▂▃█▄</td></tr><tr><td>test_loss</td><td>▇▇█▇█▆▇▅▁▅</td></tr><tr><td>test_precision</td><td>▁▄▁▂▂▂▂▃█▄</td></tr><tr><td>test_recall</td><td>▁▄▁▂▂▂▂▃█▄</td></tr><tr><td>train_accuracy</td><td>▁▂▂▃▄▅▆▆██</td></tr><tr><td>train_dropout_history</td><td>▃▅▁▅▆█▁▃▅▆</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▃▃▁▁</td></tr><tr><td>train_server_round</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_dropout_history</td><td>4</td></tr><tr><td>server_round_eval</td><td>10</td></tr><tr><td>test_accuracy</td><td>0.53968</td></tr><tr><td>test_f1</td><td>0.53968</td></tr><tr><td>test_loss</td><td>0.66118</td></tr><tr><td>test_precision</td><td>0.53968</td></tr><tr><td>test_recall</td><td>0.53968</td></tr><tr><td>train_accuracy</td><td>0.73405</td></tr><tr><td>train_dropout_history</td><td>4</td></tr><tr><td>train_loss</td><td>0.54904</td></tr><tr><td>train_server_round</td><td>10</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dropout_30pct_random_train_random_eval</strong> at: <a href='https://wandb.ai/trungviet17/federated-mri-server/runs/nkcqdirh' target=\"_blank\">https://wandb.ai/trungviet17/federated-mri-server/runs/nkcqdirh</a><br> View project at: <a href='https://wandb.ai/trungviet17/federated-mri-server' target=\"_blank\">https://wandb.ai/trungviet17/federated-mri-server</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250604_170640-nkcqdirh/logs</code>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"({'rounds': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n  'train_accuracy': [0.5596696986565263,\n   0.5915622177819381,\n   0.5819169085919575,\n   0.6186440663714385,\n   0.6312154784222335,\n   0.6672240726425496,\n   0.6912181250068576,\n   0.6888652169202704,\n   0.7345565755250621,\n   0.7340499221575905],\n  'train_loss': [0.6915231507606944,\n   0.6636595545613923,\n   0.669087836830204,\n   0.6536725372184276,\n   0.6523050912218529,\n   0.6304668008433936,\n   0.5976119376050627,\n   0.5868222142510676,\n   0.5479022490686597,\n   0.5490410326464662],\n  'test_accuracy': [0.4452644560719768,\n   0.5645756509617832,\n   0.4501607720076335,\n   0.4675052355295457,\n   0.49399038389898264,\n   0.49462365730261715,\n   0.48557692447390693,\n   0.5239852479536449,\n   0.6918392158890467,\n   0.5396825481114793],\n  'test_loss': [0.6918848821157899,\n   0.6894544849096629,\n   0.6939519975985233,\n   0.6923129401117001,\n   0.6990406974576987,\n   0.6796625331311243,\n   0.680844415552341,\n   0.6639552458039363,\n   0.6138671744029501,\n   0.6611779988414109],\n  'test_f1': [0.4452644560719768,\n   0.5645756509617832,\n   0.4501607720076335,\n   0.4675052355295457,\n   0.49399038389898264,\n   0.49462365730261715,\n   0.48557692447390693,\n   0.5239852479536449,\n   0.6918392158890467,\n   0.5396825481114793],\n  'test_precision': [0.4452644560719768,\n   0.5645756509617832,\n   0.4501607720076335,\n   0.4675052355295457,\n   0.49399038389898264,\n   0.49462365730261715,\n   0.48557692447390693,\n   0.5239852479536449,\n   0.6918392158890467,\n   0.5396825481114793],\n  'test_recall': [0.4452644560719768,\n   0.5645756509617832,\n   0.4501607720076335,\n   0.4675052355295457,\n   0.49399038389898264,\n   0.49462365730261715,\n   0.48557692447390693,\n   0.5239852479536449,\n   0.6918392158890467,\n   0.5396825481114793]},\n ({1: [6276042256941164512, 15780236247657851889],\n   2: [6276042256941164512, 15780236247657851889, 4225278872497288944],\n   3: [4225278872497288944],\n   4: [7041842867620325298, 5890663559472525427, 10026370797255282897],\n   5: [7041842867620325298,\n    10026370797255282897,\n    5890663559472525427,\n    8457015012208665922],\n   6: [17733881892529882227,\n    8457015012208665922,\n    13303908111421134425,\n    7041842867620325298,\n    5890663559472525427],\n   7: [5890663559472525427],\n   8: [15780236247657851889, 5890663559472525427],\n   9: [17733881892529882227, 13303908111421134425, 6276042256941164512],\n   10: [8457015012208665922,\n    17733881892529882227,\n    10026370797255282897,\n    6977275890887553587]},\n  {1: [15780236247657851889, 17733881892529882227, 5890663559472525427],\n   2: [17733881892529882227, 4225278872497288944, 6276042256941164512],\n   3: [13303908111421134425, 4225278872497288944],\n   4: [17733881892529882227,\n    8457015012208665922,\n    10026370797255282897,\n    13303908111421134425,\n    15780236247657851889,\n    6977275890887553587],\n   5: [17733881892529882227, 6977275890887553587, 8457015012208665922],\n   6: [6276042256941164512, 8457015012208665922, 10026370797255282897],\n   7: [17733881892529882227, 8457015012208665922, 15780236247657851889],\n   8: [15780236247657851889, 4225278872497288944, 5890663559472525427],\n   9: [4225278872497288944, 10026370797255282897, 7041842867620325298],\n   10: [17733881892529882227,\n    6276042256941164512,\n    6977275890887553587,\n    5890663559472525427]}))"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}