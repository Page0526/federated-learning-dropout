{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:36:25.779408Z",
     "iopub.status.busy": "2025-05-03T16:36:25.778968Z",
     "iopub.status.idle": "2025-05-03T16:36:51.062304Z",
     "shell.execute_reply": "2025-05-03T16:36:51.061635Z",
     "shell.execute_reply.started": "2025-05-03T16:36:25.779383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:36:51.064297Z",
     "iopub.status.busy": "2025-05-03T16:36:51.063686Z",
     "iopub.status.idle": "2025-05-03T16:37:11.081051Z",
     "shell.execute_reply": "2025-05-03T16:37:11.080495Z",
     "shell.execute_reply.started": "2025-05-03T16:36:51.064273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import warnings\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter, OrderedDict\n",
    "from typing import List, Tuple, Dict, Optional, Union, Callable\n",
    "from enum import IntEnum\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "\n",
    "# Torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Flower\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp\n",
    "from flwr.common import (\n",
    "    Code, EvaluateIns, EvaluateRes, FitIns, FitRes, GetParametersIns, GetParametersRes,\n",
    "    Status, Parameters, Scalar, NDArray, NDArrays, ndarrays_to_parameters, parameters_to_ndarrays, Context\n",
    ")\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy import Strategy\n",
    "from flwr.simulation import run_simulation\n",
    "\n",
    "# HuggingFace Datasets\n",
    "from datasets.utils.logging import disable_progress_bar, set_verbosity_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:44.122512Z",
     "iopub.status.busy": "2025-05-03T16:37:44.121316Z",
     "iopub.status.idle": "2025-05-03T16:37:44.209669Z",
     "shell.execute_reply": "2025-05-03T16:37:44.208873Z",
     "shell.execute_reply.started": "2025-05-03T16:37:44.122482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Thiết lập thiết bị\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()\n",
    "set_verbosity_error()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:44.878969Z",
     "iopub.status.busy": "2025-05-03T16:37:44.878694Z",
     "iopub.status.idle": "2025-05-03T16:37:44.883280Z",
     "shell.execute_reply": "2025-05-03T16:37:44.882352Z",
     "shell.execute_reply.started": "2025-05-03T16:37:44.878948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hằng số\n",
    "NUM_CLIENTS = 10\n",
    "NUM_ROUNDS = 5\n",
    "\n",
    "# Định nghĩa drop out\n",
    "class CustomCode(IntEnum):\n",
    "    DROPPED_OUT = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:47.529681Z",
     "iopub.status.busy": "2025-05-03T16:37:47.529399Z",
     "iopub.status.idle": "2025-05-03T16:37:47.627487Z",
     "shell.execute_reply": "2025-05-03T16:37:47.626817Z",
     "shell.execute_reply.started": "2025-05-03T16:37:47.529659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "im = nib.load('/kaggle/input/mri-dataset/not_skull_stripped/sub-BrainAge000000/anat/sub-BrainAge000000_T1w.nii/sub-BrainAge000000_T1w.nii')\n",
    "data = im.get_fdata()\n",
    "data.shape, im.affine, im.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:49.063003Z",
     "iopub.status.busy": "2025-05-03T16:37:49.062696Z",
     "iopub.status.idle": "2025-05-03T16:37:49.276789Z",
     "shell.execute_reply": "2025-05-03T16:37:49.276208Z",
     "shell.execute_reply.started": "2025-05-03T16:37:49.062979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_slice(slice_index):\n",
    "    plt.imshow(data[slice_index, :, :], cmap='gray')\n",
    "    plt.title(f\"Axial Slice {slice_index}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "interact(show_slice, slice_index=(0, data.shape[2] - 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:52.155262Z",
     "iopub.status.busy": "2025-05-03T16:37:52.154591Z",
     "iopub.status.idle": "2025-05-03T16:37:53.899683Z",
     "shell.execute_reply": "2025-05-03T16:37:53.898944Z",
     "shell.execute_reply.started": "2025-05-03T16:37:52.155238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/mri-dataset/not_skull_stripped'\n",
    "label_path = list(Path(data_dir).glob(\"*.xlsx\"))\n",
    "label_ls = pd.read_excel(label_path[0])\n",
    "label_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:53.901601Z",
     "iopub.status.busy": "2025-05-03T16:37:53.900892Z",
     "iopub.status.idle": "2025-05-03T16:37:53.919869Z",
     "shell.execute_reply": "2025-05-03T16:37:53.919216Z",
     "shell.execute_reply.started": "2025-05-03T16:37:53.901562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_ls = label_ls[(label_ls['subject_dx'] == 'control') & ((label_ls['subject_sex'] == 'm') | (label_ls['subject_sex'] == 'f'))]\n",
    "len(label_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:56.002233Z",
     "iopub.status.busy": "2025-05-03T16:37:56.001455Z",
     "iopub.status.idle": "2025-05-03T16:37:56.362252Z",
     "shell.execute_reply": "2025-05-03T16:37:56.361491Z",
     "shell.execute_reply.started": "2025-05-03T16:37:56.002200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_ls['subject_age'] = pd.to_numeric(label_ls['subject_age'], errors='coerce')\n",
    "\n",
    "# Loại bỏ các dòng có giá trị NaN sau khi chuyển đổi\n",
    "label_ls = label_ls.dropna(subset=['subject_age'])\n",
    "\n",
    "# Vẽ biểu đồ phân bố tuổi\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(label_ls['subject_age'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Phân bố tuổi')\n",
    "plt.xlabel('Tuổi')\n",
    "plt.ylabel('Số lượng')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:37:58.490278Z",
     "iopub.status.busy": "2025-05-03T16:37:58.489683Z",
     "iopub.status.idle": "2025-05-03T16:37:58.501543Z",
     "shell.execute_reply": "2025-05-03T16:37:58.500832Z",
     "shell.execute_reply.started": "2025-05-03T16:37:58.490256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subject_metadata = label_ls[['subject_sex','subject_id','dataset_name','subject_age']]\n",
    "subject_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:38:00.235734Z",
     "iopub.status.busy": "2025-05-03T16:38:00.235199Z",
     "iopub.status.idle": "2025-05-03T16:38:00.265744Z",
     "shell.execute_reply": "2025-05-03T16:38:00.264978Z",
     "shell.execute_reply.started": "2025-05-03T16:38:00.235703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subject_metadata_dict = label_ls.set_index('subject_id')[['subject_sex','dataset_name','subject_age']].to_dict(orient='index')\n",
    "len(subject_metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:38:01.362390Z",
     "iopub.status.busy": "2025-05-03T16:38:01.362131Z",
     "iopub.status.idle": "2025-05-03T16:38:01.372314Z",
     "shell.execute_reply": "2025-05-03T16:38:01.371495Z",
     "shell.execute_reply.started": "2025-05-03T16:38:01.362370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, im_dir, label_ls, transform=None, im_filenames=None):\n",
    "        self.im_dir = Path(im_dir)\n",
    "        self.label_ls = label_ls\n",
    "        self.transform = transform\n",
    "\n",
    "        if im_filenames is not None:\n",
    "            self.im_filenames = im_filenames\n",
    "        else:\n",
    "            self.im_filenames = self._gather_valid_paths()\n",
    "\n",
    "    def _gather_valid_paths(self):\n",
    "        paths = self.im_dir.glob(\"*/*/*/*.nii\")\n",
    "        valid_paths = []\n",
    "        fail_paths = {\n",
    "            self.im_dir / \"sub-BrainAge005600/anat/sub-BrainAge005600_T1w.nii/sub-BrainAge005600_T1w.nii\"\n",
    "        }\n",
    "\n",
    "        for path in paths:\n",
    "            if not path.is_file():\n",
    "                continue\n",
    "                \n",
    "            if path in fail_paths:\n",
    "                continue\n",
    "                \n",
    "            subject_id = self._extract_subject_id(path)\n",
    "            if subject_id not in self.label_ls:\n",
    "                continue\n",
    "            try:\n",
    "                # nib.load(path).get_fdata()\n",
    "                nib.load(path)\n",
    "                valid_paths.append(path)\n",
    "            except Exception:\n",
    "                continue\n",
    "        return valid_paths\n",
    "\n",
    "    def _extract_subject_id(self, path):\n",
    "        for part in Path(path).parts:\n",
    "            if part.startswith(\"sub-BrainAge\"):\n",
    "                return part  # ví dụ: \"sub-BrainAge000000\"\n",
    "        return None\n",
    "\n",
    "    def _normalize(self, im):\n",
    "        im = (im - np.min(im)) / (np.max(im) - np.min(im) + 1e-5)\n",
    "        return im.astype(np.float32)\n",
    "\n",
    "    def _get_label(self, subject_id):\n",
    "        sex = self.label_ls.get(subject_id, {}).get(\"subject_sex\")\n",
    "        if sex == 'm':\n",
    "            return 0\n",
    "        elif sex == 'f':\n",
    "            return 1\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid label for subject {subject_id}: {sex}\")\n",
    "            \n",
    "    def _get_age(self, subject_id):\n",
    "        return self.label_ls.get(subject_id, {}).get(\"subject_age\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.im_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        im_path = self.im_filenames[idx]\n",
    "        subject_id = self._extract_subject_id(im_path)\n",
    "\n",
    "        im = nib.load(im_path).get_fdata()\n",
    "        im = self._normalize(im)\n",
    "\n",
    "        label = self._get_label(subject_id)\n",
    "        image = torch.from_numpy(im).unsqueeze(0)  # Shape: (1, H, W, D)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:38:04.038840Z",
     "iopub.status.busy": "2025-05-03T16:38:04.038553Z",
     "iopub.status.idle": "2025-05-03T16:38:04.045206Z",
     "shell.execute_reply": "2025-05-03T16:38:04.044537Z",
     "shell.execute_reply.started": "2025-05-03T16:38:04.038818Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_sample_data(data: MRIDataset, num_samples: int) -> list:\n",
    "    subject_metadata = data.label_ls\n",
    "\n",
    "    subject_ids = [data._extract_subject_id(path) for path in data.im_filenames]\n",
    "    age_array = np.array(\n",
    "        [subject_metadata.get(sid, {}).get(\"subject_age\", np.nan) for sid in subject_ids],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    valid_mask = ~np.isnan(age_array)\n",
    "    valid_indices = np.arange(len(data.im_filenames))[valid_mask]\n",
    "    age_array = age_array[valid_mask]\n",
    "\n",
    "    # Phân bins theo độ tuổi\n",
    "    bins = [0, 20, 30, 40, 50, 60, 70, 80, 100]\n",
    "    age_bins = np.digitize(age_array, bins, right=False)\n",
    "    unique_bins = np.unique(age_bins)\n",
    "\n",
    "    bin_counts = np.bincount(age_bins, minlength=max(unique_bins)+1)[1:]\n",
    "    age_dist = bin_counts / bin_counts.sum()\n",
    "\n",
    "    sampled_indices = []\n",
    "    for bin_id, dist in zip(range(1, len(age_dist)+1), age_dist):\n",
    "        bin_valid_indices = valid_indices[age_bins == bin_id]\n",
    "        bin_sample_count = int(num_samples * dist)\n",
    "        bin_sample_count = min(len(bin_valid_indices), bin_sample_count)\n",
    "        if bin_sample_count > 0:\n",
    "            chosen = np.random.choice(bin_valid_indices, size=bin_sample_count, replace=False)\n",
    "            sampled_indices.extend(chosen)\n",
    "\n",
    "    return sampled_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:38:05.555236Z",
     "iopub.status.busy": "2025-05-03T16:38:05.554923Z",
     "iopub.status.idle": "2025-05-03T16:38:05.559850Z",
     "shell.execute_reply": "2025-05-03T16:38:05.559127Z",
     "shell.execute_reply.started": "2025-05-03T16:38:05.555214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_client_datasets(partition_id: int, num_partitions: int, dataset, num_samples: int):\n",
    "    data = dataset\n",
    "    sampled_indices = get_sample_data(data, num_samples)\n",
    "\n",
    "    np.random.shuffle(sampled_indices)\n",
    "    train_size = int(0.8 * len(sampled_indices))\n",
    "    train_indices = sampled_indices[:train_size]\n",
    "    val_indices = sampled_indices[train_size:]\n",
    "\n",
    "    train_subset = Subset(data, train_indices)\n",
    "    val_subset = Subset(data, val_indices)\n",
    "    return train_subset, val_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:38:06.158576Z",
     "iopub.status.busy": "2025-05-03T16:38:06.158014Z",
     "iopub.status.idle": "2025-05-03T16:38:06.162083Z",
     "shell.execute_reply": "2025-05-03T16:38:06.161302Z",
     "shell.execute_reply.started": "2025-05-03T16:38:06.158552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_server_test_datasets(data: MRIDataset):\n",
    "    testloader = DataLoader(data, batch_size=8, shuffle=False)\n",
    "    return testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:38:06.906777Z",
     "iopub.status.busy": "2025-05-03T16:38:06.906501Z",
     "iopub.status.idle": "2025-05-03T16:40:26.446273Z",
     "shell.execute_reply": "2025-05-03T16:40:26.445627Z",
     "shell.execute_reply.started": "2025-05-03T16:38:06.906757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = MRIDataset(data_dir, subject_metadata_dict)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:43:45.840707Z",
     "iopub.status.busy": "2025-05-03T16:43:45.840241Z",
     "iopub.status.idle": "2025-05-03T16:43:45.845119Z",
     "shell.execute_reply": "2025-05-03T16:43:45.844575Z",
     "shell.execute_reply.started": "2025-05-03T16:43:45.840670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_filenames(im_filenames, output_path):\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump([str(path) for path in im_filenames], f)\n",
    "    print(f\"Đã lưu im_filenames vào: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:43:47.630984Z",
     "iopub.status.busy": "2025-05-03T16:43:47.630219Z",
     "iopub.status.idle": "2025-05-03T16:43:47.640103Z",
     "shell.execute_reply": "2025-05-03T16:43:47.639413Z",
     "shell.execute_reply.started": "2025-05-03T16:43:47.630949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_filenames(dataset.im_filenames, \"valid_filenames.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:43:50.610829Z",
     "iopub.status.busy": "2025-05-03T16:43:50.610515Z",
     "iopub.status.idle": "2025-05-03T16:43:50.615287Z",
     "shell.execute_reply": "2025-05-03T16:43:50.614600Z",
     "shell.execute_reply.started": "2025-05-03T16:43:50.610807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_filenames(input_path):\n",
    "    input_path = Path(input_path)\n",
    "    if not input_path.is_file():\n",
    "        raise FileNotFoundError(f\"File {input_path} không tồn tại\")\n",
    "    with open(input_path, 'r') as f:\n",
    "        return [Path(path) for path in json.load(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:43:52.440248Z",
     "iopub.status.busy": "2025-05-03T16:43:52.439712Z",
     "iopub.status.idle": "2025-05-03T16:43:52.469668Z",
     "shell.execute_reply": "2025-05-03T16:43:52.468975Z",
     "shell.execute_reply.started": "2025-05-03T16:43:52.440226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "im_filenames = load_filenames(\"valid_filenames.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:45:12.383693Z",
     "iopub.status.busy": "2025-05-03T16:45:12.383138Z",
     "iopub.status.idle": "2025-05-03T16:45:12.520326Z",
     "shell.execute_reply": "2025-05-03T16:45:12.519796Z",
     "shell.execute_reply.started": "2025-05-03T16:45:12.383667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_filenames = dataset.im_filenames\n",
    "\n",
    "# Chia train/test \n",
    "train_filenames, test_filenames = train_test_split(\n",
    "    all_filenames, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "trainset = MRIDataset(\n",
    "    im_dir=dataset.im_dir,\n",
    "    label_ls=dataset.label_ls,\n",
    "    transform=dataset.transform,\n",
    "    im_filenames=train_filenames\n",
    ")\n",
    "\n",
    "testset = MRIDataset(\n",
    "    im_dir=dataset.im_dir,\n",
    "    label_ls=dataset.label_ls,\n",
    "    transform=dataset.transform,\n",
    "    im_filenames=test_filenames\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# trainloader, _ = load_client_datasets(partition_id=0, num_partitions=1, dataset=trainset, num_samples=1000)\n",
    "\n",
    "# batch = next(iter(trainloader))\n",
    "# images, labels = batch\n",
    "# images = images.numpy()\n",
    "# slice_idx = images.shape[3] // 2\n",
    "# slices = images[:, :, :, slice_idx]\n",
    "\n",
    "# class_names = [\"Male\", \"Female\"]\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     if i < len(slices):\n",
    "#         ax.imshow(slices[i], cmap='gray')\n",
    "#         ax.set_title(class_names[labels.item()])\n",
    "#         ax.axis(\"off\")\n",
    "#     else:\n",
    "#         ax.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def plot_age_distribution(subset):\n",
    "#     dataset = subset.dataset\n",
    "#     indices = subset.indices\n",
    "\n",
    "#     data = []\n",
    "#     for i in indices:\n",
    "#         subject_id = dataset._extract_subject_id(dataset.im_filenames[i])\n",
    "#         metadata = dataset.label_ls.get(subject_id, {})\n",
    "#         age = metadata.get(\"subject_age\")\n",
    "#         sex = metadata.get(\"subject_sex\")\n",
    "#         if age is not None and not pd.isna(age) and sex in ['m', 'f']:\n",
    "#             data.append({\"age\": age, \"sex\": \"Male\" if sex == \"m\" else \"Female\"})\n",
    "\n",
    "#     if not data:\n",
    "#         print(\"No valid age/sex data found.\")\n",
    "#         return\n",
    "\n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     sns.histplot(data=df, x=\"age\", hue=\"sex\", bins=10, kde=True, palette={\"Male\": \"blue\", \"Female\": \"pink\"}, edgecolor=\"black\")\n",
    "#     plt.title(\"Age Distribution by Sex\")\n",
    "#     plt.xlabel(\"Age\")\n",
    "#     plt.ylabel(\"Count\")\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot_age_distribution(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:45:17.957277Z",
     "iopub.status.busy": "2025-05-03T16:45:17.956685Z",
     "iopub.status.idle": "2025-05-03T16:45:17.972547Z",
     "shell.execute_reply": "2025-05-03T16:45:17.971813Z",
     "shell.execute_reply.started": "2025-05-03T16:45:17.957253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm3d(num_input_features))\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True))\n",
    "        self.add_module(\n",
    "            'conv1',\n",
    "            nn.Conv3d(num_input_features,\n",
    "                      bn_size * growth_rate,\n",
    "                      kernel_size=1,\n",
    "                      stride=1,\n",
    "                      bias=False))\n",
    "        self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate))\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "        self.add_module(\n",
    "            'conv2',\n",
    "            nn.Conv3d(bn_size * growth_rate,\n",
    "                      growth_rate,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=False))\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super().forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features,\n",
    "                                     p=self.drop_rate,\n",
    "                                     training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super().__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate,\n",
    "                                growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer{}'.format(i + 1), layer)\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super().__init__()\n",
    "        self.add_module('norm', nn.BatchNorm3d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module(\n",
    "            'conv',\n",
    "            nn.Conv3d(num_input_features,\n",
    "                      num_output_features,\n",
    "                      kernel_size=1,\n",
    "                      stride=1,\n",
    "                      bias=False))\n",
    "        self.add_module('pool', nn.AvgPool3d(kernel_size=2, stride=2))\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_input_channels=1,\n",
    "                 conv1_t_size=7,\n",
    "                 conv1_t_stride=1,\n",
    "                 no_max_pool=False,\n",
    "                 growth_rate=32,\n",
    "                 block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64,\n",
    "                 bn_size=4,\n",
    "                 drop_rate=0,\n",
    "                 num_classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.features = [('conv1',\n",
    "                          nn.Conv3d(n_input_channels,\n",
    "                                    num_init_features,\n",
    "                                    kernel_size=(conv1_t_size, 7, 7),\n",
    "                                    stride=(conv1_t_stride, 2, 2),\n",
    "                                    padding=(conv1_t_size // 2, 3, 3),\n",
    "                                    bias=False)),\n",
    "                         ('norm1', nn.BatchNorm3d(num_init_features)),\n",
    "                         ('relu1', nn.ReLU(inplace=True))]\n",
    "        if not no_max_pool:\n",
    "            self.features.append(\n",
    "                ('pool1', nn.MaxPool3d(kernel_size=3, stride=2, padding=1)))\n",
    "        self.features = nn.Sequential(OrderedDict(self.features))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(num_layers=num_layers,\n",
    "                                num_input_features=num_features,\n",
    "                                bn_size=bn_size,\n",
    "                                growth_rate=growth_rate,\n",
    "                                drop_rate=drop_rate)\n",
    "            self.features.add_module('denseblock{}'.format(i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features,\n",
    "                                    num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition{}'.format(i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm3d(num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Khởi tạo trọng số\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool3d(out, output_size=(1, 1, 1)).view(features.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:45:21.281601Z",
     "iopub.status.busy": "2025-05-03T16:45:21.281046Z",
     "iopub.status.idle": "2025-05-03T16:45:21.292997Z",
     "shell.execute_reply": "2025-05-03T16:45:21.292138Z",
     "shell.execute_reply.started": "2025-05-03T16:45:21.281578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm hỗ trợ cho mô hình\n",
    "\n",
    "# Lấy tham số mô hình\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "# Cập nhật tham số mô hình\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(net, trainloader, epochs: int, lr: float, id: int) -> Tuple[float, float]:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    net.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        progress_bar = tqdm(trainloader, desc=f\"[Client {id} Epoch {epoch+1}/{epochs}]\", position=id, leave=False, disable=True)\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * labels.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(trainloader.dataset)\n",
    "        print(f\"[Client {id}] Epoch {epoch+1}/{epochs} - Loss: {avg_epoch_loss:.4f}\")\n",
    "        total_loss += epoch_loss\n",
    "    \n",
    "    avg_loss = total_loss / (len(trainloader.dataset) * epochs)\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    print(f\"[Client {id}] Train Loss: {avg_loss:.4f} | Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test(net, testloader, id: int) -> Tuple[float, float]:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    net.eval()\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(testloader, desc=f\"[Client {id}] Testing\", position=id, leave=False, disable=True)\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).float()\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels.unsqueeze(1)).item() * labels.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "            progress_bar.set_postfix(loss=loss/total)\n",
    "    \n",
    "    avg_loss = loss / len(testloader.dataset) if len(testloader.dataset) > 0 else 0.0\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    print(f\"[Client {id}] Test Loss: {avg_loss:.4f} | Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:45:25.292975Z",
     "iopub.status.busy": "2025-05-03T16:45:25.292219Z",
     "iopub.status.idle": "2025-05-03T16:45:25.384320Z",
     "shell.execute_reply": "2025-05-03T16:45:25.383596Z",
     "shell.execute_reply.started": "2025-05-03T16:45:25.292954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = DenseNet(num_init_features=32,growth_rate=16,block_config=(4, 8, 16, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train(model,trainloader,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "\n",
    "# summary(model, input_size=(8, 1, 130, 130, 130))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:45:27.164099Z",
     "iopub.status.busy": "2025-05-03T16:45:27.163439Z",
     "iopub.status.idle": "2025-05-03T16:45:27.177806Z",
     "shell.execute_reply": "2025-05-03T16:45:27.176917Z",
     "shell.execute_reply.started": "2025-05-03T16:45:27.164076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "def is_dropout(partition_id: int, num_partitions: int) -> bool:\n",
    "    prob = 0.2\n",
    "    return random.random() < prob\n",
    "\n",
    "# Định nghĩa Client\n",
    "class FlowerClient(Client):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader, num_partitions):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.num_partitions = num_partitions\n",
    "        self.previous_parameters = None\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        ndarrays = get_parameters(self.net)\n",
    "        parameters = ndarrays_to_parameters(ndarrays)\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return GetParametersRes(status=status, parameters=parameters)\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        if is_dropout(self.partition_id, self.num_partitions):\n",
    "            print(f\"[Client {self.partition_id}] dropped out in round {ins.config.get('server_round')}\")\n",
    "            status = Status(code=CustomCode.DROPPED_OUT, message=\"Client dropped out\")\n",
    "            return FitRes(\n",
    "                status=status,\n",
    "                parameters=ins.parameters,\n",
    "                num_examples=0,\n",
    "                metrics={}\n",
    "            )\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {ins.config}\")\n",
    "\n",
    "        ndarrays_original = parameters_to_ndarrays(ins.parameters)\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "\n",
    "        lr = ins.config.get(\"lr\", 0.001)\n",
    "        train_loss, train_accuracy = train(self.net, self.trainloader, epochs=1, lr=lr, id=self.partition_id)\n",
    "\n",
    "        ndarrays_updated = get_parameters(self.net)\n",
    "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
    "        self.previous_parameters = parameters_updated\n",
    "\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=parameters_updated,\n",
    "            num_examples=len(self.trainloader.dataset),\n",
    "            metrics={\n",
    "                \"train_loss\": float(train_loss),\n",
    "                \"train_accuracy\": float(train_accuracy)\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        if is_dropout(self.partition_id, self.num_partitions):\n",
    "            print(f\"[Client {self.partition_id}] dropped out in evaluation round {ins.config.get('server_round')}\")\n",
    "            status = Status(code=CustomCode.DROPPED_OUT, message=\"Client dropped out\")\n",
    "            return EvaluateRes(\n",
    "                status=status,\n",
    "                loss=0.0,\n",
    "                num_examples=0,\n",
    "                metrics={}\n",
    "            )\n",
    "\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {ins.config}\")\n",
    "\n",
    "        ndarrays_original = parameters_to_ndarrays(ins.parameters)\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "\n",
    "        val_loss, val_accuracy = test(self.net, self.valloader, self.partition_id)\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=float(val_loss),\n",
    "            num_examples=len(self.valloader.dataset),\n",
    "            metrics={\"val_accuracy\": float(val_accuracy)}\n",
    "        )\n",
    "\n",
    "# Hàm tạo client\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = model.to(DEVICE)\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    \n",
    "    train_subset, val_subset = load_client_datasets(partition_id, num_partitions, dataset=trainset, num_samples=4000)\n",
    "    trainloader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
    "    valloader = DataLoader(val_subset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    return FlowerClient(partition_id, net, trainloader, valloader, num_partitions).to_client()\n",
    "\n",
    "# Client\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T16:45:29.162599Z",
     "iopub.status.busy": "2025-05-03T16:45:29.162095Z",
     "iopub.status.idle": "2025-05-03T16:45:29.181286Z",
     "shell.execute_reply": "2025-05-03T16:45:29.180529Z",
     "shell.execute_reply.started": "2025-05-03T16:45:29.162576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom Strategy\n",
    "class FedCustom(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 1,\n",
    "        min_evaluate_clients: int = 1,\n",
    "        min_available_clients: int = 3,\n",
    "        evaluate_fn: Optional[Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "\n",
    "    def initialize_parameters(self, client_manager: ClientManager) -> Optional[Parameters]:\n",
    "        net = model\n",
    "        ndarrays = get_parameters(net)\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def configure_fit(self, server_round: int, parameters: Parameters, client_manager: ClientManager) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n",
    "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
    "\n",
    "        standard_config = {\"lr\": 0.001, \"server_round\": server_round}\n",
    "        fit_configurations = []\n",
    "        for client in clients:\n",
    "            fit_configurations.append((client, FitIns(parameters, standard_config)))\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]]\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        valid_results = [(client_proxy, res) for client_proxy, res in results if res.status.code == Code.OK]\n",
    "        if not valid_results:\n",
    "            return None, {}\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(res.parameters), res.num_examples)\n",
    "            for _, res in valid_results\n",
    "        ]\n",
    "        parameters_aggregated = ndarrays_to_parameters(\n",
    "            flwr.server.strategy.aggregate.aggregate(weights_results)\n",
    "        )\n",
    "\n",
    "        total_examples = sum(res.num_examples for _, res in valid_results)\n",
    "        train_loss_agg = sum(\n",
    "            res.num_examples * res.metrics[\"train_loss\"] for _, res in valid_results\n",
    "        ) / total_examples if total_examples > 0 else 0.0\n",
    "        train_accuracy_agg = sum(\n",
    "            res.num_examples * res.metrics[\"train_accuracy\"] for _, res in valid_results\n",
    "        ) / total_examples if total_examples > 0 else 0.0\n",
    "\n",
    "        metrics_aggregated = {\n",
    "            \"train_loss\": train_loss_agg,\n",
    "            \"train_accuracy\": train_accuracy_agg,\n",
    "            \"clients_participated\": len(valid_results)\n",
    "        }\n",
    "\n",
    "        # wandb.log({\n",
    "        #     \"round\": server_round,\n",
    "        #     \"train_loss\": train_loss_agg,\n",
    "        #     \"train_accuracy\": train_accuracy_agg,\n",
    "        #     \"clients_participated_fit\": len(valid_results)\n",
    "        # })\n",
    "\n",
    "        HISTORY[\"train_loss\"].append(train_loss_agg)\n",
    "        HISTORY[\"train_accuracy\"].append(train_accuracy_agg)\n",
    "        HISTORY[\"clients_participated\"].append(len(valid_results))\n",
    "\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {\"server_round\": server_round}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(client_manager.num_available())\n",
    "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        if not results:\n",
    "            print(f\"Round {server_round}: No results received\")\n",
    "            return None, {\"val_accuracy\": 0.0, \"clients_participated\": 0}\n",
    "\n",
    "        valid_results = [\n",
    "            (client_proxy, res) for client_proxy, res in results\n",
    "            if res.status.code == Code.OK\n",
    "        ]\n",
    "        if not valid_results:\n",
    "            print(f\"Round {server_round}: No valid evaluation results\")\n",
    "            return None, {\"val_accuracy\": 0.0, \"clients_participated\": 0}\n",
    "\n",
    "        total_examples = sum(res.num_examples for _, res in valid_results)\n",
    "        loss_aggregated = flwr.server.strategy.aggregate.weighted_loss_avg(\n",
    "            [(res.num_examples, res.loss) for _, res in valid_results]\n",
    "        )\n",
    "        val_accuracy_aggregated = sum(\n",
    "            res.num_examples * res.metrics[\"val_accuracy\"] for _, res in valid_results\n",
    "        ) / total_examples if total_examples > 0 else 0.0\n",
    "\n",
    "        metrics_aggregated = {\n",
    "            \"val_loss\": loss_aggregated,\n",
    "            \"val_accuracy\": val_accuracy_aggregated,\n",
    "            \"clients_participated\": len(valid_results)\n",
    "        }\n",
    "\n",
    "        # wandb.log({\n",
    "        #     \"round\": server_round,\n",
    "        #     \"val_loss\": loss_aggregated,\n",
    "        #     \"val_accuracy\": val_accuracy_aggregated,\n",
    "        #     \"clients_participated_eval\": len(valid_results)\n",
    "        # })\n",
    "\n",
    "        HISTORY[\"val_loss\"].append(loss_aggregated)\n",
    "        HISTORY[\"val_accuracy\"].append(val_accuracy_aggregated)\n",
    "        HISTORY[\"clients_participated\"].append(len(valid_results))\n",
    "\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(self, server_round: int, parameters: Parameters) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        if server_round == 0 or self.evaluate_fn is None:\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        return eval_res\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "\n",
    "# Hàm đánh giá trên server\n",
    "def evaluate_fn(server_round: int, parameters: NDArrays, config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    net = model.to(DEVICE)\n",
    "    set_parameters(net, parameters)\n",
    "    testloader = load_server_test_datasets(data=testset)\n",
    "    test_loss, test_accuracy = test(net, testloader, id=0)  # id=0 cho server\n",
    "    \n",
    "    # wandb.log({\n",
    "    #     \"round\": server_round,\n",
    "    #     \"test_loss\": test_loss,\n",
    "    #     \"test_accuracy\": test_accuracy\n",
    "    # })\n",
    "    \n",
    "    HISTORY[\"test_loss\"].append(test_loss)\n",
    "    HISTORY[\"test_accuracy\"].append(test_accuracy)\n",
    "    \n",
    "    return test_loss, {\"test_accuracy\": test_accuracy}\n",
    "\n",
    "# Server\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    strategy = FedCustom(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=1.0,\n",
    "        min_fit_clients=1,\n",
    "        min_evaluate_clients=1,\n",
    "        min_available_clients=NUM_CLIENTS,\n",
    "        evaluate_fn=evaluate_fn\n",
    "    )\n",
    "    config = ServerConfig(num_rounds=NUM_ROUNDS)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-03T17:12:58.153Z",
     "iopub.execute_input": "2025-05-03T16:45:34.018594Z",
     "iopub.status.busy": "2025-05-03T16:45:34.017905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cấu hình backend\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 0}}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config[\"client_resources\"][\"num_gpus\"] = 1\n",
    "\n",
    "# Khởi tạo HISTORY\n",
    "HISTORY = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_accuracy\": [],\n",
    "    \"clients_participated\": []\n",
    "}\n",
    "\n",
    "# Chạy simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-03T17:12:58.154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vẽ biểu đồ kết quả\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Biểu đồ Accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(range(1, len(HISTORY[\"train_accuracy\"]) + 1), HISTORY[\"train_accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(range(1, len(HISTORY[\"val_accuracy\"]) + 1), HISTORY[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.plot(range(1, len(HISTORY[\"test_accuracy\"]) + 1), HISTORY[\"test_accuracy\"], label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs. Round\")\n",
    "plt.legend()\n",
    "\n",
    "# Biểu đồ Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(range(1, len(HISTORY[\"train_loss\"]) + 1), HISTORY[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(range(1, len(HISTORY[\"val_loss\"]) + 1), HISTORY[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.plot(range(1, len(HISTORY[\"test_loss\"]) + 1), HISTORY[\"test_loss\"], label=\"Test Loss\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs. Round\")\n",
    "plt.legend()\n",
    "\n",
    "# Biểu đồ Clients Participated\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(range(1, len(HISTORY[\"clients_participated\"]) + 1), HISTORY[\"clients_participated\"], label=\"Clients Participated\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Number of Clients\")\n",
    "plt.title(\"Clients Participated vs. Round\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7180861,
     "sourceId": 11460111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
