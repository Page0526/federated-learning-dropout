{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11680004,"sourceType":"datasetVersion","datasetId":7180861},{"sourceId":11721921,"sourceType":"datasetVersion","datasetId":7270261}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q lightning flwr wandb hydra-core","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:35:53.014636Z","iopub.execute_input":"2025-06-03T05:35:53.015138Z","iopub.status.idle":"2025-06-03T05:37:15.239793Z","shell.execute_reply.started":"2025-06-03T05:35:53.015110Z","shell.execute_reply":"2025-06-03T05:37:15.239061Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.8 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom pathlib import Path\nimport nibabel as nib\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom typing import Dict, List, Optional, Tuple, Union","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:15.241822Z","iopub.execute_input":"2025-06-03T05:37:15.242132Z","iopub.status.idle":"2025-06-03T05:37:19.021280Z","shell.execute_reply.started":"2025-06-03T05:37:15.242109Z","shell.execute_reply":"2025-06-03T05:37:19.020534Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nsecret_label = \"wandb_api_key\"\nWANDB_APIKEY = UserSecretsClient().get_secret(secret_label)\n\nROOT_PATH = '/kaggle/input/mini-brain3d-dataset/not_skull_stripped'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.022004Z","iopub.execute_input":"2025-06-03T05:37:19.022443Z","iopub.status.idle":"2025-06-03T05:37:19.302491Z","shell.execute_reply.started":"2025-06-03T05:37:19.022415Z","shell.execute_reply":"2025-06-03T05:37:19.301917Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class MRIDataset(Dataset) :\n\n    def __init__(self, root_dir: str, label_path: str = None, transform = None, label_df: pd.DataFrame = None, is_3d: bool = False):\n        self.root_dir = Path(root_dir)\n        self.transform = transform\n        self.is_3d = is_3d\n        if label_df is None:\n          self.labels_df = pd.read_csv(label_path)\n          \n        else :\n          self.labels_df = label_df\n\n        self.labels_df['subject_id'] = self.labels_df['subject_id'].astype(str)\n        self.labels_df = self.labels_df[self.labels_df['subject_dx'] == 'control']\n\n        all_nii_files = list(self.root_dir.rglob(\"*.nii\"))\n        fail_paths = [\"sub-BrainAge005600/anat/sub-BrainAge005600_T1w.nii/sub-BrainAge005600_T1w.nii\"]\n        self.file_paths = [fp for fp in all_nii_files if fp.is_file() and fp.name not in fail_paths ]\n\n        valid_subjects = set(self.labels_df['subject_id'].values)\n\n        self.file_paths = [fp for fp in self.file_paths if any(vs in str(fp) for vs in valid_subjects)]\n        self.file_paths.sort()\n\n\n\n    def __len__(self):\n        return len(self.file_paths)\n\n\n    def preprocessing_datapoint(self, img_data):\n\n        mid_x = img_data.shape[0] // 2\n        mid_y = img_data.shape[1] // 2\n        mid_z = img_data.shape[2] // 2\n\n        axial_slice = img_data[:, :, mid_z]\n        coronal_slice = img_data[:, mid_y, :]\n        sagittal_slice = img_data[mid_x, :, :]\n\n\n        combined_data = np.stack([axial_slice, coronal_slice, sagittal_slice], axis=0)\n        combined_data = torch.from_numpy(combined_data).float()\n\n        if self.transform : combined_data = self.transform(combined_data)\n\n        return combined_data\n\n\n\n\n    def __getitem__(self, idx):\n        img_path = self.file_paths[idx]\n        file_path_str = str(img_path)\n\n        subject_id = None\n        valid_subjects_set = set(self.labels_df['subject_id'].values)\n\n\n        for sid in valid_subjects_set:\n            if sid in file_path_str:\n                subject_id = sid\n                break\n\n        if subject_id is None:\n            raise ValueError(f\"Không tìm thấy subject_id cho file: {img_path}\")\n\n        metadata = self.labels_df.loc[self.labels_df['subject_id'] == subject_id].iloc[0].to_dict()\n\n        img_data = nib.load(img_path).get_fdata()\n\n        img_data = torch.from_numpy(img_data).unsqueeze(0).float()\n\n        label = 0\n        if metadata['subject_sex'] == 'm' : label = 1\n\n        if not self.is_3d:\n            img_data = self.preprocessing_datapoint(img_data)\n\n        return img_data,  label\n\n\n\ndef visualize_sample(dataset, idx):\n    mri_data, label = dataset[idx]\n    title = f\"Label: {label}\\n\"\n    plt.close('all')\n    fig = plt.figure(figsize = (18, 6))\n\n    if isinstance(mri_data, torch.Tensor):\n        data = mri_data.squeeze().numpy()\n    else:\n        data = mri_data\n\n\n    ax1 = fig.add_subplot(1, 3, 1)\n    plt.imshow(data[0, :, :].T, cmap='gray', origin='lower')\n\n    ax2 = fig.add_subplot(1, 3, 2)\n    ax2.imshow(data[1, :, :].T, cmap='gray', origin='lower')\n\n    ax3 = fig.add_subplot(1, 3, 3)\n    ax3.imshow(data[2, :, :].T, cmap='gray', origin='lower')\n\n    plt.suptitle(title)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.303200Z","iopub.execute_input":"2025-06-03T05:37:19.303396Z","iopub.status.idle":"2025-06-03T05:37:19.413910Z","shell.execute_reply.started":"2025-06-03T05:37:19.303379Z","shell.execute_reply":"2025-06-03T05:37:19.413349Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Data splitting","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split \n\ndef preprocessing_labels(df: pd.DataFrame, root_dir: str = ROOT_PATH):\n    subject_list = []\n    for root, dirs, files in os.walk(root_dir):\n      for dir_name in dirs:\n        if dir_name.startswith(\"sub-BrainAge\"):\n            subject_list.append(dir_name)\n\n    return df[df['subject_id'].isin(subject_list)]\n\n\ndef prepare_data(data: pd.DataFrame):\n    df = data.copy()\n    df['age_group'] = pd.qcut(df['subject_age'], q = min(5, len(df)), labels = False)\n    df['key'] = df.apply(lambda row : f\"{row['age_group']}_{row['subject_sex']}\", axis = 1)\n    return df\n\n\ndef sampling_data(data, size, random_state ):\n  samples = data.groupby('key', group_keys = False)\n  samples = samples.apply(lambda x: x.sample(\n      n = min(int(size / len(data['key'].unique())), len(x)),\n      replace = len(x) < int(size / len(data['key'].unique())),\n      random_state =  random_state\n  ), include_groups=False)\n\n\n  if len(samples) < size:\n    additional_samples = data.drop(samples.index).sample(\n        n = min(size - len(samples), len(data) - len(samples)),\n        replace = True,\n        random_state = random_state\n    )\n\n    samples = pd.concat([samples, additional_samples])\n  return samples\n\n\ndef create_train_test(sample_labels: list, val_ratio: float = 0.2, root_dir: str = ROOT_PATH, is_3d: bool = False):\n    \n  client_datasets = []\n  for label_df in sample_labels:\n    dataset = MRIDataset(root_dir=root_dir, label_df = label_df, is_3d = is_3d)\n    \n    train_dataset, val_dataset = random_split(dataset, [1 - val_ratio, val_ratio])\n    client_datasets.append((train_dataset, val_dataset))\n  return client_datasets\n    \n\ndef distributed_data_to_clients(data: pd.DataFrame, num_clients: int, overlap_ratio: float):\n\n  df = prepare_data(data)\n\n  n_samples = len(df)\n  samples_per_client = int(n_samples / (num_clients * (1 - overlap_ratio) + overlap_ratio))\n\n  client_datasets = []\n  selected_samples = {}\n\n  # Tạo các client datasets với sự phân bố cân bằng\n  for client_idx in range(num_clients):\n\n      if client_idx == 0:\n          client_data = df.sample(n=samples_per_client, random_state=42+client_idx)\n      else:\n          # overlap size\n          overlap_size = int(samples_per_client * overlap_ratio)\n          non_overlap_size = samples_per_client - overlap_size\n\n          # building overlap\n          all_previous_samples = pd.DataFrame()\n          for prev_client_idx in range(client_idx):\n              all_previous_samples = pd.concat([all_previous_samples, selected_samples[prev_client_idx]])\n\n          # sampling\n          if len(all_previous_samples) > 0:\n              overlap_samples = sampling_data(all_previous_samples, overlap_size, client_idx * 100 + 42)\n          else:\n              overlap_samples = pd.DataFrame(columns=df.columns)\n\n          # Lấy mẫu mới (không overlap)\n          remaining_indices = df.index.difference(all_previous_samples.index)\n          if len(remaining_indices) > 0:\n              remaining_df = df.loc[remaining_indices]\n              non_overlap_samples = sampling_data(remaining_df, non_overlap_size, client_idx * 100 + 42)\n          else:\n\n              non_overlap_samples = df.sample(n=non_overlap_size, replace=True, random_state=42+client_idx*300)\n\n\n          client_data = pd.concat([overlap_samples, non_overlap_samples])\n\n\n      selected_samples[client_idx] = client_data\n      client_datasets.append(client_data.drop(['age_group', 'key'], axis=1))\n\n  return client_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.414747Z","iopub.execute_input":"2025-06-03T05:37:19.414964Z","iopub.status.idle":"2025-06-03T05:37:19.428037Z","shell.execute_reply.started":"2025-06-03T05:37:19.414948Z","shell.execute_reply":"2025-06-03T05:37:19.427529Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def iid_client_split(dataset, num_client = 3,  val_ratio = 0.2):\n\n    client_datasets = []\n    sample_per_client = len(dataset) // num_client\n\n\n    for i in range(num_client):\n        start_idx = i * sample_per_client\n        end_idx = (i + 1) * sample_per_client if i < num_client - 1 else len(dataset)\n        indecies = list(range(start_idx, end_idx))\n\n        client_dataset = torch.utils.data.Subset(dataset, indecies)\n        train_dataset, val_dataset = random_split(client_dataset, [1 - val_ratio, val_ratio])\n\n        client_datasets.append((train_dataset, val_dataset))\n    return client_datasets\n\n\ndef same_distribution_client_split(dataset, num_client, val_ratio = 0.2, overlap_ratio = 0.2, root_dir = ROOT_PATH, is_3d = False):\n    \"\"\"\n    Split the dataset into clients with the same distribution of labels.\n    \"\"\"\n    labels_df = dataset.labels_df\n    labels_df = preprocessing_labels(labels_df, root_dir = root_dir)    \n    labels_df = prepare_data(labels_df)\n\n    client_datasets = distributed_data_to_clients(labels_df, num_clients=num_client, overlap_ratio=overlap_ratio)\n\n    client_datasets = create_train_test(client_datasets, val_ratio=val_ratio, root_dir=root_dir, is_3d = is_3d)\n\n    return client_datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.428817Z","iopub.execute_input":"2025-06-03T05:37:19.429156Z","iopub.status.idle":"2025-06-03T05:37:19.443917Z","shell.execute_reply.started":"2025-06-03T05:37:19.429132Z","shell.execute_reply":"2025-06-03T05:37:19.443319Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"#  Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn \nimport torch.nn.functional as F\nfrom collections import OrderedDict\nfrom torchsummary import summary\n\nclass _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super().__init__()\n        self.add_module('norm1', nn.BatchNorm3d(num_input_features))\n        self.add_module('relu1', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv1',\n            nn.Conv3d(num_input_features,\n                      bn_size * growth_rate,\n                      kernel_size=1,\n                      stride=1,\n                      bias=False))\n        self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate))\n        self.add_module('relu2', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv2',\n            nn.Conv3d(bn_size * growth_rate,\n                      growth_rate,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1,\n                      bias=False))\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super().forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features,\n                                     p=self.drop_rate,\n                                     training=self.training)\n        return torch.cat([x, new_features], 1)\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super().__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features + i * growth_rate,\n                                growth_rate, bn_size, drop_rate)\n            self.add_module('denselayer{}'.format(i + 1), layer)\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super().__init__()\n        self.add_module('norm', nn.BatchNorm3d(num_input_features))\n        self.add_module('relu', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv',\n            nn.Conv3d(num_input_features,\n                      num_output_features,\n                      kernel_size=1,\n                      stride=1,\n                      bias=False))\n        self.add_module('pool', nn.AvgPool3d(kernel_size=2, stride=2))\n\nclass DenseNet(nn.Module):\n    def __init__(self,\n                 n_input_channels=1,\n                 conv1_t_size=7,\n                 conv1_t_stride=1,\n                 no_max_pool=False,\n                 growth_rate=16,\n                 block_config=(4, 8, 16, 12),\n                 num_init_features=32,\n                 bn_size=4,\n                 drop_rate=0,\n                 num_classes=2):\n        super().__init__()\n\n        # First convolution\n        self.features = [('conv1',\n                          nn.Conv3d(n_input_channels,\n                                    num_init_features,\n                                    kernel_size=(conv1_t_size, 7, 7),\n                                    stride=(conv1_t_stride, 2, 2),\n                                    padding=(conv1_t_size // 2, 3, 3),\n                                    bias=False)),\n                         ('norm1', nn.BatchNorm3d(num_init_features)),\n                         ('relu1', nn.ReLU(inplace=True))]\n        if not no_max_pool:\n            self.features.append(\n                ('pool1', nn.MaxPool3d(kernel_size=3, stride=2, padding=1)))\n        self.features = nn.Sequential(OrderedDict(self.features))\n\n        # Each denseblock\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            block = _DenseBlock(num_layers=num_layers,\n                                num_input_features=num_features,\n                                bn_size=bn_size,\n                                growth_rate=growth_rate,\n                                drop_rate=drop_rate)\n            self.features.add_module('denseblock{}'.format(i + 1), block)\n            num_features = num_features + num_layers * growth_rate\n            if i != len(block_config) - 1:\n                trans = _Transition(num_input_features=num_features,\n                                    num_output_features=num_features // 2)\n                self.features.add_module('transition{}'.format(i + 1), trans)\n                num_features = num_features // 2\n\n        # Final batch norm\n        self.features.add_module('norm5', nn.BatchNorm3d(num_features))\n\n        # Linear layer\n        self.classifier = nn.Linear(num_features, num_classes)\n\n        # Khởi tạo trọng số\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm3d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        features = self.features(x)\n        out = F.relu(features, inplace=True)\n        out = F.adaptive_avg_pool3d(out, output_size=(1, 1, 1)).view(features.size(0), -1)\n        logits = self.classifier(out)\n        return out, logits\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.446192Z","iopub.execute_input":"2025-06-03T05:37:19.446410Z","iopub.status.idle":"2025-06-03T05:37:19.468663Z","shell.execute_reply.started":"2025-06-03T05:37:19.446395Z","shell.execute_reply":"2025-06-03T05:37:19.468166Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Relaxed Balanced Softmax & feature augmentation","metadata":{}},{"cell_type":"code","source":"class RelaxedBSM(nn.Module):\n    def __init__(self, dataloader, num_classes, eps=0.01, device=None):\n        super(RelaxedBSM, self).__init__()\n        self.num_classes = num_classes\n        self.dataloader = dataloader\n        self.eps = eps\n        \n        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n        self._cached_prior = None\n        self.to(self.device)\n\n    def prior_y(self, recalculate=False):\n        if self._cached_prior is not None and not recalculate:\n            return self._cached_prior\n            \n        py = torch.zeros(self.num_classes, device=self.device)\n        total_samples = 0\n        with torch.no_grad():\n            for _, labels in self.dataloader:\n                labels = labels.to(self.device)\n\n                if not labels.dtype.is_floating_point:\n                    bin_counts = torch.bincount(labels, minlength=self.num_classes).float()\n                else:\n                    bin_counts = labels.sum(dim=0) if labels.dim() > 1 \\\n                    else torch.zeros(self.num_classes, device=self.device).scatter_add_(0, labels.long(), torch.ones_like(labels, device=self.device))\n\n                py += bin_counts\n                total_samples += labels.size(0)\n        self._cached_prior = py / total_samples if total_samples > 0 else torch.ones(self.num_classes, device=self.device) / self.num_classes\n        return self._cached_prior\n\n    def smooth_distribution(self, py):\n        \"\"\"Apply smoothing to a probability distribution\"\"\"\n        py_smooth = (1 - self.eps) * py + self.eps / self.num_classes\n        return py_smooth / py_smooth.sum()\n\n    def prior_y_batch(self, labels):\n        labels = labels.to(self.device)\n        py = torch.bincount(labels, minlength=self.num_classes).float()\n        return py / labels.size(0)\n\n    def bsm1(self, logit):\n        py = self.prior_y()\n        py_smooth = self.smooth_distribution(py)\n\n        logit = logit - logit.max(dim=1, keepdim=True)[0]\n        exp_logits = torch.exp(logit)\n        \n        pc_exp = exp_logits * py_smooth.unsqueeze(0)\n        denominator = pc_exp.sum(dim=1, keepdim=True) + 1e-8\n        \n        return pc_exp / denominator\n\n    def bsm2(self, logit, py):\n        \"\"\"Balanced Softmax with provided class distribution\"\"\"\n        py = py.to(self.device)\n        py_smooth = self.smooth_distribution(py)\n        \n        logit = logit - logit.max(dim=1, keepdim=True)[0]\n        exp_logits = torch.exp(logit)\n        \n        pc_exp = exp_logits * py_smooth.unsqueeze(0)\n        denominator = pc_exp.sum(dim=1, keepdim=True) + 1e-8\n        \n        return pc_exp / denominato\n    \n    def forward(self, logit, py=None):\n        \"\"\"Forward method for nn.Module compatibility\"\"\"\n        if py is None:\n            return self.bsm1(logit)\n        else:\n            return self.bsm2(logit, py)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.469418Z","iopub.execute_input":"2025-06-03T05:37:19.469672Z","iopub.status.idle":"2025-06-03T05:37:19.484045Z","shell.execute_reply.started":"2025-06-03T05:37:19.469649Z","shell.execute_reply":"2025-06-03T05:37:19.483412Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def get_prototypes(model, dataloader, num_classes, device=None):\n    model.eval()\n    prototypes = [[] for _ in range(num_classes)]\n    with torch.no_grad():\n        for im, labels in dataloader:\n            im = im.to(device, non_blocking = True)\n            labels = labels.to(device, non_blocking = True)\n            model = model.to(device)\n            features, _ = model(im)\n            for i, label in enumerate(labels):\n                prototypes[label.item()].append(features[i])\n                \n    class_prototypes = torch.zeros((num_classes, features.shape[1]), device = device)\n    for c in range(num_classes):\n        if prototypes[c]:\n            # average over all feature vectors from the same class\n            class_prototypes[c] = torch.stack(prototypes[c]).mean(dim = 0)\n        else:\n            class_prototypes[c] = torch.zeros(features.shape[1], device = device) # pseudo-prototypes for missing class in dataloader\n            \n    return class_prototypes # [num_classes, feature_vectors]\n\ndef feature_augmentation(features, labels, prototypes, num_classes, lam=1.0, device=None):\n    \"\"\"Perform feature augmentation by transferring intra-class variance to missing classes.\"\"\"\n    aug_features = []\n    aug_labels = []\n    for i in range(len(labels)):\n        src_class = labels[i].item()\n        # Cycle through classes for augmentation\n        tgt_class = (src_class + 1) % num_classes\n        if torch.all(prototypes[tgt_class] == 0):\n            continue\n        # Compute augmented feature: \\tilde{h}_{j,k} = p_j + \\lambda (h_{i,k} - p_i)\n        aug_feature = prototypes[tgt_class].to(device) + lam * (features[i] - prototypes[src_class].to(device))\n        aug_features.append(aug_feature)\n        aug_labels.append(tgt_class)\n    \n    if aug_features:\n        aug_features = torch.stack(aug_features)\n        aug_labels = torch.tensor(aug_labels, dtype=torch.long, device=features.device)\n        return aug_features, aug_labels\n    else:\n        return None, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.484646Z","iopub.execute_input":"2025-06-03T05:37:19.484838Z","iopub.status.idle":"2025-06-03T05:37:19.500349Z","shell.execute_reply.started":"2025-06-03T05:37:19.484824Z","shell.execute_reply":"2025-06-03T05:37:19.499691Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Lightning module","metadata":{}},{"cell_type":"code","source":"import lightning as pl\nfrom torchmetrics import Accuracy, F1Score, Precision, Recall, MeanMetric\nimport torch.optim as optim \n\n\nclass DenseNetModule(pl.LightningModule):\n    def __init__(self, net, rbsm=None, global_prototypes=None, learning_rate=1e-3, weight_decay = 1e-2, batch_size = 32, lam=1, mu=0.1):\n        super().__init__()\n        self.model = net\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.batch_size = batch_size\n        if global_prototypes:\n            self.global_prototypes = global_prototypes\n        else:\n            self.global_prototypes = [torch.zeros(364) for _ in range(2)]\n        self.lam = lam\n        self.mu = mu\n        \n        # how confidence model is in it prediction\n        # tức model có thể rất tự tin trong quyết định nhưng thực tế lại sai\n        # BCE = y*log(y_pred) + (1 - y)*log(1 - y_pred)\n        self.criterion = nn.CrossEntropyLoss()\n        self.nll_loss = nn.NLLLoss()\n        self.rbsm = rbsm\n        \n        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        features, logits = self(x)\n        \n        balanced_probs = self.rbsm(logits)\n        loglikelihood = torch.log(balanced_probs + 1e-8)\n        loss0 = self.nll_loss(loglikelihood, y)\n        loss1 = 0.0\n        aug_features, aug_labels = feature_augmentation(features, y, self.global_prototypes, 2, self.lam, self.device)\n        if aug_features is not None: \n            aug_logits = self.model.classifier(aug_features)\n            aug_probs = self.rbsm(aug_logits)\n            aug_loglikelihood = torch.log(aug_probs + 1e-8)\n            loss1 = self.nll_loss(aug_loglikelihood, aug_labels)\n\n        loss = loss0 + self.mu * loss1\n        acc = self.train_accuracy(torch.argmax(logits, dim=1), y)\n\n        self.log('train/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('train/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        _, logits = self(x)\n        \n        loss = self.criterion(logits, y)\n        acc = self.val_accuracy(torch.argmax(logits, dim=1), y)\n        \n        self.log('val/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        _, logits = self(x)\n        \n        loss = self.criterion(logits, y)\n        acc = self.test_accuracy(torch.argmax(logits, dim=1), y)\n\n        self.log('test/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        return loss\n            \n    def configure_optimizers(self):\n        optimizer =  torch.optim.SGD(self.parameters(), lr=self.learning_rate, weight_decay = self.weight_decay)\n        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n\n        return {\n           \"optimizer\": optimizer,\n           \"lr_scheduler\": {\n               \"scheduler\": scheduler,\n               \"monitor\": \"val_loss\",\n           },\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:19.501117Z","iopub.execute_input":"2025-06-03T05:37:19.501558Z","iopub.status.idle":"2025-06-03T05:37:27.801116Z","shell.execute_reply.started":"2025-06-03T05:37:19.501539Z","shell.execute_reply":"2025-06-03T05:37:27.800510Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Client","metadata":{}},{"cell_type":"code","source":"from collections import OrderedDict\nfrom flwr.client import NumPyClient\nfrom flwr.common import  Context\nfrom torch.utils.data import DataLoader\nimport logging \nimport warnings \nfrom lightning.pytorch.loggers.wandb import WandbLogger\nfrom lightning.pytorch.callbacks import ModelCheckpoint\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:27.801799Z","iopub.execute_input":"2025-06-03T05:37:27.802211Z","iopub.status.idle":"2025-06-03T05:37:40.060423Z","shell.execute_reply.started":"2025-06-03T05:37:27.802193Z","shell.execute_reply":"2025-06-03T05:37:40.059665Z"}},"outputs":[{"name":"stderr","text":"2025-06-03 05:37:29.602755: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748929049.781159      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748929049.835146      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class FlowerLightningClient(NumPyClient):\n\n    def __init__(self, model: pl.LightningModule, train_dataloader, val_dataloader, epochs, batch_size, device, client_id): \n        self.train_dataloader = train_dataloader\n        self.val_dataloader = val_dataloader\n        self.epochs = epochs\n        self.device = device \n        self.client_id = client_id\n        self.model = model\n        self.batch_size = batch_size\n\n\n    def get_parameters(self, config):\n        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        if not parameters:\n            return\n    \n        params_dict = zip(self.model.state_dict().keys(), parameters)\n        state_dict = OrderedDict((k, torch.tensor(v)) for k, v in params_dict)\n    \n        if state_dict:\n            self.model.load_state_dict(state_dict, strict=False)\n\n        self.model = self.model.to(self.device)\n\n        \n    def fit(self, parameters, config):\n\n        self.set_parameters(parameters)\n        \n        checkpoint_callback = ModelCheckpoint(\n            dirpath=f\"./checkpoints/client_{self.client_id}\",\n            filename=f\"round_{config.get('round_num', 0)}\" + \"-{epoch:02d}\",\n            save_top_k=1,\n            monitor=\"val/loss\",\n            mode=\"min\"\n        )\n\n        trainer = pl.Trainer(\n            max_epochs=self.epochs,\n            accelerator=\"auto\",\n            devices=1,\n            callbacks=[checkpoint_callback],\n            enable_progress_bar=False, \n            log_every_n_steps=1\n        )\n        \n        global_prototypes = pickle.loads(config['global_prototypes'])\n        self.model.global_prototypes = global_prototypes\n        rbsm = RelaxedBSM(self.train_dataloader, num_classes=2, device=self.device)\n        self.model.rbsm = rbsm.to(self.device)\n        self.model.model = self.model.model.to(self.device)\n        trainer.fit(self.model.to(self.device), train_dataloaders=self.train_dataloader, val_dataloaders=self.val_dataloader)\n        local_prototypes = get_prototypes(self.model, self.train_dataloader, 2, self.device)\n        \n        callback_metrics = trainer.callback_metrics\n\n        train_loss = callback_metrics.get(\"train/loss\", 0)\n        train_accuracy = callback_metrics.get(\"train/acc\", 0)\n        val_loss = callback_metrics.get(\"val/loss\", 0)\n        val_accuracy = callback_metrics.get(\"val/acc\", 0)\n    \n        # Calculate label counts\n        from collections import Counter\n        label_counts = Counter()\n        for _, label in self.train_dataloader.dataset:\n            if isinstance(label, torch.Tensor):\n                label = label.item()\n            label_counts[label] += 1\n            \n        metrics = {\n            \"train_loss\": train_loss.item() if isinstance(train_loss, torch.Tensor) else float(train_loss),\n            \"train_accuracy\": train_accuracy.item() if isinstance(train_accuracy, torch.Tensor) else float(train_accuracy),\n            \"val_loss\": val_loss.item() if isinstance(val_loss, torch.Tensor) else float(val_loss),\n            \"val_accuracy\": val_accuracy.item() if isinstance(val_accuracy, torch.Tensor) else float(val_accuracy),\n            \"local_prototypes\": pickle.dumps(local_prototypes),\n            \"label_counts\": pickle.dumps(label_counts)\n        }\n\n        return self.get_parameters(config={}), len(self.train_dataloader.dataset), metrics\n\n\n    def evaluate(self, parameters, config):\n\n        self.set_parameters(parameters)\n\n        trainer = pl.Trainer(\n            accelerator=\"auto\",\n            devices=1 ,\n            enable_progress_bar=False\n        )\n\n        results = trainer.test(self.model, dataloaders=self.val_dataloader)\n        \n        callback_metrics = trainer.callback_metrics\n\n        test_loss = callback_metrics.get(\"test/loss\")\n        test_accuracy = callback_metrics.get(\"test/acc\")\n        \n        # Additional metrics\n        metrics = {\n            \"test_loss\": test_loss.item() if isinstance(test_loss, torch.Tensor) else float(test_loss),\n            \"test_accuracy\": test_accuracy.item() if isinstance(test_accuracy, torch.Tensor) else float(test_accuracy),\n        }\n        return float(test_loss), len(self.val_dataloader.dataset), metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:40.061270Z","iopub.execute_input":"2025-06-03T05:37:40.061555Z","iopub.status.idle":"2025-06-03T05:37:40.074922Z","shell.execute_reply.started":"2025-06-03T05:37:40.061530Z","shell.execute_reply":"2025-06-03T05:37:40.074229Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def create_lightning_client_fn(device, epochs, client_datasets, batch_size, num_workers, pl_model):\n\n    def client_fn(context: Context):\n        \n        client_id = context.node_config['partition-id']\n        train_dataset, val_dataset = client_datasets[client_id]\n\n        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = num_workers)\n        val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n\n        return FlowerLightningClient(pl_model, train_dataloader, val_dataloader, epochs, batch_size, device, client_id).to_client()\n\n    return client_fn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:40.075748Z","iopub.execute_input":"2025-06-03T05:37:40.075955Z","iopub.status.idle":"2025-06-03T05:37:41.351055Z","shell.execute_reply.started":"2025-06-03T05:37:40.075940Z","shell.execute_reply":"2025-06-03T05:37:41.350360Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import random\nimport flwr as fl\nfrom flwr.common import (\n    EvaluateRes,\n    FitIns,\n    FitRes,\n    Parameters,\n    EvaluateIns,\n)\nfrom flwr.server.client_proxy import ClientProxy\nfrom flwr.server.client_manager import ClientManager\nfrom flwr.server.strategy import FedAvg\nfrom flwr.common.parameter import parameters_to_ndarrays","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:41.351926Z","iopub.execute_input":"2025-06-03T05:37:41.352221Z","iopub.status.idle":"2025-06-03T05:37:41.368110Z","shell.execute_reply.started":"2025-06-03T05:37:41.352187Z","shell.execute_reply":"2025-06-03T05:37:41.367445Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from flwr.common import ndarrays_to_parameters\n\ndef get_parameters(model) -> List[np.ndarray]:\n    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n    \nclass DropoutFedAvg(FedAvg):\n    \"\"\"FedAvg strategy with client dropout simulation and metrics tracking.\"\"\"\n\n    def __init__( self, net, dropout_rate_training: float = 0.3, dropout_rate_eval: float = 0.3, fixed_clients: Optional[List[int]] = None, dropout_pattern_train: str = \"random\", dropout_pattern_eval: str = \"random\", **kwargs):\n    \n        if \"fit_metrics_aggregation_fn\" not in kwargs:\n            kwargs[\"fit_metrics_aggregation_fn\"] = self.weighted_average\n        if \"evaluate_metrics_aggregation_fn\" not in kwargs:\n            kwargs[\"evaluate_metrics_aggregation_fn\"] = self.weighted_average\n\n        super().__init__(**kwargs)\n        self.dropout_rate_training = dropout_rate_training\n        self.dropout_rate_eval = dropout_rate_eval\n        self.fixed_clients = fixed_clients or []\n        self.dropout_pattern_train = dropout_pattern_train\n        self.dropout_pattern_eval = dropout_pattern_eval\n        self.current_round = 0\n        self.dropped_clients_history_training: Dict[int, List[int]] = {}\n        self.dropped_clients_history_evaluation: Dict[int, List[int]] = {}\n\n        # For tracking metrics\n        self.fit_metrics_history: List[Dict[str, float]] = []\n        self.eval_metrics_history: List[Dict[str, float]] = []\n\n        self.net = net\n        self.global_prototypes = [torch.zeros(364) for _ in range(2)] # create pseudo-global prototypes\n    \n    def weighted_average(self, metrics: List[Tuple[int, Dict]]) -> Dict:\n        \"\"\"Aggregate metrics using weighted average based on number of samples.\"\"\"\n        if not metrics:\n            return {}\n\n        total_examples = sum([num_examples for num_examples, _ in metrics])\n        weighted_metrics = {}\n\n        for metric_key in [\"train_loss\", \"train_accuracy\", \"val_loss\", \"val_accuracy\", \"test_accuracy\", \"test_loss\"]:\n            values = [\n                metric_dict[metric_key] * num_examples\n                for num_examples, metric_dict in metrics\n                if metric_key in metric_dict and isinstance(metric_dict[metric_key], (int, float))\n            ]\n            if values:\n                weighted_sum = sum(values)\n                weighted_metrics[metric_key] = weighted_sum / total_examples if total_examples > 0 else 0\n\n        return weighted_metrics\n\n\n    def configure_fit( self, server_round: int, parameters: Parameters, client_manager: ClientManager) -> List[Tuple[ClientProxy, FitIns]]:\n        \"\"\"Configure the next round of training with client dropout.\"\"\"\n        self.current_round = server_round\n\n    \n        client_fit_instructions = super().configure_fit(\n            server_round, parameters, client_manager, \n        )\n\n        if not client_fit_instructions:\n            return []\n\n\n        available_clients = self._apply_dropout(client_fit_instructions, dropout_rate=self.dropout_rate_training, dropout_pattern=self.dropout_pattern_train)\n\n        # Save dropout history for this round\n        client_ids = [int(client.cid) for client, _ in client_fit_instructions]\n        available_client_ids = [int(client.cid) for client, _ in available_clients]\n        dropped_clients = [cid for cid in client_ids if cid not in available_client_ids]\n        self.dropped_clients_history_training[server_round] = dropped_clients\n\n        print(f\"Round {server_round}: {len(dropped_clients)} clients dropped out of {len(client_ids)} during training\")\n        print(f\"Dropped client IDs: {dropped_clients}\")\n\n        # send global prototypes to clients\n        updated_clients = []\n        for client, fit_ins in available_clients:\n            custom_config = dict(fit_ins.config)\n            custom_config['global_prototypes'] = pickle.dumps(self.global_prototypes)\n            new_fit_ins = FitIns(parameters=fit_ins.parameters, config=custom_config)\n            updated_clients.append((client, new_fit_ins))\n            \n        return updated_clients\n    \n    def configure_evaluate( self, server_round: int, parameters: Parameters, client_manager: ClientManager) -> List[Tuple[ClientProxy, EvaluateIns]]:\n        self.current_round = server_round\n\n        client_evaluate_instructions = super().configure_evaluate(\n            server_round, parameters, client_manager\n        )\n\n        if not client_evaluate_instructions: return []\n\n        available_clients = self._apply_dropout(client_evaluate_instructions, dropout_rate=self.dropout_rate_eval, dropout_pattern=self.dropout_pattern_eval)\n\n        client_ids = [int(client.cid) for client, _ in client_evaluate_instructions]\n        available_client_ids = [int(client.cid) for client, _ in available_clients]\n        dropped_clients = [cid for cid in client_ids if cid not in available_client_ids]\n\n        self.dropped_clients_history_evaluation[server_round] = dropped_clients\n        \n\n        print(f\"Round {server_round}: {len(dropped_clients)} clients dropped out of {len(client_ids)} during evaluation\")\n        print(f\"Dropped client IDs: {dropped_clients}\")\n\n        return available_clients\n\n\n    def _apply_dropout(self, client_instructions: List[Tuple[ClientProxy, Union[FitIns, EvaluateIns ]]], dropout_pattern: str, dropout_rate: 0.3) -> List[Tuple[ClientProxy, FitIns]]:\n        \"\"\"Apply dropout to clients based on the specified pattern.\"\"\"\n        if len(client_instructions) == 0:\n            return []\n\n        # Get all client IDs\n        all_clients = [(client, ins) for client, ins in client_instructions]\n        all_client_ids = [int(client.cid) for client, _ in all_clients]\n\n        # Determine which clients will drop out\n        dropout_mask = [False] * len(all_clients)\n\n        if dropout_pattern == \"random\":\n           \n            for i, cid in enumerate(all_client_ids):\n                \n                if cid in self.fixed_clients:\n                    continue\n            \n                if random.random() < dropout_rate:\n                    dropout_mask[i] = True\n\n        elif dropout_pattern == \"alternate\":\n         \n            if self.current_round % 2 == 1:  \n                for i, cid in enumerate(all_client_ids):\n                    if cid not in self.fixed_clients:\n                        dropout_mask[i] = True\n\n        elif dropout_pattern == \"fixed\":\n      \n            n_dropout = int(len(all_clients) * dropout_rate)\n            for i in range(n_dropout):\n                if all_client_ids[i] not in self.fixed_clients:\n                    dropout_mask[i] = True\n\n        \n        available_clients = [\n            (client, ins) for i, (client, ins) in enumerate(all_clients)\n            if not dropout_mask[i]\n        ]\n\n        return available_clients\n\n    def l2dist(self, p1, p2):\n        return np.linalg.norm(p1 - p2)\n    \n    def weighted_average_oracle(self, points, weights):\n        tot_weights = np.sum(weights)\n        weighted_updates = np.zeros_like(points[0])\n        for w, p in zip(weights, points):\n            weighted_updates += (w / tot_weights) * p\n        return weighted_updates\n    \n    def geometric_median_objective(self, median, points, alphas):\n        return sum([alpha * self.l2dist(median, p) for alpha, p in zip(alphas, points)])\n    \n    def geometric_median_update(self, points, alphas, maxiter=4, eps=1e-5, ftol=1e-6, verbose=False):\n        alphas = np.asarray(alphas, dtype=points[0].dtype) / sum(alphas)\n        median = self.weighted_average_oracle(points, alphas)\n        for _ in range(maxiter):\n            weights = np.asarray([\n                alpha / max(eps, self.l2dist(median, p)) for alpha, p in zip(alphas, points)\n            ], dtype=alphas.dtype)\n            weights /= weights.sum()\n            new_median = self.weighted_average_oracle(points, weights)\n            if abs(self.geometric_median_objective(median, points, alphas) - self.geometric_median_objective(new_median, points, alphas)) < ftol:\n                break\n            median = new_median\n        return median\n\n    def aggregation(self, weights_results, type_aggregation):\n        if type_aggregation == \"mean\":\n            parameters_aggregated = ndarrays_to_parameters(\n                flwr.server.strategy.aggregate.aggregate(weights_results)\n            )\n        elif type_aggregation == \"median\":\n            # get input for RFA\n            update_vectors = [np.concatenate([w.flatten() for w in fl.common.parameters_to_ndarrays(fit_res.parameters)]) for _, fit_res in weights_results]\n            num_examples = [fit_res.num_examples for _, fit_res in weights_results]\n    \n            # aggregation RFA\n            median_vector = self.geometric_median_update(update_vectors, num_examples)\n    \n            parameters = get_parameters(self.net)\n            shapes = [w.shape for w in parameters]\n            sizes = [int(np.prod(s)) for s in shapes]\n            \n            slices = np.split(median_vector, np.cumsum(sizes)[:-1])\n            median_weights = [s.reshape(shape) for s, shape in zip(slices, shapes)]\n            \n            parameters_aggregated = ndarrays_to_parameters(median_weights)\n\n        return parameters_aggregated\n\n    def aggregate_fit(self, server_round: int, results: List[Tuple[ClientProxy, FitRes]], failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]]):\n        \n        aggregated = super().aggregate_fit(server_round, results, failures)\n        # aggregated = self.aggregation(weights_results=results, type_aggregation=\"median\") # params\n\n        # if aggregated is not None:\n        if aggregated and aggregated[0] is not None:\n            aggregated_ndarrays: list[np.ndarray] = fl.common.parameters_to_ndarrays(\n                aggregated[0]\n            )\n\n            params_dict = zip(self.net.state_dict().keys(), aggregated_ndarrays)\n            # aggregated_ndarrays = fl.common.parameters_to_ndarrays(aggregated)\n            # params_dict = zip(self.net.state_dict().keys(), aggregated_ndarrays)\n            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n            self.net.load_state_dict(state_dict, strict=True)\n\n            # Save the model to disk\n            torch.save(self.net.state_dict(), f\"model_round_{server_round}.pth\")\n\n        # aggregated_metrics = {}\n        if results:\n            metrics = [(res.num_examples, res.metrics) for _, res in results]\n            # update global prototypes\n            for _, res in results:\n                label_counts = pickle.loads(res.metrics[\"label_counts\"])\n                local_prototypes = pickle.loads(res.metrics[\"local_prototypes\"])\n                for label in label_counts:\n                    proto = local_prototypes[label].to(\"cpu\")\n                    count = label_counts[label]\n                    self.global_prototypes[label] += (count * proto) / res.num_examples\n                    \n            aggregated_metrics = self.weighted_average(metrics)\n            self.fit_metrics_history.append(aggregated_metrics)\n\n            if wandb.run is not None:\n                wandb.log({\n                    \"train_server_round\": server_round, \n                    \"train_accuracy\": aggregated_metrics.get(\"train_accuracy\", 0.0), \n                    \"train_loss\" : aggregated_metrics.get(\"train_loss\", 0.0)\n                })\n\n            print(f\"Round {server_round} training metrics: {aggregated_metrics}\")\n\n        # return aggregated, aggregated_metrics\n        return aggregated\n\n    def aggregate_evaluate( self, server_round: int, results: List[Tuple[ClientProxy, EvaluateRes]],  failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]):\n        \n        aggregated = super().aggregate_evaluate(server_round, results, failures)\n\n        if results:\n            metrics = [(res.num_examples, res.metrics) for _, res in results]\n            aggregated_metrics = self.weighted_average(metrics)\n            self.eval_metrics_history.append(aggregated_metrics)\n            \n            if wandb.run is not None:\n                wandb.log({\n                    \"eval_server_round\" : server_round,\n                    \"test_accuracy\": aggregated_metrics.get(\"test_accuracy\"), \n                    \"test_loss\" : aggregated_metrics.get(\"test_loss\"), \n                })\n                \n            print(f\"Round {server_round} evaluation metrics: {aggregated_metrics}\")\n\n        return aggregated\n\n    def get_dropout_history(self) -> Dict[int, List[int]]:\n        return self.dropped_clients_history_training, self.dropped_clients_history_evaluation\n\n    def get_metrics_history(self) -> Tuple[List[Dict[str, float]], List[Dict[str, float]]]: \n        return self.fit_metrics_history, self.eval_metrics_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:41.368940Z","iopub.execute_input":"2025-06-03T05:37:41.369395Z","iopub.status.idle":"2025-06-03T05:37:41.399091Z","shell.execute_reply.started":"2025-06-03T05:37:41.369371Z","shell.execute_reply":"2025-06-03T05:37:41.398416Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from flwr.client import ClientApp\nfrom flwr.server import ServerApp\nfrom flwr.simulation import run_simulation\nimport os\nfrom flwr.common import Context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:41.399806Z","iopub.execute_input":"2025-06-03T05:37:41.400127Z","iopub.status.idle":"2025-06-03T05:37:41.413886Z","shell.execute_reply.started":"2025-06-03T05:37:41.400109Z","shell.execute_reply":"2025-06-03T05:37:41.413283Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def run_dropout_experiment(\n    client_fn_creator,\n    pl_model : Union[pl.LightningModule, torch.nn.Module], \n    num_clients: int,\n    num_rounds: int = 5,\n    dropout_rate_training: float = 0.3,\n    dropout_rate_eval: float = 0.3,\n    dropout_pattern_train: str = \"random\",\n    dropout_pattern_eval: str = \"random\",\n    fixed_clients: Optional[List[int]] = None,\n    experiment_name: str = \"dropout_experiment\",\n    save_dir: str = \"model_weights\",\n    num_gpus : int = 0, \n    resource_config : Optional[Dict[str, float]] = None,\n\n):\n    \n    # Configure client app\n    print(f\"\\nStarting experiment: {experiment_name}\")\n    print(f\"Dropout rate training: {dropout_rate_training}, Pattern: {dropout_pattern_train}\")\n    print(f\"Dropout rate evaluation: {dropout_rate_eval}, Pattern: {dropout_pattern_eval   }\")\n    print(f\"Number of GPUs: {num_gpus}\")\n    print(f\"Number of clients: {num_clients}\")\n    print(f\"Number of rounds: {num_rounds}\")\n    print(f\"Fixed clients: {fixed_clients or []}\")\n    # Create strategy with dropout\n    strategy = DropoutFedAvg(\n        net=pl_model.model if isinstance(pl_model, pl.LightningModule) else pl_model,\n        dropout_rate_training=dropout_rate_training,\n        dropout_rate_eval=dropout_rate_eval,\n        dropout_pattern_train=dropout_pattern_train,\n        dropout_pattern_eval=dropout_pattern_eval,\n        fixed_clients=fixed_clients or [],\n        fraction_fit=1.0,\n        fraction_evaluate=1.0,\n        min_fit_clients=1,\n        min_evaluate_clients=1,\n        min_available_clients=1,\n\n    )\n\n    # Configure server with strategy\n    def server_fn(server_context: Context):\n        from flwr.server import ServerAppComponents, ServerConfig\n        config = ServerConfig(num_rounds=num_rounds)\n        return ServerAppComponents(strategy=strategy, config=config)\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    epochs = resource_config.get(\"epochs\", 1) if resource_config else 1\n    client_datasets = resource_config.get(\"client_datasets\", {}) if resource_config else {}\n\n    \n    batch_size = resource_config.get(\"batch_size\", 32) if resource_config else 32\n    learning_rate = resource_config.get(\"learning_rate\", 0.001) if resource_config else 0.001\n    num_workers = resource_config.get(\"num_workers\", 1) if resource_config else 1\n    client_fn = client_fn_creator(device=device, epochs=epochs, client_datasets=client_datasets\n                                , batch_size=batch_size, pl_model=pl_model, num_workers=num_workers)\n    \n    # Create client and server apps\n    client_app = ClientApp(client_fn=client_fn)\n    server_app = ServerApp(server_fn=server_fn)\n\n    # Configure backend\n    backend_config = {\n        \"client_resources\": {\n            \"num_cpus\": 1,\n            \"num_gpus\": num_gpus,\n        }\n    }\n    history = strategy.get_dropout_history()\n    # Run simulation\n    try:\n        run_simulation(\n            client_app=client_app,\n            server_app=server_app,\n            num_supernodes=num_clients,\n            backend_config=backend_config,\n        )\n\n        # Get metrics directly from strategy\n        fit_metrics, eval_metrics = strategy.get_metrics_history()\n\n        # Format metrics for plotting\n        rounds = list(range(1, len(eval_metrics) + 1))\n\n        train_accuracy_values = [metrics.get(\"train_accuracy\", 0.0) for metrics in fit_metrics]\n        train_loss_values = [metrics.get(\"train_loss\", 0.0) for metrics in fit_metrics]\n        \n\n        test_accuracy_values = [metrics.get(\"test_accuracy\", 0.0) for metrics in eval_metrics]\n        test_loss_values = [metrics.get(\"test_loss\", 0.0) for metrics in eval_metrics]\n\n\n        # cleanup_wandb_loggers()\n        results = {\n            \"rounds\": rounds,\n            \"train_accuracy\": train_accuracy_values,\n            \"train_loss\": train_loss_values,\n            \"test_accuracy\": test_accuracy_values,\n            \"test_loss\": test_loss_values,\n        }\n\n        return results, history\n    \n    except Exception as e:\n        print(f\"Error in dropout experiment: {e}\")\n        import traceback\n        traceback.print_exc()\n        return {\"error\": str(e)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:41.414513Z","iopub.execute_input":"2025-06-03T05:37:41.414708Z","iopub.status.idle":"2025-06-03T05:37:41.429628Z","shell.execute_reply.started":"2025-06-03T05:37:41.414693Z","shell.execute_reply":"2025-06-03T05:37:41.428958Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"import hydra \nfrom omegaconf import DictConfig, OmegaConf\nimport logging \nimport wandb\nimport warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:41.430509Z","iopub.execute_input":"2025-06-03T05:37:41.430743Z","iopub.status.idle":"2025-06-03T05:37:43.904975Z","shell.execute_reply.started":"2025-06-03T05:37:41.430729Z","shell.execute_reply":"2025-06-03T05:37:43.904298Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Config ","metadata":{}},{"cell_type":"code","source":"config = {\n    \"base_path\": \"/kaggle\",\n    \"device\": \"cuda\",  # from train.device\n    \"run_name\": \"dropout_30pct_fixed_train_fixed_eval_0.3_fixed_0.3\",  # resolved using experiment values\n    \"seed\": 42,\n    \"num_clients\": 10,\n    \"num_rounds\": 10,\n    \"gpus\": 1,\n    \"wandb_log\": True,\n    \"train\": {\n        \"batch_size\": 4,\n        \"learning_rate\": 0.001,\n        \"epochs\": 2,\n        \"device\": \"cuda\",\n        \"num_workers\": 2,\n        \"weight_decay\": 0.0001,\n        \"scheduler\": {\n            \"use\": False,\n            \"type\": \"cosine\",\n            \"warmup_epochs\": 5,\n            \"min_lr\": 0.0001,\n        }\n    },\n\n    \"experiment\": {\n        \"pattern_train\": \"fixed\",\n        \"pattern_eval\": \"fixed\",\n        \"dropout_rate_training\": 0.3,\n        \"dropout_rate_eval\": 0.3,\n        \"fixed_clients\": [0, 1, 2],\n        \"name\": \"dropout_30pct_fixed_train_fixed_eval\",\n    },\n\n    \"data\": {\n        # \"root_path\": \"/kaggle/input/mini-brain3d-dataset/not_skull_stripped\",\n        \"root_path\": \"/kaggle/input/mri-dataset/datasetzip/not_skull_stripped\",\n        \"label_path\": \"/kaggle/input/mri-label/label.csv\",\n        \"val_ratio\": 0.2,\n        \"overlap_ratio\": 0.2,\n        \"distribution\": \"same\",\n    },\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:43.905741Z","iopub.execute_input":"2025-06-03T05:37:43.905963Z","iopub.status.idle":"2025-06-03T05:37:43.910979Z","shell.execute_reply.started":"2025-06-03T05:37:43.905946Z","shell.execute_reply":"2025-06-03T05:37:43.910337Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def run_experiment_with_lightning(cfg_dict: dict) -> None:\n    cfg: DictConfig = OmegaConf.create(cfg_dict)  # convert to DictConfig to retain dot-access\n    logger =  logger = logging.getLogger(__name__)\n    logger.info(f\"Running experiment with config: {cfg.experiment.name}\")\n    logger.info(f\"Config: {OmegaConf.to_yaml(cfg)}\")\n\n    if cfg.wandb_log:\n        wandb.init(\n            project=\"sex-classification\",\n            name=f\"{cfg.experiment.name}\",\n            config=OmegaConf.to_container(cfg, resolve=True),\n            group=\"server\"\n        )\n\n    device = cfg.device\n    epochs = cfg.train.epochs\n\n    logger.info(\"Loading model\")\n    net: nn.Module = DenseNet()\n    pl_model: pl.LightningModule = DenseNetModule(net = net)\n\n    logger.info(\"Loading dataset\")\n    is_3d = True if isinstance(pl_model, DenseNetModule) else False\n    print(f\"Is 3D: {is_3d}\")\n\n    full_dataset = MRIDataset(\n        root_dir=cfg.data.root_path,\n        label_path=cfg.data.label_path,\n        is_3d=is_3d\n    )\n\n    logger.info(f\"Dataset loaded successfully with len is {len(full_dataset)}\")\n    logger.info(f\"Splitting dataset into {cfg.num_clients} clients\")\n\n    if cfg.data.distribution == \"iid\":\n        client_datasets = iid_client_split(\n            full_dataset,\n            num_client=cfg.num_clients,\n            val_ratio=cfg.data.val_ratio\n        )\n    elif cfg.data.distribution == \"same\":\n        client_datasets = same_distribution_client_split(\n            full_dataset,\n            num_client=cfg.num_clients,\n            val_ratio=cfg.data.val_ratio,\n            overlap_ratio=cfg.data.overlap_ratio,\n            root_dir=cfg.data.root_path,\n            is_3d=is_3d\n        )\n    else:\n        raise ValueError(f\"Unknown distribution type: {cfg.data.distribution}\")\n\n    logger.info(f\"Client datasets created successfully with {len(client_datasets)} clients\")\n\n    resources = {\n        \"client_datasets\": client_datasets,\n        \"device\": device,\n        \"epochs\": epochs,\n        \"batch_size\": cfg.train.batch_size,\n        \"learning_rate\": cfg.train.learning_rate,\n        \"num_workers\": cfg.train.num_workers\n    }\n\n    logger.info(\"Running experiments with PyTorch Lightning\")\n\n    results, history = run_dropout_experiment(\n        client_fn_creator=create_lightning_client_fn,\n        pl_model=pl_model,\n        num_clients=cfg.num_clients,\n        num_rounds=cfg.num_rounds,\n        dropout_rate_training=cfg.experiment.dropout_rate_training,\n        dropout_rate_eval=cfg.experiment.dropout_rate_eval,\n        dropout_pattern_train=cfg.experiment.pattern_train,\n        dropout_pattern_eval=cfg.experiment.pattern_eval,\n        experiment_name=cfg.experiment.name,\n        num_gpus=cfg.gpus,\n        resource_config=resources\n    )\n\n    logger.info(\"Run successfully + wandb tracking\")\n    print(f\"Result is {results}\")\n\n    if cfg.wandb_log:\n        wandb.finish()\n\n    logger.info(\"Experiments completed successfully\")\n    logger.info(f\"Client Dropout History: {history}\")\n\n    return results, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:43.911674Z","iopub.execute_input":"2025-06-03T05:37:43.911885Z","iopub.status.idle":"2025-06-03T05:37:43.938933Z","shell.execute_reply.started":"2025-06-03T05:37:43.911869Z","shell.execute_reply":"2025-06-03T05:37:43.938321Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"wandb.login(key=WANDB_APIKEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:43.939844Z","iopub.execute_input":"2025-06-03T05:37:43.940124Z","iopub.status.idle":"2025-06-03T05:37:50.694845Z","shell.execute_reply.started":"2025-06-03T05:37:43.940101Z","shell.execute_reply":"2025-06-03T05:37:50.694112Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n  return LooseVersion(v) >= LooseVersion(check)\n/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_bokeh.py:16: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n  import imp  # pylint: disable=deprecated-module\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpage0526\u001b[0m (\u001b[33miai-uet-vnu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"run_experiment_with_lightning(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T05:37:50.697254Z","iopub.execute_input":"2025-06-03T05:37:50.697821Z","iopub.status.idle":"2025-06-03T07:53:51.732942Z","shell.execute_reply.started":"2025-06-03T05:37:50.697802Z","shell.execute_reply":"2025-06-03T07:53:51.732228Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py:259: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n  self.scope.user = {\"email\": email}  # noqa\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250603_053750-088uu6cf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iai-uet-vnu/sex-classification/runs/088uu6cf' target=\"_blank\">dropout_30pct_fixed_train_fixed_eval</a></strong> to <a href='https://wandb.ai/iai-uet-vnu/sex-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iai-uet-vnu/sex-classification' target=\"_blank\">https://wandb.ai/iai-uet-vnu/sex-classification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iai-uet-vnu/sex-classification/runs/088uu6cf' target=\"_blank\">https://wandb.ai/iai-uet-vnu/sex-classification/runs/088uu6cf</a>"},"metadata":{}},{"name":"stdout","text":"Is 3D: True\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [INIT]\n\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n","output_type":"stream"},{"name":"stdout","text":"\nStarting experiment: dropout_30pct_fixed_train_fixed_eval\nDropout rate training: 0.3, Pattern: fixed\nDropout rate evaluation: 0.3, Pattern: fixed\nNumber of GPUs: 1\nNumber of clients: 10\nNumber of rounds: 10\nFixed clients: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(pid=449)\u001b[0m 2025-06-03 05:58:03.740312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[36m(pid=449)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n\u001b[36m(pid=449)\u001b[0m E0000 00:00:1748930283.763935     449 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[36m(pid=449)\u001b[0m E0000 00:00:1748930283.771117     449 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 1]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 1: 3 clients dropped out of 10 during training\nDropped client IDs: [16291045025589148999, 15319501751034550911, 7086999154511402866]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 1 training metrics: {'train_loss': 0.6874326879010539, 'train_accuracy': 0.5373580331796668, 'val_loss': 0.7138694602967164, 'val_accuracy': 0.47601756106146925}\nRound 1: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [8962672425154457638, 13193605613819160160, 16291045025589148999]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5833333134651184     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │     0.691129744052887     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6922095417976379     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6921945214271545     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6941953301429749     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6911715865135193     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6945425271987915     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5043478012084961     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6934217810630798     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 2]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 1 evaluation metrics: {'test_accuracy': 0.5089820245068944, 'test_loss': 0.6926906526445629}\nRound 2: 3 clients dropped out of 10 during training\nDropped client IDs: [16291045025589148999, 7086999154511402866, 12161179495455028808]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 2 training metrics: {'train_loss': 0.744848544041292, 'train_accuracy': 0.551837465497391, 'val_loss': 0.7309289324415382, 'val_accuracy': 0.5192505558515828}\nRound 2: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [8110288427707767833, 7086999154511402866, 17442941788023419691]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7080458402633667     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4166666567325592     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7056188583374023     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4583333432674408     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6837888956069946     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │            0.5            │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7142555117607117     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6842838525772095     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5897436141967773     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6801979541778564     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 3]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.7920792102813721     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6520588397979736     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 2 evaluation metrics: {'test_accuracy': 0.5305623466053335, 'test_loss': 0.6906604626942381}\nRound 3: 3 clients dropped out of 10 during training\nDropped client IDs: [15319501751034550911, 17442941788023419691, 13193605613819160160]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 3 training metrics: {'train_loss': 0.7019901377124246, 'train_accuracy': 0.5817849428378479, 'val_loss': 0.7204203272860769, 'val_accuracy': 0.5798433021804816}\nRound 3: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [12161179495455028808, 7086999154511402866, 8962672425154457638]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7579296231269836     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7437492609024048     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.6000000238418579     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7031348347663879     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5833333134651184     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7697359919548035     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5652173757553101     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6968284249305725     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │     0.504273533821106     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6963844895362854     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 4]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.6732673048973083     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6469958424568176     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 3 evaluation metrics: {'test_accuracy': 0.5621156263615372, 'test_loss': 0.7182100855116474}\nRound 4: 3 clients dropped out of 10 during training\nDropped client IDs: [8962672425154457638, 3937667712009983251, 13193605613819160160]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 4 training metrics: {'train_loss': 0.6734535168540834, 'train_accuracy': 0.6039000699100227, 'val_loss': 0.7520143226978621, 'val_accuracy': 0.561405343654532}\nRound 4: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [3937667712009983251, 15319501751034550911, 8110288427707767833]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.49166667461395264    │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6914288401603699     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │     0.574999988079071     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7347034215927124     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │     0.550000011920929     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7839962244033813     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │     0.574999988079071     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7640864253044128     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6735687255859375     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4871794879436493     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6930009126663208     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 5]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.3861386179924011     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6540330648422241     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 4 evaluation metrics: {'test_accuracy': 0.5171149185423746, 'test_loss': 0.7150030351792688}\nRound 5: 3 clients dropped out of 10 during training\nDropped client IDs: [13193605613819160160, 8110288427707767833, 8962672425154457638]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 5 training metrics: {'train_loss': 0.6569755749042506, 'train_accuracy': 0.6232586277570962, 'val_loss': 0.7501523073227893, 'val_accuracy': 0.5200841155722241}\nRound 5: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [15319501751034550911, 12161179495455028808, 7086999154511402866]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7438389658927917     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7145799994468689     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7571987509727478     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6759150624275208     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5043478012084961     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6886308193206787     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.43589743971824646    │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6933019161224365     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 6]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.2970297038555145     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6743543744087219     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 5 evaluation metrics: {'test_accuracy': 0.4833948322621072, 'test_loss': 0.7077522677395763}\nRound 6: 3 clients dropped out of 10 during training\nDropped client IDs: [12161179495455028808, 15319501751034550911, 17442941788023419691]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 6 training metrics: {'train_loss': 0.6421355955687423, 'train_accuracy': 0.6217537422519629, 'val_loss': 0.7029360144501828, 'val_accuracy': 0.5326229420835149}\nRound 6: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [8962672425154457638, 16291045025589148999, 7086999154511402866]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6845877766609192     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7817056775093079     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7474696040153503     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7131615877151489     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7619240880012512     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5130434632301331     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6890823245048523     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 7]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.43589743971824646    │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6970416307449341     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 6 evaluation metrics: {'test_accuracy': 0.5180288463329467, 'test_loss': 0.7253127237781882}\nRound 7: 3 clients dropped out of 10 during training\nDropped client IDs: [12161179495455028808, 8110288427707767833, 7086999154511402866]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 7 training metrics: {'train_loss': 0.6355818985335592, 'train_accuracy': 0.6245443578696338, 'val_loss': 0.7641056722091151, 'val_accuracy': 0.556113014425426}\nRound 7: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [3937667712009983251, 16291045025589148999, 13193605613819160160]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │     0.550000011920929     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7461790442466736     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5166666507720947     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │     0.845216691493988     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5083333253860474     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6703661680221558     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5043478012084961     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6994045972824097     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4000000059604645     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7135200500488281     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7023928165435791     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 8]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5416666865348816     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.8208955526351929     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 7 evaluation metrics: {'test_accuracy': 0.5077844337075056, 'test_loss': 0.7428263083189547}\nRound 8: 3 clients dropped out of 10 during training\nDropped client IDs: [17442941788023419691, 16291045025589148999, 8962672425154457638]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 8 training metrics: {'train_loss': 0.6484694492834744, 'train_accuracy': 0.6245142092619241, 'val_loss': 0.7465078010509189, 'val_accuracy': 0.5071834616686018}\nRound 8: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [8962672425154457638, 12161179495455028808, 15319501751034550911]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.3916666805744171     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7239977717399597     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7024581432342529     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5833333134651184     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6763384938240051     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6967870593070984     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │     0.530434787273407     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6874871253967285     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4188034236431122     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7154236435890198     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 9]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.23762376606464386    │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7538160681724548     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 8 evaluation metrics: {'test_accuracy': 0.4698646954761367, 'test_loss': 0.7070735360130319}\nRound 9: 3 clients dropped out of 10 during training\nDropped client IDs: [8110288427707767833, 15319501751034550911, 17076469643470162750]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 9 training metrics: {'train_loss': 0.6212650995932402, 'train_accuracy': 0.6339611110355555, 'val_loss': 0.8284072632271059, 'val_accuracy': 0.5267435036065512}\nRound 9: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [17076469643470162750, 12161179495455028808, 13193605613819160160]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7061630487442017     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5166666507720947     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6650491952896118     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4956521689891815     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7025576829910278     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.32673266530036926    │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6980598568916321     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4000000059604645     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7209848761558533     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5166666507720947     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.8140129446983337     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.8607694506645203     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 9 evaluation metrics: {'test_accuracy': 0.48651960236476915, 'test_loss': 0.7393820109758892}\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 10]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 10: 3 clients dropped out of 10 during training\nDropped client IDs: [17076469643470162750, 17442941788023419691, 12161179495455028808]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=449)\u001b[0m   | Name           | Type               | Params | Mode \n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0 | model          | DenseNet           | 1.7 M  | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1 | criterion      | CrossEntropyLoss   | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 2 | nll_loss       | NLLLoss            | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 3 | train_accuracy | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 4 | val_accuracy   | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 5 | test_accuracy  | MulticlassAccuracy | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6 | rbsm           | RelaxedBSM         | 0      | train\n\u001b[36m(ClientAppActor pid=449)\u001b[0m --------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 1.7 M     Total params\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 6.797     Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 313       Modules in train mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 7 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 10 training metrics: {'train_loss': 0.6201410852292973, 'train_accuracy': 0.6333638845581255, 'val_loss': 0.7159393470730944, 'val_accuracy': 0.4623896806767473}\nRound 10: 3 clients dropped out of 10 during evaluation\nDropped client IDs: [17442941788023419691, 17076469643470162750, 7086999154511402866]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5249999761581421     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7227803468704224     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5583333373069763     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6692304611206055     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.5333333611488342     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7428447008132935     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │            0.5            │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6936638951301575     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │     0.52173912525177      │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.6872621178627014     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.4444444477558136     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7127071022987366     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=449)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 7 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [SUMMARY]\n\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 6934.41s\n\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6926906526445629\n\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6906604626942381\n\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.7182100855116474\n\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.7150030351792688\n\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.7077522677395763\n\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.7253127237781882\n\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.7428263083189547\n\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.7070735360130319\n\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.7393820109758892\n\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.7108005813860219\n\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n\u001b[92mINFO \u001b[0m:      \t{'train_accuracy': [(1, 0.5373580331796668),\n\u001b[92mINFO \u001b[0m:      \t                    (2, 0.551837465497391),\n\u001b[92mINFO \u001b[0m:      \t                    (3, 0.5817849428378479),\n\u001b[92mINFO \u001b[0m:      \t                    (4, 0.6039000699100227),\n\u001b[92mINFO \u001b[0m:      \t                    (5, 0.6232586277570962),\n\u001b[92mINFO \u001b[0m:      \t                    (6, 0.6217537422519629),\n\u001b[92mINFO \u001b[0m:      \t                    (7, 0.6245443578696338),\n\u001b[92mINFO \u001b[0m:      \t                    (8, 0.6245142092619241),\n\u001b[92mINFO \u001b[0m:      \t                    (9, 0.6339611110355555),\n\u001b[92mINFO \u001b[0m:      \t                    (10, 0.6333638845581255)],\n\u001b[92mINFO \u001b[0m:      \t 'train_loss': [(1, 0.6874326879010539),\n\u001b[92mINFO \u001b[0m:      \t                (2, 0.744848544041292),\n\u001b[92mINFO \u001b[0m:      \t                (3, 0.7019901377124246),\n\u001b[92mINFO \u001b[0m:      \t                (4, 0.6734535168540834),\n\u001b[92mINFO \u001b[0m:      \t                (5, 0.6569755749042506),\n\u001b[92mINFO \u001b[0m:      \t                (6, 0.6421355955687423),\n\u001b[92mINFO \u001b[0m:      \t                (7, 0.6355818985335592),\n\u001b[92mINFO \u001b[0m:      \t                (8, 0.6484694492834744),\n\u001b[92mINFO \u001b[0m:      \t                (9, 0.6212650995932402),\n\u001b[92mINFO \u001b[0m:      \t                (10, 0.6201410852292973)],\n\u001b[92mINFO \u001b[0m:      \t 'val_accuracy': [(1, 0.47601756106146925),\n\u001b[92mINFO \u001b[0m:      \t                  (2, 0.5192505558515828),\n\u001b[92mINFO \u001b[0m:      \t                  (3, 0.5798433021804816),\n\u001b[92mINFO \u001b[0m:      \t                  (4, 0.561405343654532),\n\u001b[92mINFO \u001b[0m:      \t                  (5, 0.5200841155722241),\n\u001b[92mINFO \u001b[0m:      \t                  (6, 0.5326229420835149),\n\u001b[92mINFO \u001b[0m:      \t                  (7, 0.556113014425426),\n\u001b[92mINFO \u001b[0m:      \t                  (8, 0.5071834616686018),\n\u001b[92mINFO \u001b[0m:      \t                  (9, 0.5267435036065512),\n\u001b[92mINFO \u001b[0m:      \t                  (10, 0.4623896806767473)],\n\u001b[92mINFO \u001b[0m:      \t 'val_loss': [(1, 0.7138694602967164),\n\u001b[92mINFO \u001b[0m:      \t              (2, 0.7309289324415382),\n\u001b[92mINFO \u001b[0m:      \t              (3, 0.7204203272860769),\n\u001b[92mINFO \u001b[0m:      \t              (4, 0.7520143226978621),\n\u001b[92mINFO \u001b[0m:      \t              (5, 0.7501523073227893),\n\u001b[92mINFO \u001b[0m:      \t              (6, 0.7029360144501828),\n\u001b[92mINFO \u001b[0m:      \t              (7, 0.7641056722091151),\n\u001b[92mINFO \u001b[0m:      \t              (8, 0.7465078010509189),\n\u001b[92mINFO \u001b[0m:      \t              (9, 0.8284072632271059),\n\u001b[92mINFO \u001b[0m:      \t              (10, 0.7159393470730944)]}\n\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n\u001b[92mINFO \u001b[0m:      \t{'test_accuracy': [(1, 0.5089820245068944),\n\u001b[92mINFO \u001b[0m:      \t                   (2, 0.5305623466053335),\n\u001b[92mINFO \u001b[0m:      \t                   (3, 0.5621156263615372),\n\u001b[92mINFO \u001b[0m:      \t                   (4, 0.5171149185423746),\n\u001b[92mINFO \u001b[0m:      \t                   (5, 0.4833948322621072),\n\u001b[92mINFO \u001b[0m:      \t                   (6, 0.5180288463329467),\n\u001b[92mINFO \u001b[0m:      \t                   (7, 0.5077844337075056),\n\u001b[92mINFO \u001b[0m:      \t                   (8, 0.4698646954761367),\n\u001b[92mINFO \u001b[0m:      \t                   (9, 0.48651960236476915),\n\u001b[92mINFO \u001b[0m:      \t                   (10, 0.48585485994155997)],\n\u001b[92mINFO \u001b[0m:      \t 'test_loss': [(1, 0.6926906526445629),\n\u001b[92mINFO \u001b[0m:      \t               (2, 0.6906604626942381),\n\u001b[92mINFO \u001b[0m:      \t               (3, 0.7182100855116474),\n\u001b[92mINFO \u001b[0m:      \t               (4, 0.7150030351792688),\n\u001b[92mINFO \u001b[0m:      \t               (5, 0.7077522677395763),\n\u001b[92mINFO \u001b[0m:      \t               (6, 0.7253127237781882),\n\u001b[92mINFO \u001b[0m:      \t               (7, 0.7428263083189547),\n\u001b[92mINFO \u001b[0m:      \t               (8, 0.7070735360130319),\n\u001b[92mINFO \u001b[0m:      \t               (9, 0.7393820109758892),\n\u001b[92mINFO \u001b[0m:      \t               (10, 0.7108005813860219)]}\n\u001b[92mINFO \u001b[0m:      \n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=449)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=449)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/acc          │    0.2871287167072296     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m │         test/loss         │    0.7528383135795593     │\n\u001b[36m(ClientAppActor pid=449)\u001b[0m └───────────────────────────┴───────────────────────────┘\nRound 10 evaluation metrics: {'test_accuracy': 0.48585485994155997, 'test_loss': 0.7108005813860219}\nResult is {'rounds': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'train_accuracy': [0.5373580331796668, 0.551837465497391, 0.5817849428378479, 0.6039000699100227, 0.6232586277570962, 0.6217537422519629, 0.6245443578696338, 0.6245142092619241, 0.6339611110355555, 0.6333638845581255], 'train_loss': [0.6874326879010539, 0.744848544041292, 0.7019901377124246, 0.6734535168540834, 0.6569755749042506, 0.6421355955687423, 0.6355818985335592, 0.6484694492834744, 0.6212650995932402, 0.6201410852292973], 'test_accuracy': [0.5089820245068944, 0.5305623466053335, 0.5621156263615372, 0.5171149185423746, 0.4833948322621072, 0.5180288463329467, 0.5077844337075056, 0.4698646954761367, 0.48651960236476915, 0.48585485994155997], 'test_loss': [0.6926906526445629, 0.6906604626942381, 0.7182100855116474, 0.7150030351792688, 0.7077522677395763, 0.7253127237781882, 0.7428263083189547, 0.7070735360130319, 0.7393820109758892, 0.7108005813860219]}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_server_round</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test_accuracy</td><td>▄▆█▅▂▅▄▁▂▂</td></tr><tr><td>test_loss</td><td>▁▁▅▄▃▆█▃█▄</td></tr><tr><td>train_accuracy</td><td>▁▂▄▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▅█▆▄▃▂▂▃▁▁</td></tr><tr><td>train_server_round</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_server_round</td><td>10</td></tr><tr><td>test_accuracy</td><td>0.48585</td></tr><tr><td>test_loss</td><td>0.7108</td></tr><tr><td>train_accuracy</td><td>0.63336</td></tr><tr><td>train_loss</td><td>0.62014</td></tr><tr><td>train_server_round</td><td>10</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dropout_30pct_fixed_train_fixed_eval</strong> at: <a href='https://wandb.ai/iai-uet-vnu/sex-classification/runs/088uu6cf' target=\"_blank\">https://wandb.ai/iai-uet-vnu/sex-classification/runs/088uu6cf</a><br> View project at: <a href='https://wandb.ai/iai-uet-vnu/sex-classification' target=\"_blank\">https://wandb.ai/iai-uet-vnu/sex-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250603_053750-088uu6cf/logs</code>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"({'rounds': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n  'train_accuracy': [0.5373580331796668,\n   0.551837465497391,\n   0.5817849428378479,\n   0.6039000699100227,\n   0.6232586277570962,\n   0.6217537422519629,\n   0.6245443578696338,\n   0.6245142092619241,\n   0.6339611110355555,\n   0.6333638845581255],\n  'train_loss': [0.6874326879010539,\n   0.744848544041292,\n   0.7019901377124246,\n   0.6734535168540834,\n   0.6569755749042506,\n   0.6421355955687423,\n   0.6355818985335592,\n   0.6484694492834744,\n   0.6212650995932402,\n   0.6201410852292973],\n  'test_accuracy': [0.5089820245068944,\n   0.5305623466053335,\n   0.5621156263615372,\n   0.5171149185423746,\n   0.4833948322621072,\n   0.5180288463329467,\n   0.5077844337075056,\n   0.4698646954761367,\n   0.48651960236476915,\n   0.48585485994155997],\n  'test_loss': [0.6926906526445629,\n   0.6906604626942381,\n   0.7182100855116474,\n   0.7150030351792688,\n   0.7077522677395763,\n   0.7253127237781882,\n   0.7428263083189547,\n   0.7070735360130319,\n   0.7393820109758892,\n   0.7108005813860219]},\n ({1: [16291045025589148999, 15319501751034550911, 7086999154511402866],\n   2: [16291045025589148999, 7086999154511402866, 12161179495455028808],\n   3: [15319501751034550911, 17442941788023419691, 13193605613819160160],\n   4: [8962672425154457638, 3937667712009983251, 13193605613819160160],\n   5: [13193605613819160160, 8110288427707767833, 8962672425154457638],\n   6: [12161179495455028808, 15319501751034550911, 17442941788023419691],\n   7: [12161179495455028808, 8110288427707767833, 7086999154511402866],\n   8: [17442941788023419691, 16291045025589148999, 8962672425154457638],\n   9: [8110288427707767833, 15319501751034550911, 17076469643470162750],\n   10: [17076469643470162750, 17442941788023419691, 12161179495455028808]},\n  {1: [8962672425154457638, 13193605613819160160, 16291045025589148999],\n   2: [8110288427707767833, 7086999154511402866, 17442941788023419691],\n   3: [12161179495455028808, 7086999154511402866, 8962672425154457638],\n   4: [3937667712009983251, 15319501751034550911, 8110288427707767833],\n   5: [15319501751034550911, 12161179495455028808, 7086999154511402866],\n   6: [8962672425154457638, 16291045025589148999, 7086999154511402866],\n   7: [3937667712009983251, 16291045025589148999, 13193605613819160160],\n   8: [8962672425154457638, 12161179495455028808, 15319501751034550911],\n   9: [17076469643470162750, 12161179495455028808, 13193605613819160160],\n   10: [17442941788023419691, 17076469643470162750, 7086999154511402866]}))"},"metadata":{}}],"execution_count":22}]}