{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11620100,"sourceType":"datasetVersion","datasetId":7289711},{"sourceId":11680004,"sourceType":"datasetVersion","datasetId":7180861},{"sourceId":11721921,"sourceType":"datasetVersion","datasetId":7270261}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q lightning flwr wandb hydra-core","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:04:11.468754Z","iopub.execute_input":"2025-06-03T09:04:11.469006Z","iopub.status.idle":"2025-06-03T09:05:39.795752Z","shell.execute_reply.started":"2025-06-03T09:04:11.468985Z","shell.execute_reply":"2025-06-03T09:05:39.794823Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.8 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom pathlib import Path\nimport nibabel as nib\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:39.797700Z","iopub.execute_input":"2025-06-03T09:05:39.797963Z","iopub.status.idle":"2025-06-03T09:05:42.424894Z","shell.execute_reply.started":"2025-06-03T09:05:39.797939Z","shell.execute_reply":"2025-06-03T09:05:42.424290Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nsecret_label = \"wandb api key\"\nWANDB_APIKEY = UserSecretsClient().get_secret(secret_label)\n\nROOT_PATH = '/kaggle/input/mri-dataset/datasetzip/not_skull_stripped'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:42.425548Z","iopub.execute_input":"2025-06-03T09:05:42.425899Z","iopub.status.idle":"2025-06-03T09:05:42.534163Z","shell.execute_reply.started":"2025-06-03T09:05:42.425881Z","shell.execute_reply":"2025-06-03T09:05:42.533634Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class MRIDataset(Dataset) :\n\n    def __init__(self, root_dir: str, label_path: str = None, transform = None, label_df: pd.DataFrame = None, is_3d: bool = False):\n        self.root_dir = Path(root_dir)\n        self.transform = transform\n        self.is_3d = is_3d\n        if label_df is None:\n          self.labels_df = pd.read_csv(label_path)\n          \n        else :\n          self.labels_df = label_df\n\n        self.labels_df['subject_id'] = self.labels_df['subject_id'].astype(str)\n        self.labels_df = self.labels_df[self.labels_df['subject_dx'] == 'control']\n\n        all_nii_files = list(self.root_dir.rglob(\"*.nii\"))\n        fail_paths = [\"sub-BrainAge005600/anat/sub-BrainAge005600_T1w.nii/sub-BrainAge005600_T1w.nii\"]\n        self.file_paths = [fp for fp in all_nii_files if fp.is_file() and fp.name not in fail_paths ]\n\n        valid_subjects = set(self.labels_df['subject_id'].values)\n\n        self.file_paths = [fp for fp in self.file_paths if any(vs in str(fp) for vs in valid_subjects)]\n        self.file_paths.sort()\n\n\n\n    def __len__(self):\n        return len(self.file_paths)\n\n\n    def preprocessing_datapoint(self, img_data):\n\n        mid_x = img_data.shape[0] // 2\n        mid_y = img_data.shape[1] // 2\n        mid_z = img_data.shape[2] // 2\n\n        axial_slice = img_data[:, :, mid_z]\n        coronal_slice = img_data[:, mid_y, :]\n        sagittal_slice = img_data[mid_x, :, :]\n\n\n        combined_data = np.stack([axial_slice, coronal_slice, sagittal_slice], axis=0)\n        combined_data = torch.from_numpy(combined_data).float()\n\n        if self.transform : combined_data = self.transform(combined_data)\n\n        return combined_data\n\n\n\n\n    def __getitem__(self, idx):\n        img_path = self.file_paths[idx]\n        file_path_str = str(img_path)\n\n        subject_id = None\n        valid_subjects_set = set(self.labels_df['subject_id'].values)\n\n\n        for sid in valid_subjects_set:\n            if sid in file_path_str:\n                subject_id = sid\n                break\n\n        if subject_id is None:\n            raise ValueError(f\"Không tìm thấy subject_id cho file: {img_path}\")\n\n        metadata = self.labels_df.loc[self.labels_df['subject_id'] == subject_id].iloc[0].to_dict()\n\n        img_data = nib.load(img_path).get_fdata()\n\n        img_data = torch.from_numpy(img_data).float()\n\n        label = 0\n        if metadata['subject_sex'] == 'm' : label = 1\n\n        if not self.is_3d:\n            img_data = self.preprocessing_datapoint(img_data)\n\n        return img_data,  label\n\n\n\ndef visualize_sample(dataset, idx):\n    mri_data, label = dataset[idx]\n    title = f\"Label: {label}\\n\"\n    plt.close('all')\n    fig = plt.figure(figsize = (18, 6))\n\n    if isinstance(mri_data, torch.Tensor):\n        data = mri_data.squeeze().numpy()\n    else:\n        data = mri_data\n\n\n    ax1 = fig.add_subplot(1, 3, 1)\n    plt.imshow(data[0, :, :].T, cmap='gray', origin='lower')\n\n    ax2 = fig.add_subplot(1, 3, 2)\n    ax2.imshow(data[1, :, :].T, cmap='gray', origin='lower')\n\n    ax3 = fig.add_subplot(1, 3, 3)\n    ax3.imshow(data[2, :, :].T, cmap='gray', origin='lower')\n\n    plt.suptitle(title)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:42.534857Z","iopub.execute_input":"2025-06-03T09:05:42.535041Z","iopub.status.idle":"2025-06-03T09:05:42.547438Z","shell.execute_reply.started":"2025-06-03T09:05:42.535025Z","shell.execute_reply":"2025-06-03T09:05:42.546805Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset = MRIDataset(root_dir= '/kaggle/input/mini-brain3d-dataset/not_skull_stripped' , label_path = '/kaggle/input/mri-label/label.csv', is_3d = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:42.548296Z","iopub.execute_input":"2025-06-03T09:05:42.548570Z","iopub.status.idle":"2025-06-03T09:05:43.578147Z","shell.execute_reply.started":"2025-06-03T09:05:42.548546Z","shell.execute_reply":"2025-06-03T09:05:43.577528Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset[0][0].shape ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:43.578813Z","iopub.execute_input":"2025-06-03T09:05:43.578993Z","iopub.status.idle":"2025-06-03T09:05:43.717032Z","shell.execute_reply.started":"2025-06-03T09:05:43.578979Z","shell.execute_reply":"2025-06-03T09:05:43.716397Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([130, 130, 130])"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Data splitting","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split \n\ndef preprocessing_labels(df: pd.DataFrame, root_dir: str = ROOT_PATH):\n    \n    subject_list = []\n    for root, dirs, files in os.walk(root_dir):\n      for dir_name in dirs:\n        if dir_name.startswith(\"sub-BrainAge\"):\n            subject_list.append(dir_name)\n\n\n    return df[df['subject_id'].isin(subject_list)]\n\n\ndef prepare_data(data: pd.DataFrame):\n\n  df = data.copy()\n  df['age_group'] = pd.qcut(df['subject_age'], q = min(5, len(df)), labels = False)\n  df['key'] = df.apply(lambda row : f\"{row['age_group']}_{row['subject_sex']}\", axis = 1)\n  return df\n\n\ndef sampling_data(data, size, random_state ):\n\n  samples = data.groupby('key', group_keys = False)\n\n\n  samples = samples.apply(lambda x: x.sample(\n      n = min(int(size / len(data['key'].unique())), len(x)),\n      replace = len(x) < int(size / len(data['key'].unique())),\n      random_state =  random_state\n  ), include_groups=False)\n\n\n  if len(samples) < size:\n    additional_samples = data.drop(samples.index).sample(\n        n = min(size - len(samples), len(data) - len(samples)),\n        replace = True,\n        random_state = random_state\n    )\n\n    samples = pd.concat([samples, additional_samples])\n  return samples\n\n\ndef create_train_test(sample_labels: list, val_ratio: float = 0.2, root_dir: str = ROOT_PATH, is_3d: bool = False):\n\n  client_datasets = []\n  for label_df in sample_labels:\n    dataset = MRIDataset(root_dir=root_dir, label_df = label_df, is_3d = is_3d)\n    \n    train_dataset, val_dataset = random_split(dataset, [1 - val_ratio, val_ratio])\n    client_datasets.append((train_dataset, val_dataset))\n  return client_datasets\n\n\ndef distributed_data_to_clients(data: pd.DataFrame, num_clients: int, overlap_ratio: float):\n\n  df = prepare_data(data)\n\n  n_samples = len(df)\n  samples_per_client = int(n_samples / (num_clients * (1 - overlap_ratio) + overlap_ratio))\n\n  client_datasets = []\n  selected_samples = {}\n\n  # Tạo các client datasets với sự phân bố cân bằng\n  for client_idx in range(num_clients):\n\n      if client_idx == 0:\n          client_data = df.sample(n=samples_per_client, random_state=42+client_idx)\n      else:\n          # overlap size\n          overlap_size = int(samples_per_client * overlap_ratio)\n          non_overlap_size = samples_per_client - overlap_size\n\n          # building overlap\n          all_previous_samples = pd.DataFrame()\n          for prev_client_idx in range(client_idx):\n              all_previous_samples = pd.concat([all_previous_samples, selected_samples[prev_client_idx]])\n\n          # sampling\n          if len(all_previous_samples) > 0:\n              overlap_samples = sampling_data(all_previous_samples, overlap_size, client_idx * 100 + 42)\n          else:\n              overlap_samples = pd.DataFrame(columns=df.columns)\n\n          # Lấy mẫu mới (không overlap)\n          remaining_indices = df.index.difference(all_previous_samples.index)\n          if len(remaining_indices) > 0:\n              remaining_df = df.loc[remaining_indices]\n              non_overlap_samples = sampling_data(remaining_df, non_overlap_size, client_idx * 100 + 42)\n          else:\n\n              non_overlap_samples = df.sample(n=non_overlap_size, replace=True, random_state=42+client_idx*300)\n\n\n          client_data = pd.concat([overlap_samples, non_overlap_samples])\n\n\n      selected_samples[client_idx] = client_data\n      client_datasets.append(client_data.drop(['age_group', 'key'], axis=1))\n\n  return client_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:43.719554Z","iopub.execute_input":"2025-06-03T09:05:43.719802Z","iopub.status.idle":"2025-06-03T09:05:44.778924Z","shell.execute_reply.started":"2025-06-03T09:05:43.719761Z","shell.execute_reply":"2025-06-03T09:05:44.778115Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n\ndef iid_client_split(dataset, num_client = 3,  val_ratio = 0.2):\n\n    client_datasets = []\n    sample_per_client = len(dataset) // num_client\n\n\n    for i in range(num_client):\n        start_idx = i * sample_per_client\n        end_idx = (i + 1) * sample_per_client if i < num_client - 1 else len(dataset)\n        indecies = list(range(start_idx, end_idx))\n\n        client_dataset = torch.utils.data.Subset(dataset, indecies)\n        train_dataset, val_dataset = random_split(client_dataset, [1 - val_ratio, val_ratio])\n\n        client_datasets.append((train_dataset, val_dataset))\n    return client_datasets\n\n\n\n\n\ndef same_distribution_client_split(dataset, num_client, val_ratio = 0.2, overlap_ratio = 0.2, root_dir = ROOT_PATH, is_3d = False):\n    \"\"\"\n    Split the dataset into clients with the same distribution of labels.\n    \"\"\"\n    labels_df = dataset.labels_df\n    labels_df = preprocessing_labels(labels_df, root_dir = root_dir)    \n    labels_df = prepare_data(labels_df)\n\n    client_datasets = distributed_data_to_clients(labels_df, num_clients=num_client, overlap_ratio=overlap_ratio)\n\n    client_datasets = create_train_test(client_datasets, val_ratio=val_ratio, root_dir=root_dir, is_3d = is_3d)\n\n    return client_datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:44.779898Z","iopub.execute_input":"2025-06-03T09:05:44.780132Z","iopub.status.idle":"2025-06-03T09:05:44.800382Z","shell.execute_reply.started":"2025-06-03T09:05:44.780114Z","shell.execute_reply":"2025-06-03T09:05:44.799688Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"#  Model","metadata":{}},{"cell_type":"markdown","source":"## 3D DenseNet","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn \nimport torch \nimport torch.nn.functional as F\nfrom collections import OrderedDict\nfrom typing import List, Tuple\nfrom torchsummary import summary\n\n\nclass _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super().__init__()\n        self.add_module('norm1', nn.BatchNorm3d(num_input_features))\n        self.add_module('relu1', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv1',\n            nn.Conv3d(num_input_features,\n                      bn_size * growth_rate,\n                      kernel_size=1,\n                      stride=1,\n                      bias=False))\n        self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate))\n        self.add_module('relu2', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv2',\n            nn.Conv3d(bn_size * growth_rate,\n                      growth_rate,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1,\n                      bias=False))\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super().forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features,\n                                     p=self.drop_rate,\n                                     training=self.training)\n        return torch.cat([x, new_features], 1)\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super().__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features + i * growth_rate,\n                                growth_rate, bn_size, drop_rate)\n            self.add_module('denselayer{}'.format(i + 1), layer)\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super().__init__()\n        self.add_module('norm', nn.BatchNorm3d(num_input_features))\n        self.add_module('relu', nn.ReLU(inplace=True))\n        self.add_module(\n            'conv',\n            nn.Conv3d(num_input_features,\n                      num_output_features,\n                      kernel_size=1,\n                      stride=1,\n                      bias=False))\n        self.add_module('pool', nn.AvgPool3d(kernel_size=2, stride=2))\n\nclass DenseNet(nn.Module):\n    def __init__(self,\n                 n_input_channels=1,\n                 conv1_t_size=7,\n                 conv1_t_stride=1,\n                 no_max_pool=False,\n                 growth_rate=16,\n                 block_config=(4, 8, 16, 12),\n                 num_init_features=32,\n                 bn_size=4,\n                 drop_rate=0,\n                 num_classes=1):\n        super().__init__()\n\n        # First convolution\n        self.features = [('conv1',\n                          nn.Conv3d(n_input_channels,\n                                    num_init_features,\n                                    kernel_size=(conv1_t_size, 7, 7),\n                                    stride=(conv1_t_stride, 2, 2),\n                                    padding=(conv1_t_size // 2, 3, 3),\n                                    bias=False)),\n                         ('norm1', nn.BatchNorm3d(num_init_features)),\n                         ('relu1', nn.ReLU(inplace=True))]\n        if not no_max_pool:\n            self.features.append(\n                ('pool1', nn.MaxPool3d(kernel_size=3, stride=2, padding=1)))\n        self.features = nn.Sequential(OrderedDict(self.features))\n\n        # Each denseblock\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            block = _DenseBlock(num_layers=num_layers,\n                                num_input_features=num_features,\n                                bn_size=bn_size,\n                                growth_rate=growth_rate,\n                                drop_rate=drop_rate)\n            self.features.add_module('denseblock{}'.format(i + 1), block)\n            num_features = num_features + num_layers * growth_rate\n            if i != len(block_config) - 1:\n                trans = _Transition(num_input_features=num_features,\n                                    num_output_features=num_features // 2)\n                self.features.add_module('transition{}'.format(i + 1), trans)\n                num_features = num_features // 2\n\n        self.features.add_module('norm5', nn.BatchNorm3d(num_features))\n        self.classifier = nn.Linear(num_features, num_classes)\n\n        # Khởi tạo trọng số\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm3d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        features = self.features(x)\n        out = F.relu(features, inplace=True)\n        out = F.adaptive_avg_pool3d(out, output_size=(1, 1, 1)).view(features.size(0), -1)\n        logits = self.classifier(out)\n        return logits\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:44.801077Z","iopub.execute_input":"2025-06-03T09:05:44.801260Z","iopub.status.idle":"2025-06-03T09:05:44.826693Z","shell.execute_reply.started":"2025-06-03T09:05:44.801246Z","shell.execute_reply":"2025-06-03T09:05:44.826214Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import lightning as pl\nimport torch.nn as nn \nfrom torchmetrics import Accuracy, F1Score, Precision, Recall, MeanMetric\nimport torch.optim as optim \nimport torch \n\n\n\nclass DenseNetModule(pl.LightningModule):\n    def __init__(self, net, learning_rate=1e-3, weight_decay = 1e-2, batch_size = 32):\n        super().__init__()\n        self.model = net\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.batch_size = batch_size\n        # how confidence model is in it prediction\n        # tức model có thể rất tự tin trong quyết định nhưng thực tế lại sai\n        # BCE = y*log(y_pred) + (1 - y)*log(1 - y_pred)\n        self.criterion = nn.BCEWithLogitsLoss()\n        \n        self.train_accuracy = Accuracy(task=\"binary\", num_classes=1)\n        self.val_accuracy = Accuracy(task=\"binary\", num_classes=1)\n        self.test_accuracy = Accuracy(task=\"binary\", num_classes=1)\n\n\n        self.val_precision = Precision(task=\"binary\", num_classes=1)\n        self.test_precision = Precision(task=\"binary\", num_classes=1)\n\n        self.val_recall = Recall(task=\"binary\", num_classes=1)\n        self.test_recall = Recall(task=\"binary\", num_classes=1)\n\n        self.val_f1 = F1Score(task=\"binary\", num_classes=1)\n        self.test_f1 = F1Score(task=\"binary\", num_classes=1)\n\n    \n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        # x.shape  = (batch_size, in_channel, height, width, depth), y.shape = (batch_size)\n        logits = self(x.unsqueeze(1))\n        \n        loss = self.criterion(logits, y.float().unsqueeze(1))\n        \n        acc = self.train_accuracy((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n\n        \n        self.log('train/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('train/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x.unsqueeze(1))\n        \n        loss = self.criterion(logits, y.float().unsqueeze(1))\n        acc = self.val_accuracy((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        f1 = self.val_f1((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        precision = self.val_precision((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        recall = self.val_recall((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        \n        self.log('val/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/precision', precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val/recall', recall, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n\n\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x.unsqueeze(1))\n        \n        loss = self.criterion(logits, y.float().unsqueeze(1))\n        acc = self.test_accuracy((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        f1 = self.test_f1((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        precision = self.test_precision((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n        recall = self.test_recall((torch.sigmoid(logits) > 0.5).float(), y.unsqueeze(1))\n\n        \n\n\n\n        self.log('test/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/precision', precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('test/recall', recall, on_step=False, on_epoch=True, prog_bar=True)\n        return loss\n\n\n\n\n    def configure_optimizers(self):\n        optimizer =  torch.optim.SGD(self.parameters(), lr=self.learning_rate, weight_decay = self.weight_decay)\n        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n\n        return {\n           \"optimizer\": optimizer,\n           \"lr_scheduler\": {\n               \"scheduler\": scheduler,\n               \"monitor\": \"val_loss\",\n           },\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:44.827432Z","iopub.execute_input":"2025-06-03T09:05:44.827635Z","iopub.status.idle":"2025-06-03T09:05:54.145137Z","shell.execute_reply.started":"2025-06-03T09:05:44.827620Z","shell.execute_reply":"2025-06-03T09:05:54.144387Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 2D model ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\nclass BrainMRINet(nn.Module):\n    def __init__(self, num_classes: int = 2, pretrained: bool = True):\n        super(BrainMRINet, self).__init__()\n        # Load DenseNet-121\n        densenet = models.densenet121(weights='IMAGENET1K_V1')\n\n        # Replace the classifier (classifier is a single Linear layer in DenseNet)\n        num_features = densenet.classifier.in_features\n        densenet.classifier = nn.Sequential(\n            nn.Linear(num_features, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n\n        self.model = densenet\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:54.145821Z","iopub.execute_input":"2025-06-03T09:05:54.146184Z","iopub.status.idle":"2025-06-03T09:05:54.151656Z","shell.execute_reply.started":"2025-06-03T09:05:54.146168Z","shell.execute_reply":"2025-06-03T09:05:54.150827Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class BrainMRILightningModule(pl.LightningModule): \n    \n    def __init__(self, net: nn.Module,  learning_rate=1e-3, weight_decay = 1e-2, batch_size = 32 ):\n        super().__init__()\n\n        self.save_hyperparameters(ignore=['net'])\n\n        self.model = net \n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.batch_size = batch_size\n\n\n        self.train_acc = Accuracy(task= \"multiclass\",  num_classes=net.model.classifier[-1].out_features)\n        self.val_acc = Accuracy(task= \"multiclass\", num_classes=net.model.classifier[-1].out_features)\n        \n        self.test_acc = Accuracy(task= \"multiclass\",  num_classes=net.model.classifier[-1].out_features)\n        \n        # F1 score \n        self.val_f1 = F1Score(task=\"multiclass\", num_classes=net.model.classifier[-1].out_features)\n        self.test_f1 = F1Score(task=\"multiclass\", num_classes=net.model.classifier[-1].out_features)\n        # Precision\n        self.val_precision = Precision(task=\"multiclass\", num_classes=net.model.classifier[-1].out_features)   \n        self.test_precision = Precision(task=\"multiclass\", num_classes=net.model.classifier[-1].out_features)\n        # Recall\n        self.val_recall = Recall(task=\"multiclass\", num_classes=net.model.classifier[-1].out_features)\n        self.test_recall = Recall(task=\"multiclass\", num_classes=net.model.classifier[-1].out_features)\n\n        self.criterion = nn.CrossEntropyLoss()\n\n\n    def forward(self, x):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        optimizer =  optim.SGD(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n        return {\n            \"optimizer\": optimizer,\n            \"gradient_clip_val\": 1.0,  # Adjust value as needed\n        }\n    \n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        \n        loss = nn.CrossEntropyLoss()(outputs, y)\n        preds = torch.argmax(outputs, dim=1)\n        \n        # Update metrics\n        acc = self.train_acc(preds, y)\n        \n\n        self.log(\"train/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"train/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n        \n        return loss\n    \n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        \n        loss = self.criterion(outputs, y)\n        preds = torch.argmax(outputs, dim=1)\n        \n        # Update metrics\n       \n        acc =  self.val_acc(preds, y)\n        f1 =  self.val_f1(preds, y)\n        precision =  self.val_precision(preds, y)\n        recall =  self.val_recall(preds, y)\n        \n        # Log metrics\n        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/precision\", precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/recall\", recall, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n    \n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        \n        loss = self.criterion(outputs, y)\n        preds = torch.argmax(outputs, dim=1)\n        \n        # Update metrics\n        acc = self.test_acc(preds, y)\n        f1 = self.test_f1(preds, y)\n        precision = self.test_precision(preds, y)\n        recall = self.test_recall(preds, y)\n        \n        # Log metrics\n        self.log(\"test/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/precision\", precision, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/recall\", recall, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:54.152850Z","iopub.execute_input":"2025-06-03T09:05:54.153304Z","iopub.status.idle":"2025-06-03T09:05:54.199615Z","shell.execute_reply.started":"2025-06-03T09:05:54.153279Z","shell.execute_reply":"2025-06-03T09:05:54.198895Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Client","metadata":{}},{"cell_type":"code","source":"import torch \nfrom collections import OrderedDict\nfrom flwr.client import NumPyClient\nfrom flwr.common import  Context\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn \nimport logging \nimport lightning as pl\nimport warnings \nfrom lightning.pytorch.loggers.wandb import WandbLogger\nfrom lightning.pytorch.callbacks import ModelCheckpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:05:54.200446Z","iopub.execute_input":"2025-06-03T09:05:54.200690Z","iopub.status.idle":"2025-06-03T09:06:07.715832Z","shell.execute_reply.started":"2025-06-03T09:05:54.200675Z","shell.execute_reply":"2025-06-03T09:06:07.715104Z"}},"outputs":[{"name":"stderr","text":"2025-06-03 09:05:56.154917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748941556.365704      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748941556.431894      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def get_parameters(net) -> List[np.ndarray]:\n    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n\n\ndef set_parameters(net, parameters: List[np.ndarray]):\n    params_dict = zip(net.state_dict().keys(), parameters)\n    state_dict = OrderedDict({k: torch.from_numpy(np.copy(v)) for k, v in params_dict})\n    net.load_state_dict(state_dict, strict=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:07.716618Z","iopub.execute_input":"2025-06-03T09:06:07.716898Z","iopub.status.idle":"2025-06-03T09:06:08.071895Z","shell.execute_reply.started":"2025-06-03T09:06:07.716873Z","shell.execute_reply":"2025-06-03T09:06:08.071030Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class FlowerLightningClient(NumPyClient):\n\n\n    def __init__(self, model: pl.LightningModule, train_dataloader, val_dataloader, epochs, batch_size, device, client_id): \n\n        self.model = model\n        self.train_dataloader = train_dataloader\n        self.val_dataloader = val_dataloader\n        self.epochs = epochs\n        self.device = device \n        self.client_id = client_id\n        self.batch_size = batch_size\n    \n    def get_parameters(self, config):\n\n        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        if not parameters:\n            return\n\n        params_dict = zip(self.model.state_dict().keys(), parameters)\n        state_dict = OrderedDict()\n        for k, v in params_dict:\n            state_dict[k] = torch.tensor(v)\n            \n\n        if state_dict:\n            self.model.load_state_dict(state_dict, strict=False)\n\n        \n    def fit(self, parameters, config):\n\n        self.set_parameters(parameters)\n        \n        checkpoint_callback = ModelCheckpoint(\n            dirpath=f\"./checkpoints/client_{self.client_id}\",\n            filename=f\"round_{config.get('round_num', 0)}\" + \"-{epoch:02d}\",\n            save_top_k=1,\n            monitor=\"val/loss\",\n            mode=\"min\"\n        )\n\n        trainer = pl.Trainer(\n            max_epochs=self.epochs,\n            accelerator=\"auto\",\n            devices=1,\n            callbacks=[checkpoint_callback],\n            enable_progress_bar=False, \n            log_every_n_steps=1\n        )\n\n        trainer.fit(self.model, train_dataloaders=self.train_dataloader, val_dataloaders=self.val_dataloader)\n\n        callback_metrics = trainer.callback_metrics\n\n        train_loss = callback_metrics.get(\"train/loss\", 0)\n        train_accuracy = callback_metrics.get(\"train/acc\", 0)\n        val_loss = callback_metrics.get(\"val/loss\", 0)\n        val_accuracy = callback_metrics.get(\"val/acc\", 0)\n        val_precision = callback_metrics.get(\"val/precision\", 0)\n        val_recall = callback_metrics.get(\"val/recall\", 0)\n        val_f1 = callback_metrics.get(\"val/f1\", 0)\n\n\n\n        metrics = {\n            \"train_loss\": train_loss.item() if isinstance(train_loss, torch.Tensor) else float(train_loss),\n            \"train_accuracy\": train_accuracy.item() if isinstance(train_accuracy, torch.Tensor) else float(train_accuracy),\n            \"val_loss\": val_loss.item() if isinstance(val_loss, torch.Tensor) else float(val_loss),\n            \"val_accuracy\": val_accuracy.item() if isinstance(val_accuracy, torch.Tensor) else float(val_accuracy),\n            \"val_precision\": val_precision.item() if isinstance(val_precision, torch.Tensor) else float(val_precision),\n            \"val_recall\": val_recall.item() if isinstance(val_recall, torch.Tensor) else float(val_recall),\n            \"val_f1\": val_f1.item() if isinstance(val_f1, torch.Tensor) else float(val_f1)\n        }\n\n\n\n        return self.get_parameters(config={}), len(self.train_dataloader.dataset), metrics\n\n\n    def evaluate(self, parameters, config):\n\n        self.set_parameters(parameters)\n\n       \n        trainer = pl.Trainer(\n            accelerator=\"auto\",\n            devices=1 ,\n            enable_progress_bar=False\n        )\n\n        results = trainer.test(self.model, dataloaders=self.val_dataloader)\n        \n        callback_metrics = trainer.callback_metrics\n\n        test_loss = callback_metrics.get(\"test/loss\", 0)\n        test_accuracy = callback_metrics.get(\"test/acc\", 0)\n        test_f1 = callback_metrics.get(\"test/f1\", 0)\n        test_precision = callback_metrics.get(\"test/precision\", 0)\n        test_recall = callback_metrics.get(\"test/recall\", 0)\n        \n        # Additional metrics\n        metrics = {\n            \"test_loss\": test_loss.item() if isinstance(test_loss, torch.Tensor) else float(test_loss),\n            \"test_accuracy\": test_accuracy.item() if isinstance(test_accuracy, torch.Tensor) else float(test_accuracy),\n            \"test_f1\": test_f1.item() if isinstance(test_f1, torch.Tensor) else float(test_f1),\n            \"test_precision\": test_precision.item() if isinstance(test_precision, torch.Tensor) else float(test_precision),\n            \"test_recall\": test_recall.item() if isinstance(test_recall, torch.Tensor) else float(test_recall)\n        }\n\n       \n        return float(test_loss), len(self.val_dataloader.dataset), metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:08.072650Z","iopub.execute_input":"2025-06-03T09:06:08.072897Z","iopub.status.idle":"2025-06-03T09:06:08.112297Z","shell.execute_reply.started":"2025-06-03T09:06:08.072879Z","shell.execute_reply":"2025-06-03T09:06:08.111707Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def create_lightning_client_fn(device, epochs, client_datasets, batch_size, num_workers, pl_model):\n\n    def client_fn(context: Context):\n        \n        \n        client_id = context.node_config['partition-id']\n        train_dataset, val_dataset = client_datasets[client_id]\n\n        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = num_workers)\n        val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n        return FlowerLightningClient(pl_model, train_dataloader, val_dataloader, epochs, batch_size, device, client_id).to_client()\n\n    return client_fn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:08.113053Z","iopub.execute_input":"2025-06-03T09:06:08.113279Z","iopub.status.idle":"2025-06-03T09:06:08.131193Z","shell.execute_reply.started":"2025-06-03T09:06:08.113264Z","shell.execute_reply":"2025-06-03T09:06:08.130611Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import random\nimport numpy as np\nfrom typing import Dict, List, Optional, Tuple, Union\nimport flwr as fl\nfrom flwr.common import (\n    EvaluateRes,\n    FitIns,\n    FitRes,\n    Parameters,\n    EvaluateIns,\n)\nfrom flwr.server.client_proxy import ClientProxy\nfrom flwr.server.client_manager import ClientManager\nfrom flwr.server.strategy import FedAvg\nfrom flwr.common.parameter import parameters_to_ndarrays\nfrom flwr.common import ndarrays_to_parameters\nimport numpy as np \nimport torch\nfrom collections import OrderedDict\nimport wandb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:08.131869Z","iopub.execute_input":"2025-06-03T09:06:08.132154Z","iopub.status.idle":"2025-06-03T09:06:10.382791Z","shell.execute_reply.started":"2025-06-03T09:06:08.132133Z","shell.execute_reply":"2025-06-03T09:06:10.382045Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class FedAR(FedAvg):\n    def __init__(\n        self, \n        net, \n        dropout_rate_training: float = 0.3, \n        dropout_rate_eval: float = 0.3, \n        fixed_clients: Optional[List[int]] = None, \n        dropout_pattern_train: str = \"random\", \n        dropout_pattern_eval: str = \"random\",\n        eta: float = 0.1,       # Server learning rate (η)\n        rho: float = 0.1,        # Staleness exponent (ρ)\n        psi_max: float = 2.0,    # Max weight (ψ_max)\n        t0: float = 1.0,     \n        b: float = 3.0,      # (γ)\n        initial_parameters: Optional[Parameters] = None,\n        **kwargs):\n    \n        if \"fit_metrics_aggregation_fn\" not in kwargs:\n            kwargs[\"fit_metrics_aggregation_fn\"] = self.weighted_average\n        if \"evaluate_metrics_aggregation_fn\" not in kwargs:\n            kwargs[\"evaluate_metrics_aggregation_fn\"] = self.weighted_average\n\n        super().__init__(**kwargs)\n        self.dropout_rate_training = dropout_rate_training\n        self.dropout_rate_eval = dropout_rate_eval\n        self.fixed_clients = fixed_clients or []\n        self.dropout_pattern_train = dropout_pattern_train\n        self.dropout_pattern_eval = dropout_pattern_eval\n        self.current_round = 0\n        self.dropped_clients_history_training: Dict[int, List[int]] = {}\n        self.dropped_clients_history_evaluation: Dict[int, List[int]] = {}\n\n        # For tracking metrics\n        self.fit_metrics_history: List[Dict[str, float]] = []\n        self.eval_metrics_history: List[Dict[str, float]] = []\n\n        self.net = net\n        self.eta = eta\n        self.rho = rho\n        self.psi_max = psi_max\n        self.t0 = t0\n        self.b = b\n\n        # Per-client state\n        self.G: dict[str, list[np.ndarray]] = {}  # Surrogate updates\n        self.tau: dict[str, int] = {}             # Inactivity counters\n        self.psi: dict[str, float] = {}           # Staleness weights\n        self.E: set[str] = set()                  # Ever-active clients\n        self.initialized = False                  # Track if G is initialized\n        self.current_params = initial_parameters  # Initialize here\n\n    def initialize_parameters(self, client_manager: ClientManager) -> Optional[Parameters]:\n        current_params = get_parameters(self.net)\n        return ndarrays_to_parameters(current_params)\n\n    def initialize_state(self, parameters: Parameters):\n        \"\"\"Initialize surrogates to zero for all clients in E.\"\"\"\n        if self.initialized: \n            return\n        w_global = parameters_to_ndarrays(parameters)\n        for cid in self.E:\n            if cid not in self.G:  # Initialize new clients\n                self.G[cid] = [np.zeros_like(arr, dtype=np.float32) for arr in w_global]\n                self.tau[cid] = 0  # Reset inactivity counter\n                self.psi[cid] = 1.0  # Default weight for active client\n        self.initialized = True\n        \n    def weighted_average(self, metrics: List[Tuple[int, Dict]]) -> Dict:\n        \"\"\"Aggregate metrics using weighted average based on number of samples.\"\"\"\n        if not metrics:\n            return {}\n\n        total_examples = sum([num_examples for num_examples, _ in metrics])\n        weighted_metrics = {}\n\n        for metric_key in metrics[0][1].keys():\n            weighted_sum = sum(\n                metric_dict[metric_key] * num_examples\n                for num_examples, metric_dict in metrics\n                if metric_key in metric_dict\n            )\n            weighted_metrics[metric_key] = weighted_sum / total_examples if total_examples > 0 else 0\n\n        return weighted_metrics\n\n\n    def configure_fit( self, server_round: int, parameters: Parameters, client_manager: ClientManager) -> List[Tuple[ClientProxy, FitIns]]:\n        \"\"\"Configure the next round of training with client dropout.\"\"\"\n        self.current_round = server_round\n        for client in client_manager.all().values():\n            cid = client.cid\n            if cid not in self.E:\n                self.E.add(cid)\n                \n        sample_size, min_num_clients = self.num_fit_clients(\n            client_manager.num_available()\n        )\n\n        chosen_clients = client_manager.sample(\n            num_clients=sample_size,\n            min_num_clients=min_num_clients,\n        )\n\n        fit_instructions: List[Tuple[ClientProxy, FitIns]] = []\n\n        self.current_params = parameters\n\n        \n\n        self.initialize_state(parameters)\n\n        for client in chosen_clients:\n            fit_instructions.append((client, FitIns(self.current_params, {})))\n\n        available_clients = self._apply_dropout(\n            fit_instructions,\n            dropout_rate=self.dropout_rate_training,\n            dropout_pattern=self.dropout_pattern_train,\n        )\n\n        client_ids = [int(client.cid) for client, _ in fit_instructions]\n        available_client_ids = [int(client.cid) for client, _ in available_clients]\n        dropped_clients = [cid for cid in client_ids if cid not in available_client_ids]\n\n        self.dropped_clients_history_training[server_round] = dropped_clients\n\n        wandb.log({\n            \"train_dropout_history\": len(dropped_clients)\n        })\n\n        print(f\"Round {server_round}: {len(dropped_clients)} clients dropped out of {len(client_ids)} during training\")\n        print(f\"Dropped client IDs: {dropped_clients}\")\n\n        return available_clients\n    \n        \n    def configure_evaluate( self, server_round: int, parameters: Parameters, client_manager: ClientManager) -> List[Tuple[ClientProxy, EvaluateIns]]:\n        self.current_round = server_round\n\n        client_evaluate_instructions = super().configure_evaluate(\n            server_round, parameters, client_manager\n        )\n\n        if not client_evaluate_instructions: return []\n\n        available_clients = self._apply_dropout(client_evaluate_instructions, dropout_rate=self.dropout_rate_eval, dropout_pattern=self.dropout_pattern_eval)\n\n        client_ids = [int(client.cid) for client, _ in client_evaluate_instructions]\n        available_client_ids = [int(client.cid) for client, _ in available_clients]\n        dropped_clients = [cid for cid in client_ids if cid not in available_client_ids]\n\n        self.dropped_clients_history_evaluation[server_round] = dropped_clients\n        wandb.log({\n            \"eval_dropout_history\" : len(dropped_clients) \n        })\n\n        print(f\"Round {server_round}: {len(dropped_clients)} clients dropped out of {len(client_ids)} during evaluation\")\n        print(f\"Dropped client IDs: {dropped_clients}\")\n\n        return available_clients\n\n    def _apply_dropout(self, client_instructions: List[Tuple[ClientProxy, Union[FitIns, EvaluateIns ]]], dropout_pattern: str, dropout_rate: 0.3) -> List[Tuple[ClientProxy, FitIns]]:\n        \"\"\"Apply dropout to clients based on the specified pattern.\"\"\"\n        if len(client_instructions) == 0:\n            return []\n\n        # Get all client IDs\n        all_clients = [(client, ins) for client, ins in client_instructions]\n        all_client_ids = [int(client.cid) for client, _ in all_clients]\n\n        # Determine which clients will drop out\n        dropout_mask = [False] * len(all_clients)\n\n        if dropout_pattern == \"random\":\n           \n            for i, cid in enumerate(all_client_ids):\n                \n                if cid in self.fixed_clients:\n                    continue\n            \n                if random.random() < dropout_rate:\n                    dropout_mask[i] = True\n\n        elif dropout_pattern == \"alternate\":\n         \n            if self.current_round % 2 == 1:  \n                for i, cid in enumerate(all_client_ids):\n                    if cid not in self.fixed_clients:\n                        dropout_mask[i] = True\n\n        elif dropout_pattern == \"fixed\":\n      \n            n_dropout = int(len(all_clients) * dropout_rate)\n            for i in range(n_dropout):\n                if all_client_ids[i] not in self.fixed_clients:\n                    dropout_mask[i] = True\n\n        \n        available_clients = [\n            (client, ins) for i, (client, ins) in enumerate(all_clients)\n            if not dropout_mask[i]\n        ]\n\n        return available_clients\n\n    def g(self, server_round: int):\n        return self.t0 + server_round/self.b \n\n    def aggregate_fit(self, server_round: int, results: List[Tuple[ClientProxy, FitRes]], failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]]):\n\n        if not results:\n            return None, {}\n\n        #valid_results = [(client_proxy, res) for client_proxy, res in results if res.status.code == Code.OK]\n        #if not valid_results:\n            #return None, {}\n\n        g_t = self.g(server_round)\n        w_global = parameters_to_ndarrays(self.current_params)\n        updated_cids = set()\n        for client, fit_res in results:\n            cid = client.cid\n            w_client = parameters_to_ndarrays(fit_res.parameters)\n            self.G[cid] = [\n                (w_g - w_c) / self.eta \n                for w_g, w_c in zip(w_global, w_client)\n            ]\n            self.tau[cid] = 0     # Reset inactivity counter (Eq. 5)\n            self.psi[cid] = 1.0   # Active clients: ψ=1 (Eq. 6)\n            updated_cids.add(cid)\n        print(len(updated_cids))\n            \n        for cid in self.E:\n            if cid not in updated_cids:\n                self.tau[cid] += 1\n                \n        for cid in self.E:\n            tau_val = self.tau[cid]\n            if tau_val >= g_t:  # Exclude stale clients\n                self.psi[cid] = 0.0\n            else:\n                # ψ = min( (τ+1)^ρ, ψ_max )\n                self.psi[cid] = min((tau_val + 1) ** self.rho, 2)\n                \n        contributing_cids = [client.cid for client, _ in results]\n        N_t = len(contributing_cids)\n        if N_t == 0:\n            return None, {}\n\n        weighted_update = None\n        for cid in contributing_cids:\n            psi_i = self.psi[cid]\n            update_i = [psi_i * g_arr for g_arr in self.G[cid]]\n            if weighted_update is None:\n                weighted_update = update_i\n            else:\n                weighted_update = [\n                    w_u + u_i for w_u, u_i in zip(weighted_update, update_i)\n                ]\n        avg_update = [arr / N_t for arr in weighted_update]\n\n        new_weights = [\n            w_global[i] - self.eta * avg_update[i]\n            for i in range(len(w_global))\n        ]\n        aggregated = ndarrays_to_parameters(new_weights)\n        self.current_params = aggregated\n\n        if aggregated is not None:\n            aggregated_ndarrays: list[np.ndarray] = fl.common.parameters_to_ndarrays(\n                aggregated\n            )\n\n            params_dict = zip(self.net.state_dict().keys(), aggregated_ndarrays)\n            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n            self.net.load_state_dict(state_dict, strict=True)\n\n            torch.save(self.net.state_dict(), f\"model_round_{server_round}.pth\")\n        aggregated_metrics = {}\n        if results:\n            metrics = [(res.num_examples, res.metrics) for _, res in results]\n            aggregated_metrics = self.weighted_average(metrics)\n            self.fit_metrics_history.append(aggregated_metrics)\n\n            wandb.log({\n                \"train_server_round\": server_round, \n                \"train_accuracy\": aggregated_metrics.get(\"train_accuracy\", 0.0), \n                \"train_loss\" : aggregated_metrics.get(\"train_loss\", 0.0)\n            })\n\n\n            print(f\"Round {server_round} training metrics: {aggregated_metrics}\")\n\n        return aggregated, aggregated_metrics\n\n    def aggregate_evaluate( self, server_round: int, results: List[Tuple[ClientProxy, EvaluateRes]],  failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]):\n        \n        aggregated = super().aggregate_evaluate(server_round, results, failures)\n\n        if results:\n            metrics = [(res.num_examples, res.metrics) for _, res in results]\n            aggregated_metrics = self.weighted_average(metrics)\n            self.eval_metrics_history.append(aggregated_metrics)\n\n            print(f\"Round {server_round} evaluation metrics: {aggregated_metrics}\")\n\n            wandb.log({\n                \"server_round_eval\" : server_round,\n                \"test_accuracy\": aggregated_metrics.get(\"test_accuracy\", 0.0), \n                \"test_loss\" : aggregated_metrics.get(\"test_loss\", 0.0), \n                 \"test_f1\": aggregated_metrics.get(\"test_f1\", 0.0), \n                \"test_precision\" : aggregated_metrics.get(\"test_precision\", 0.0), \n                 \"test_recall\": aggregated_metrics.get(\"test_recall\", 0.0), \n            })\n\n        return aggregated\n\n    def get_dropout_history(self) -> Dict[int, List[int]]:\n        return self.dropped_clients_history_training, self.dropped_clients_history_evaluation\n\n    def get_metrics_history(self) -> Tuple[List[Dict[str, float]], List[Dict[str, float]]]: \n        return self.fit_metrics_history, self.eval_metrics_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:10.383671Z","iopub.execute_input":"2025-06-03T09:06:10.383950Z","iopub.status.idle":"2025-06-03T09:06:10.414999Z","shell.execute_reply.started":"2025-06-03T09:06:10.383933Z","shell.execute_reply":"2025-06-03T09:06:10.414321Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from flwr.client import ClientApp\nfrom flwr.server import ServerApp\nfrom flwr.simulation import run_simulation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom typing import Dict, List, Optional\nimport os\nfrom flwr.common import Context\nimport torch \nimport lightning as pl\nfrom typing import Union","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:10.415686Z","iopub.execute_input":"2025-06-03T09:06:10.415971Z","iopub.status.idle":"2025-06-03T09:06:10.440622Z","shell.execute_reply.started":"2025-06-03T09:06:10.415953Z","shell.execute_reply":"2025-06-03T09:06:10.439902Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def run_dropout_experiment(\n    client_fn_creator,\n    pl_model : Union[pl.LightningModule, torch.nn.Module], \n    num_clients: int,\n    num_rounds: int = 10,\n    dropout_rate_training: float = 0.3,\n    dropout_rate_eval: float = 0.3,\n    dropout_pattern_train: str = \"random\",\n    dropout_pattern_eval: str = \"random\",\n    fixed_clients: Optional[List[int]] = None,\n    experiment_name: str = \"dropout_experiment\",\n    save_dir: str = \"model_weights\",\n    num_gpus : int = 0, \n    resource_config : Optional[Dict[str, float]] = None,\n\n):\n    \n      # Configure client app\n    print(f\"\\nStarting experiment: {experiment_name}\")\n    print(f\"Dropout rate training: {dropout_rate_training}, Pattern: {dropout_pattern_train}\")\n    print(f\"Dropout rate evaluation: {dropout_rate_eval}, Pattern: {dropout_pattern_eval   }\")\n    print(f\"Number of GPUs: {num_gpus}\")\n    print(f\"Number of clients: {num_clients}\")\n    print(f\"Number of rounds: {num_rounds}\")\n    print(f\"Fixed clients: {fixed_clients or []}\")\n\n    # Create strategy with dropout\n    strategy = FedAR(\n        net=pl_model.model if isinstance(pl_model, pl.LightningModule) else pl_model,\n        dropout_rate_training=dropout_rate_training,\n        dropout_rate_eval=dropout_rate_eval,\n        dropout_pattern_train=dropout_pattern_train,\n        dropout_pattern_eval=dropout_pattern_eval,\n        fixed_clients=fixed_clients or [],\n        fraction_fit=1.0,\n        fraction_evaluate=1.0,\n        min_fit_clients=1,\n        min_evaluate_clients=1,\n        min_available_clients=1,\n\n    )\n\n    # Configure server with strategy\n    def server_fn(server_context: Context):\n        from flwr.server import ServerAppComponents, ServerConfig\n        config = ServerConfig(num_rounds=num_rounds)\n        return ServerAppComponents(strategy=strategy, config=config)\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    epochs = resource_config.get(\"epochs\", 1) if resource_config else 1\n    client_datasets = resource_config.get(\"client_datasets\", {}) if resource_config else {}\n\n    \n    batch_size = resource_config.get(\"batch_size\", 32) if resource_config else 32\n    learning_rate = resource_config.get(\"learning_rate\", 0.001) if resource_config else 0.001\n    num_workers = resource_config.get(\"num_workers\", 1) if resource_config else 1\n    client_fn = client_fn_creator(device=device, epochs=epochs, client_datasets=client_datasets\n                                , batch_size=batch_size, pl_model=pl_model, num_workers=num_workers)\n    \n    # Create client and server apps\n    client_app = ClientApp(client_fn=client_fn)\n    server_app = ServerApp(server_fn=server_fn)\n\n    # Configure backend\n    backend_config = {\n        \"client_resources\": {\n            \"num_cpus\": 1,\n            \"num_gpus\": num_gpus,\n        }\n    }\n    history = strategy.get_dropout_history()\n    # Run simulation\n    try:\n        run_simulation(\n            client_app=client_app,\n            server_app=server_app,\n            num_supernodes=num_clients,\n            backend_config=backend_config,\n        )\n\n        # Get metrics directly from strategy\n        fit_metrics, eval_metrics = strategy.get_metrics_history()\n\n        # Format metrics for plotting\n        rounds = list(range(1, len(eval_metrics) + 1))\n\n        train_accuracy_values = [metrics.get(\"train_accuracy\", 0.0) for metrics in fit_metrics]\n        train_loss_values = [metrics.get(\"train_loss\", 0.0) for metrics in fit_metrics]\n        \n\n        test_accuracy_values = [metrics.get(\"test_accuracy\", 0.0) for metrics in eval_metrics]\n        test_loss_values = [metrics.get(\"test_loss\", 0.0) for metrics in eval_metrics]\n        test_f1_values = [metrics.get(\"test_f1\", 0.0) for metrics in eval_metrics]\n        test_precision_values = [metrics.get(\"test_precision\", 0.0) for metrics in eval_metrics]\n        test_recall_values = [metrics.get(\"test_recall\", 0.0) for metrics in eval_metrics]    \n\n\n        # cleanup_wandb_loggers()\n\n        results = {\n            \"rounds\": rounds,\n            \"train_accuracy\": train_accuracy_values,\n            \"train_loss\": train_loss_values,\n\n            \"test_accuracy\": test_accuracy_values,\n            \"test_loss\": test_loss_values,\n            \"test_f1\": test_f1_values,\n            \"test_precision\": test_precision_values,\n            \"test_recall\": test_recall_values\n        }\n\n        return results, history\n    \n    except Exception as e:\n        print(f\"Error in dropout experiment: {e}\")\n        import traceback\n        traceback.print_exc()\n        return {\"error\": str(e)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:10.441537Z","iopub.execute_input":"2025-06-03T09:06:10.442060Z","iopub.status.idle":"2025-06-03T09:06:10.460549Z","shell.execute_reply.started":"2025-06-03T09:06:10.442025Z","shell.execute_reply":"2025-06-03T09:06:10.459710Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"from typing import List, Dict, Tuple, Optional, Union\nimport torch.nn as nn \nimport hydra \nfrom omegaconf import DictConfig, OmegaConf\nimport logging \nimport wandb \nimport os \nimport warnings\nimport lightning as pl ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:10.461483Z","iopub.execute_input":"2025-06-03T09:06:10.462241Z","iopub.status.idle":"2025-06-03T09:06:10.710364Z","shell.execute_reply.started":"2025-06-03T09:06:10.462225Z","shell.execute_reply":"2025-06-03T09:06:10.709808Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Config ","metadata":{}},{"cell_type":"code","source":"config = {\n    \"base_path\": \"/kaggle\",\n    \"device\": \"cuda\",  # from train.device\n    \"run_name\": \"dropout_0.5_2D_FedAR\",  # resolved using experiment values\n    \"seed\": 42,\n    \"num_clients\": 10,\n    \"num_rounds\": 10,\n    \"gpus\": 1,\n    \n    \"train\": {\n        \"batch_size\": 16,\n        \"learning_rate\": 0.1,\n        \"epochs\": 1,\n        \"device\": \"cuda\",\n        \"num_workers\": 2,\n        \"weight_decay\": 0.0001,\n        \"scheduler\": {\n            \"use\": False,\n            \"type\": \"cosine\",\n            \"warmup_epochs\": 1,\n            \"min_lr\": 0.01,\n        }\n    },\n\n    \"experiment\": {\n        \"pattern_train\": \"random\",\n        \"pattern_eval\": \"random\",\n        \"dropout_rate_training\": 0.0,\n        \"dropout_rate_eval\": 0.0,\n        \"fixed_clients\": [0, 1, 2, 3],\n        \"name\": \"dropout_0.0_2D_FedAR\",\n    },\n\n    \"data\": {\n        \"root_path\": \"/kaggle/input/mri-dataset/datasetzip/not_skull_stripped\",\n        \"label_path\": \"/kaggle/input/mri-label/label.csv\",\n        \"val_ratio\": 0.2,\n        \"overlap_ratio\": 0.2,\n        \"distribution\": \"same\",\n    },\n    \"is_3d\": False\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:10.713213Z","iopub.execute_input":"2025-06-03T09:06:10.713425Z","iopub.status.idle":"2025-06-03T09:06:10.718549Z","shell.execute_reply.started":"2025-06-03T09:06:10.713409Z","shell.execute_reply":"2025-06-03T09:06:10.717917Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def run_experiment_with_lightning(cfg_dict: dict) -> None:\n    cfg: DictConfig = OmegaConf.create(cfg_dict)  # convert to DictConfig to retain dot-access\n    logger =  logger = logging.getLogger(__name__)\n    logger.info(f\"Running experiment with config: {cfg.experiment.name}\")\n    logger.info(f\"Config: {OmegaConf.to_yaml(cfg)}\")\n\n    wandb.login(\n        key=WANDB_APIKEY \n    )\n\n    wandb.init(\n        project=\"federated-mri-server\",\n        name=f\"{cfg.experiment.name}\",\n        config=OmegaConf.to_container(cfg, resolve=True),\n        group=\"server\"\n    )\n\n    device = cfg.device\n    epochs = cfg.train.epochs\n\n    logger.info(\"Loading model\")\n\n    net : nn.Module() = BrainMRINet()\n    pl_model : pl.LightningModule = BrainMRILightningModule(net = net )\n\n\n    \n    # net: nn.Module = DenseNet()\n    # pl_model: pl.LightningModule = DenseNetModule(net = net)\n\n    logger.info(\"Loading dataset\")\n    is_3d = True if isinstance(pl_model, DenseNetModule) else False\n    print(f\"Is 3D: {is_3d}\")\n\n    full_dataset = MRIDataset(\n        root_dir=cfg.data.root_path,\n        label_path=cfg.data.label_path,\n        is_3d=is_3d\n    )\n\n    logger.info(f\"Dataset loaded successfully with len is {len(full_dataset)}\")\n    logger.info(f\"Splitting dataset into {cfg.num_clients} clients\")\n\n    if cfg.data.distribution == \"iid\":\n        client_datasets = iid_client_split(\n            full_dataset,\n            num_client=cfg.num_clients,\n            val_ratio=cfg.data.val_ratio\n        )\n    elif cfg.data.distribution == \"same\":\n        client_datasets = same_distribution_client_split(\n            full_dataset,\n            num_client=cfg.num_clients,\n            val_ratio=cfg.data.val_ratio,\n            overlap_ratio=cfg.data.overlap_ratio,\n            root_dir=cfg.data.root_path,\n            is_3d=is_3d\n        )\n    else:\n        raise ValueError(f\"Unknown distribution type: {cfg.data.distribution}\")\n\n    logger.info(f\"Client datasets created successfully with {len(client_datasets)} clients\")\n\n    resources = {\n        \"client_datasets\": client_datasets,\n        \"device\": device,\n        \"epochs\": epochs,\n        \"batch_size\": cfg.train.batch_size,\n        \"learning_rate\": cfg.train.learning_rate,\n        \"num_workers\": cfg.train.num_workers\n    }\n\n    logger.info(\"Running experiments with PyTorch Lightning\")\n\n    results, history = run_dropout_experiment(\n        client_fn_creator=create_lightning_client_fn,\n        pl_model=pl_model,\n        num_clients=cfg.num_clients,\n        num_rounds=cfg.num_rounds,\n        dropout_rate_training=cfg.experiment.dropout_rate_training,\n        dropout_rate_eval=cfg.experiment.dropout_rate_eval,\n        dropout_pattern_train=cfg.experiment.pattern_train,\n        dropout_pattern_eval=cfg.experiment.pattern_eval,\n        experiment_name=cfg.experiment.name,\n        num_gpus=cfg.gpus,\n        resource_config=resources\n    )\n\n    logger.info(\"Run successfully + wandb tracking\")\n    print(f\"Result is {results}\")\n\n    # for idx in range(len(results[\"rounds\"])):\n    #     wandb.log({\n    #         \"round\": idx,\n    #         \"train_accuracy\": results[\"train_accuracy\"][-1] if idx > len(results[\"train_accuracy\"]) - 1 else results[\"train_accuracy\"][idx],\n    #         \"train_loss\": results[\"train_loss\"][-1] if idx > len(results[\"train_loss\"]) - 1 else results[\"train_loss\"][idx],\n    #         \"test_accuracy\": results[\"test_accuracy\"][-1] if idx > len(results[\"test_accuracy\"]) - 1 else results[\"test_accuracy\"][idx],\n    #         \"test_loss\": results[\"test_loss\"][-1] if idx > len(results[\"test_loss\"]) - 1 else results[\"test_loss\"][idx],\n    #         \"test_f1\": results[\"test_f1\"][-1] if idx > len(results[\"test_f1\"]) - 1 else results[\"test_f1\"][idx],\n    #         \"test_precision\": results[\"test_precision\"][-1] if idx > len(results[\"test_precision\"]) - 1 else results[\"test_precision\"][idx],\n    #         \"test_recall\": results[\"test_recall\"][-1] if idx > len(results[\"test_recall\"]) - 1 else results[\"test_recall\"][idx],\n    #     })\n\n    # Log dropout history\n    # for round_idx, dropped in history[0].items():\n    #     wandb.log({\n    #         \"dropped_clients_train_count\": len(dropped),\n    #         \"dropped_clients\": wandb.Table(\n    #             columns=[\"client_id\"],\n    #             data=[[client_id] for client_id in dropped]\n    #         )\n    #     })\n\n    # for round_idx, dropped in history[1].items():\n    #     wandb.log({\n    #         \"dropped_clients_eval_count\": len(dropped),\n    #         \"dropped_clients\": wandb.Table(\n    #             columns=[\"client_id\"],\n    #             data=[[client_id] for client_id in dropped]\n    #         )\n    #     })\n\n    wandb.finish()\n\n    logger.info(\"Experiments completed successfully\")\n    logger.info(f\"Client Dropout History: {history}\")\n\n    return results, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:10.719483Z","iopub.execute_input":"2025-06-03T09:06:10.719714Z","iopub.status.idle":"2025-06-03T09:06:10.736666Z","shell.execute_reply.started":"2025-06-03T09:06:10.719689Z","shell.execute_reply":"2025-06-03T09:06:10.735948Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"run_experiment_with_lightning(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:06:10.737482Z","iopub.execute_input":"2025-06-03T09:06:10.738020Z","iopub.status.idle":"2025-06-03T09:37:26.845745Z","shell.execute_reply.started":"2025-06-03T09:06:10.737996Z","shell.execute_reply":"2025-06-03T09:37:26.844922Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n  return LooseVersion(v) >= LooseVersion(check)\n/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_bokeh.py:16: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n  import imp  # pylint: disable=deprecated-module\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msang2222004\u001b[0m (\u001b[33msang2222004-uet-vnu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py:259: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n  self.scope.user = {\"email\": email}  # noqa\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250603_090616-vbea5c2y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sang2222004-uet-vnu/federated-mri-server/runs/vbea5c2y' target=\"_blank\">dropout_0.0_2D_FedAR</a></strong> to <a href='https://wandb.ai/sang2222004-uet-vnu/federated-mri-server' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sang2222004-uet-vnu/federated-mri-server' target=\"_blank\">https://wandb.ai/sang2222004-uet-vnu/federated-mri-server</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sang2222004-uet-vnu/federated-mri-server/runs/vbea5c2y' target=\"_blank\">https://wandb.ai/sang2222004-uet-vnu/federated-mri-server/runs/vbea5c2y</a>"},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:01<00:00, 22.2MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Is 3D: False\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [INIT]\n\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 1]\n","output_type":"stream"},{"name":"stdout","text":"\nStarting experiment: dropout_0.0_2D_FedAR\nDropout rate training: 0.0, Pattern: random\nDropout rate evaluation: 0.0, Pattern: random\nNumber of GPUs: 1\nNumber of clients: 10\nNumber of rounds: 10\nFixed clients: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 1: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(pid=460)\u001b[0m 2025-06-03 09:15:39.948298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[36m(pid=460)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n\u001b[36m(pid=460)\u001b[0m E0000 00:00:1748942139.971412     460 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[36m(pid=460)\u001b[0m E0000 00:00:1748942139.978330     460 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(pid=459)\u001b[0m 2025-06-03 09:15:39.948188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[36m(pid=459)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n\u001b[36m(pid=459)\u001b[0m E0000 00:00:1748942139.971446     459 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[36m(pid=459)\u001b[0m E0000 00:00:1748942139.978301     459 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 1 training metrics: {'train_loss': 0.6954506263689461, 'train_accuracy': 0.5397329902871227, 'val_loss': 0.6638506806156953, 'val_accuracy': 0.5950948914169988, 'val_precision': 0.5950948914169988, 'val_recall': 0.5950948914169988, 'val_f1': 0.5950948914169988}\nRound 1: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │           0.625           │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │           0.625           │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.6664143800735474     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │           0.625           │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │           0.625           │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.5166666507720947     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.5166666507720947     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │     0.684148907661438     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.5166666507720947     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.5166666507720947     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 2]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.7425742745399475     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.7425742745399475     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6307017803192139     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.7425742745399475     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.7425742745399475     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 5x across cluster]\u001b[0m\nRound 1 evaluation metrics: {'test_loss': 0.6735665339846338, 'test_accuracy': 0.5745950595802053, 'test_f1': 0.5745950595802053, 'test_precision': 0.5745950595802053, 'test_recall': 0.5745950595802053}\nRound 2: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 2 training metrics: {'train_loss': 0.6649422445118389, 'train_accuracy': 0.5920745988952126, 'val_loss': 0.6482905142133987, 'val_accuracy': 0.6266108573645094, 'val_precision': 0.6266108573645094, 'val_recall': 0.6266108573645094, 'val_f1': 0.6266108573645094}\nRound 2: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │      0.6939697265625      │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.4749999940395355     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6678038239479065     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.5666666626930237     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6560152173042297     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.6083333492279053     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │     0.574999988079071     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │     0.574999988079071     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6715724468231201     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │     0.574999988079071     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │     0.574999988079071     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 3]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 2 evaluation metrics: {'test_loss': 0.6602253396086274, 'test_accuracy': 0.5959079376368673, 'test_f1': 0.5959079376368673, 'test_precision': 0.5959079376368673, 'test_recall': 0.5959079376368673}\nRound 3: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 3 training metrics: {'train_loss': 0.6493892251093728, 'train_accuracy': 0.618139439542103, 'val_loss': 0.6351017388885217, 'val_accuracy': 0.6488110363597106, 'val_precision': 0.6488110363597106, 'val_recall': 0.6488110363597106, 'val_f1': 0.6488110363597106}\nRound 3: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.46666666865348816    │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.46666666865348816    │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.6884763836860657     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.46666666865348816    │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.46666666865348816    │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 5x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.5333333611488342     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.5333333611488342     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.6674689054489136     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.5333333611488342     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.5333333611488342     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.5416666865348816     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.5416666865348816     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6695674061775208     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.5416666865348816     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.5416666865348816     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 5x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 4]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 3 evaluation metrics: {'test_loss': 0.6506723929752373, 'test_accuracy': 0.6018755375983261, 'test_f1': 0.6018755375983261, 'test_precision': 0.6018755375983261, 'test_recall': 0.6018755375983261}\nRound 4: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 4 training metrics: {'train_loss': 0.6334784268120331, 'train_accuracy': 0.6425090095935724, 'val_loss': 0.6148267088362817, 'val_accuracy': 0.6820459358518874, 'val_precision': 0.6820459358518874, 'val_recall': 0.6820459358518874, 'val_f1': 0.6820459358518874}\nRound 4: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │            0.5            │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │            0.5            │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6780012845993042     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │            0.5            │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │            0.5            │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 2x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.6000000238418579     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.6000000238418579     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6475712656974792     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.6000000238418579     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.6000000238418579     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.6666666865348816     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.6666666865348816     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6302539706230164     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.6666666865348816     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.6666666865348816     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 5]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 4 evaluation metrics: {'test_loss': 0.6435601292567078, 'test_accuracy': 0.6138107516983078, 'test_f1': 0.6138107516983078, 'test_precision': 0.6138107516983078, 'test_recall': 0.6138107516983078}\nRound 5: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 5 training metrics: {'train_loss': 0.6138293668864566, 'train_accuracy': 0.6662428354681434, 'val_loss': 0.6012655865037105, 'val_accuracy': 0.7075811166787557, 'val_precision': 0.7075811166787557, 'val_recall': 0.7075811166787557, 'val_f1': 0.7075811166787557}\nRound 5: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.5416666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.5416666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │     0.658025860786438     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.5416666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.5416666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │           0.625           │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │           0.625           │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.6418447494506836     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │           0.625           │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │           0.625           │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │     0.801980197429657     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │     0.801980197429657     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5678902268409729     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │     0.801980197429657     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │     0.801980197429657     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 6]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 5 evaluation metrics: {'test_loss': 0.625996288486962, 'test_accuracy': 0.6632566127834011, 'test_f1': 0.6632566127834011, 'test_precision': 0.6632566127834011, 'test_recall': 0.6632566127834011}\nRound 6: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 6 training metrics: {'train_loss': 0.5914670087367101, 'train_accuracy': 0.695698235140536, 'val_loss': 0.5797211717538698, 'val_accuracy': 0.7289100263577999, 'val_precision': 0.7289100263577999, 'val_recall': 0.7289100263577999, 'val_f1': 0.7289100263577999}\nRound 6: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.7083333134651184     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.7083333134651184     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5864861607551575     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.7083333134651184     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.7083333134651184     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 2x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │     0.752136766910553     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │     0.752136766910553     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.5846002101898193     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │     0.752136766910553     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │     0.752136766910553     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.7166666388511658     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.7166666388511658     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.6095553636550903     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.7166666388511658     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.7166666388511658     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 7]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 6 evaluation metrics: {'test_loss': 0.5983696473224084, 'test_accuracy': 0.7075873747506105, 'test_f1': 0.7075873747506105, 'test_precision': 0.7075873747506105, 'test_recall': 0.7075873747506105}\nRound 7: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 7 training metrics: {'train_loss': 0.57215770026288, 'train_accuracy': 0.7143462560873564, 'val_loss': 0.5595616697759844, 'val_accuracy': 0.7510805226125109, 'val_precision': 0.7510805226125109, 'val_recall': 0.7510805226125109, 'val_f1': 0.7510805226125109}\nRound 7: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │     0.782608687877655     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │     0.782608687877655     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5598809719085693     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │     0.782608687877655     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │     0.782608687877655     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 2x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │     0.699999988079071     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │     0.699999988079071     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5937467813491821     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │     0.699999988079071     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │     0.699999988079071     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 8]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.7692307829856873     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.7692307829856873     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5607014298439026     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.7692307829856873     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.7692307829856873     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 5x across cluster]\u001b[0m\nRound 7 evaluation metrics: {'test_loss': 0.5722826218259507, 'test_accuracy': 0.7280477415468585, 'test_f1': 0.7280477415468585, 'test_precision': 0.7280477415468585, 'test_recall': 0.7280477415468585}\nRound 8: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 8 training metrics: {'train_loss': 0.5540827075968761, 'train_accuracy': 0.7387158244968244, 'val_loss': 0.536619291325246, 'val_accuracy': 0.7783450545408787, 'val_precision': 0.7783450545408787, 'val_recall': 0.7783450545408787, 'val_f1': 0.7783450545408787}\nRound 8: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.7916666865348816     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.7916666865348816     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.5412177443504333     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.7916666865348816     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.7916666865348816     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.7583333253860474     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.7583333253860474     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5662622451782227     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.7583333253860474     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.7583333253860474     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 2x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │     0.791304349899292     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │     0.791304349899292     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5387614965438843     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │     0.791304349899292     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │     0.791304349899292     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.7916666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.7916666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5510151982307434     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.7916666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.7916666865348816     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 9]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 8 evaluation metrics: {'test_loss': 0.5484245953047672, 'test_accuracy': 0.7715260072945532, 'test_f1': 0.7715260072945532, 'test_precision': 0.7715260072945532, 'test_recall': 0.7715260072945532}\nRound 9: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 9 training metrics: {'train_loss': 0.5296107274315371, 'train_accuracy': 0.7660521288296004, 'val_loss': 0.5168221042832724, 'val_accuracy': 0.7911317986713473, 'val_precision': 0.7911317986713473, 'val_recall': 0.7911317986713473, 'val_f1': 0.7911317986713473}\nRound 9: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.7333333492279053     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.7333333492279053     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5602340698242188     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.7333333492279053     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.7333333492279053     │\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 2x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │     0.800000011920929     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │     0.800000011920929     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5209615230560303     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │     0.800000011920929     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │     0.800000011920929     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 10]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │     0.800000011920929     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │     0.800000011920929     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.5350551605224609     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │     0.800000011920929     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │     0.800000011920929     │\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 5x across cluster]\u001b[0m\nRound 9 evaluation metrics: {'test_loss': 0.532280720840228, 'test_accuracy': 0.7860187686922605, 'test_f1': 0.7860187686922605, 'test_precision': 0.7860187686922605, 'test_recall': 0.7860187686922605}\nRound 10: 0 clients dropped out of 10 during training\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_0 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 4  | val_f1         | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_1 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_2 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_4 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_5 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_7 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_8 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_9 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_3 exists and is not empty.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=459)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints/client_6 exists and is not empty.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=460)\u001b[0m /usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py:378: Found unsupported keys in the optimizer configuration: {'gradient_clip_val'}\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: \n\u001b[36m(ClientAppActor pid=460)\u001b[0m    | Name           | Type                | Params | Mode \n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0  | model          | BrainMRINet         | 7.2 M  | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 1  | train_acc      | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 2  | val_acc        | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 3  | test_acc       | MulticlassAccuracy  | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 6  | val_precision  | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7  | test_precision | MulticlassPrecision | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 8  | val_recall     | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 9  | test_recall    | MulticlassRecall    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 10 | criterion      | CrossEntropyLoss    | 0      | train\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Non-trainable params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 7.2 M     Total params\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 28.867    Total estimated model params size (MB)\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 448       Modules in train mode\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 0         Modules in eval mode\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ----------------------------------------------------------------\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m 5  | test_f1        | MulticlassF1Score   | 0      | train\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n","output_type":"stream"},{"name":"stdout","text":"10\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n","output_type":"stream"},{"name":"stdout","text":"Round 10 training metrics: {'train_loss': 0.5095909397514676, 'train_accuracy': 0.7808857814415352, 'val_loss': 0.4922794470230789, 'val_accuracy': 0.8192693996944779, 'val_precision': 0.8192693996944779, 'val_recall': 0.8192693996944779, 'val_f1': 0.8192693996944779}\nRound 10: 0 clients dropped out of 10 during evaluation\nDropped client IDs: []\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │     0.824999988079071     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │     0.824999988079071     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.49893683195114136    │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │     0.824999988079071     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │     0.824999988079071     │\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.8333333134651184     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.8333333134651184     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │    0.49737733602523804    │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.8333333134651184     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.8333333134651184     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n\u001b[36m(ClientAppActor pid=459)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/acc          │    0.7416666746139526     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │          test/f1          │    0.7416666746139526     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │         test/loss         │     0.535900354385376     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │      test/precision       │    0.7416666746139526     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m │        test/recall        │    0.7416666746139526     │\n\u001b[36m(ClientAppActor pid=459)\u001b[0m └───────────────────────────┴───────────────────────────┘\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.8260869383811951     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.8260869383811951     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.49357813596725464    │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.8260869383811951     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.8260869383811951     │\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 3x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: GPU available: True (cuda), used: True\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: HPU available: False, using: 0 HPUs\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=459)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/acc          │    0.8166666626930237     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │          test/f1          │    0.8166666626930237     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │         test/loss         │    0.5131483674049377     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │      test/precision       │    0.8166666626930237     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m │        test/recall        │    0.8166666626930237     │\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=460)\u001b[0m └───────────────────────────┴───────────────────────────┘\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [SUMMARY]\n\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 1310.77s\n\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6735665339846338\n\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6602253396086274\n\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.6506723929752373\n\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.6435601292567078\n\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.625996288486962\n\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.5983696473224084\n\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.5722826218259507\n\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.5484245953047672\n\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.532280720840228\n\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.5023106954490031\n\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n\u001b[92mINFO \u001b[0m:      \t{'train_accuracy': [(1, 0.5397329902871227),\n\u001b[92mINFO \u001b[0m:      \t                    (2, 0.5920745988952126),\n\u001b[92mINFO \u001b[0m:      \t                    (3, 0.618139439542103),\n\u001b[92mINFO \u001b[0m:      \t                    (4, 0.6425090095935724),\n\u001b[92mINFO \u001b[0m:      \t                    (5, 0.6662428354681434),\n\u001b[92mINFO \u001b[0m:      \t                    (6, 0.695698235140536),\n\u001b[92mINFO \u001b[0m:      \t                    (7, 0.7143462560873564),\n\u001b[92mINFO \u001b[0m:      \t                    (8, 0.7387158244968244),\n\u001b[92mINFO \u001b[0m:      \t                    (9, 0.7660521288296004),\n\u001b[92mINFO \u001b[0m:      \t                    (10, 0.7808857814415352)],\n\u001b[92mINFO \u001b[0m:      \t 'train_loss': [(1, 0.6954506263689461),\n\u001b[92mINFO \u001b[0m:      \t                (2, 0.6649422445118389),\n\u001b[92mINFO \u001b[0m:      \t                (3, 0.6493892251093728),\n\u001b[92mINFO \u001b[0m:      \t                (4, 0.6334784268120331),\n\u001b[92mINFO \u001b[0m:      \t                (5, 0.6138293668864566),\n\u001b[92mINFO \u001b[0m:      \t                (6, 0.5914670087367101),\n\u001b[92mINFO \u001b[0m:      \t                (7, 0.57215770026288),\n\u001b[92mINFO \u001b[0m:      \t                (8, 0.5540827075968761),\n\u001b[92mINFO \u001b[0m:      \t                (9, 0.5296107274315371),\n\u001b[92mINFO \u001b[0m:      \t                (10, 0.5095909397514676)],\n\u001b[92mINFO \u001b[0m:      \t 'val_accuracy': [(1, 0.5950948914169988),\n\u001b[92mINFO \u001b[0m:      \t                  (2, 0.6266108573645094),\n\u001b[92mINFO \u001b[0m:      \t                  (3, 0.6488110363597106),\n\u001b[92mINFO \u001b[0m:      \t                  (4, 0.6820459358518874),\n\u001b[92mINFO \u001b[0m:      \t                  (5, 0.7075811166787557),\n\u001b[92mINFO \u001b[0m:      \t                  (6, 0.7289100263577999),\n\u001b[92mINFO \u001b[0m:      \t                  (7, 0.7510805226125109),\n\u001b[92mINFO \u001b[0m:      \t                  (8, 0.7783450545408787),\n\u001b[92mINFO \u001b[0m:      \t                  (9, 0.7911317986713473),\n\u001b[92mINFO \u001b[0m:      \t                  (10, 0.8192693996944779)],\n\u001b[92mINFO \u001b[0m:      \t 'val_f1': [(1, 0.5950948914169988),\n\u001b[92mINFO \u001b[0m:      \t            (2, 0.6266108573645094),\n\u001b[92mINFO \u001b[0m:      \t            (3, 0.6488110363597106),\n\u001b[92mINFO \u001b[0m:      \t            (4, 0.6820459358518874),\n\u001b[92mINFO \u001b[0m:      \t            (5, 0.7075811166787557),\n\u001b[92mINFO \u001b[0m:      \t            (6, 0.7289100263577999),\n\u001b[92mINFO \u001b[0m:      \t            (7, 0.7510805226125109),\n\u001b[92mINFO \u001b[0m:      \t            (8, 0.7783450545408787),\n\u001b[92mINFO \u001b[0m:      \t            (9, 0.7911317986713473),\n\u001b[92mINFO \u001b[0m:      \t            (10, 0.8192693996944779)],\n\u001b[92mINFO \u001b[0m:      \t 'val_loss': [(1, 0.6638506806156953),\n\u001b[92mINFO \u001b[0m:      \t              (2, 0.6482905142133987),\n\u001b[92mINFO \u001b[0m:      \t              (3, 0.6351017388885217),\n\u001b[92mINFO \u001b[0m:      \t              (4, 0.6148267088362817),\n\u001b[92mINFO \u001b[0m:      \t              (5, 0.6012655865037105),\n\u001b[92mINFO \u001b[0m:      \t              (6, 0.5797211717538698),\n\u001b[92mINFO \u001b[0m:      \t              (7, 0.5595616697759844),\n\u001b[92mINFO \u001b[0m:      \t              (8, 0.536619291325246),\n\u001b[92mINFO \u001b[0m:      \t              (9, 0.5168221042832724),\n\u001b[92mINFO \u001b[0m:      \t              (10, 0.4922794470230789)],\n\u001b[92mINFO \u001b[0m:      \t 'val_precision': [(1, 0.5950948914169988),\n\u001b[92mINFO \u001b[0m:      \t                   (2, 0.6266108573645094),\n\u001b[92mINFO \u001b[0m:      \t                   (3, 0.6488110363597106),\n\u001b[92mINFO \u001b[0m:      \t                   (4, 0.6820459358518874),\n\u001b[92mINFO \u001b[0m:      \t                   (5, 0.7075811166787557),\n\u001b[92mINFO \u001b[0m:      \t                   (6, 0.7289100263577999),\n\u001b[92mINFO \u001b[0m:      \t                   (7, 0.7510805226125109),\n\u001b[92mINFO \u001b[0m:      \t                   (8, 0.7783450545408787),\n\u001b[92mINFO \u001b[0m:      \t                   (9, 0.7911317986713473),\n\u001b[92mINFO \u001b[0m:      \t                   (10, 0.8192693996944779)],\n\u001b[92mINFO \u001b[0m:      \t 'val_recall': [(1, 0.5950948914169988),\n\u001b[92mINFO \u001b[0m:      \t                (2, 0.6266108573645094),\n\u001b[92mINFO \u001b[0m:      \t                (3, 0.6488110363597106),\n\u001b[92mINFO \u001b[0m:      \t                (4, 0.6820459358518874),\n\u001b[92mINFO \u001b[0m:      \t                (5, 0.7075811166787557),\n\u001b[92mINFO \u001b[0m:      \t                (6, 0.7289100263577999),\n\u001b[92mINFO \u001b[0m:      \t                (7, 0.7510805226125109),\n\u001b[92mINFO \u001b[0m:      \t                (8, 0.7783450545408787),\n\u001b[92mINFO \u001b[0m:      \t                (9, 0.7911317986713473),\n\u001b[92mINFO \u001b[0m:      \t                (10, 0.8192693996944779)]}\n\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n\u001b[92mINFO \u001b[0m:      \t{'test_accuracy': [(1, 0.5745950595802053),\n\u001b[92mINFO \u001b[0m:      \t                   (2, 0.5959079376368673),\n\u001b[92mINFO \u001b[0m:      \t                   (3, 0.6018755375983261),\n\u001b[92mINFO \u001b[0m:      \t                   (4, 0.6138107516983078),\n\u001b[92mINFO \u001b[0m:      \t                   (5, 0.6632566127834011),\n\u001b[92mINFO \u001b[0m:      \t                   (6, 0.7075873747506105),\n\u001b[92mINFO \u001b[0m:      \t                   (7, 0.7280477415468585),\n\u001b[92mINFO \u001b[0m:      \t                   (8, 0.7715260072945532),\n\u001b[92mINFO \u001b[0m:      \t                   (9, 0.7860187686922605),\n\u001b[92mINFO \u001b[0m:      \t                   (10, 0.8226768916626822)],\n\u001b[92mINFO \u001b[0m:      \t 'test_f1': [(1, 0.5745950595802053),\n\u001b[92mINFO \u001b[0m:      \t             (2, 0.5959079376368673),\n\u001b[92mINFO \u001b[0m:      \t             (3, 0.6018755375983261),\n\u001b[92mINFO \u001b[0m:      \t             (4, 0.6138107516983078),\n\u001b[92mINFO \u001b[0m:      \t             (5, 0.6632566127834011),\n\u001b[92mINFO \u001b[0m:      \t             (6, 0.7075873747506105),\n\u001b[92mINFO \u001b[0m:      \t             (7, 0.7280477415468585),\n\u001b[92mINFO \u001b[0m:      \t             (8, 0.7715260072945532),\n\u001b[92mINFO \u001b[0m:      \t             (9, 0.7860187686922605),\n\u001b[92mINFO \u001b[0m:      \t             (10, 0.8226768916626822)],\n\u001b[92mINFO \u001b[0m:      \t 'test_loss': [(1, 0.6735665339846338),\n\u001b[92mINFO \u001b[0m:      \t               (2, 0.6602253396086274),\n\u001b[92mINFO \u001b[0m:      \t               (3, 0.6506723929752373),\n\u001b[92mINFO \u001b[0m:      \t               (4, 0.6435601292567078),\n\u001b[92mINFO \u001b[0m:      \t               (5, 0.625996288486962),\n\u001b[92mINFO \u001b[0m:      \t               (6, 0.5983696473224084),\n\u001b[92mINFO \u001b[0m:      \t               (7, 0.5722826218259507),\n\u001b[92mINFO \u001b[0m:      \t               (8, 0.5484245953047672),\n\u001b[92mINFO \u001b[0m:      \t               (9, 0.532280720840228),\n\u001b[92mINFO \u001b[0m:      \t               (10, 0.5023106954490031)],\n\u001b[92mINFO \u001b[0m:      \t 'test_precision': [(1, 0.5745950595802053),\n\u001b[92mINFO \u001b[0m:      \t                    (2, 0.5959079376368673),\n\u001b[92mINFO \u001b[0m:      \t                    (3, 0.6018755375983261),\n\u001b[92mINFO \u001b[0m:      \t                    (4, 0.6138107516983078),\n\u001b[92mINFO \u001b[0m:      \t                    (5, 0.6632566127834011),\n\u001b[92mINFO \u001b[0m:      \t                    (6, 0.7075873747506105),\n\u001b[92mINFO \u001b[0m:      \t                    (7, 0.7280477415468585),\n\u001b[92mINFO \u001b[0m:      \t                    (8, 0.7715260072945532),\n\u001b[92mINFO \u001b[0m:      \t                    (9, 0.7860187686922605),\n\u001b[92mINFO \u001b[0m:      \t                    (10, 0.8226768916626822)],\n\u001b[92mINFO \u001b[0m:      \t 'test_recall': [(1, 0.5745950595802053),\n\u001b[92mINFO \u001b[0m:      \t                 (2, 0.5959079376368673),\n\u001b[92mINFO \u001b[0m:      \t                 (3, 0.6018755375983261),\n\u001b[92mINFO \u001b[0m:      \t                 (4, 0.6138107516983078),\n\u001b[92mINFO \u001b[0m:      \t                 (5, 0.6632566127834011),\n\u001b[92mINFO \u001b[0m:      \t                 (6, 0.7075873747506105),\n\u001b[92mINFO \u001b[0m:      \t                 (7, 0.7280477415468585),\n\u001b[92mINFO \u001b[0m:      \t                 (8, 0.7715260072945532),\n\u001b[92mINFO \u001b[0m:      \t                 (9, 0.7860187686922605),\n\u001b[92mINFO \u001b[0m:      \t                 (10, 0.8226768916626822)]}\n\u001b[92mINFO \u001b[0m:      \n","output_type":"stream"},{"name":"stdout","text":"Round 10 evaluation metrics: {'test_loss': 0.5023106954490031, 'test_accuracy': 0.8226768916626822, 'test_f1': 0.8226768916626822, 'test_precision': 0.8226768916626822, 'test_recall': 0.8226768916626822}\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=460)\u001b[0m \u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: GPU available: True (cuda), used: True\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: TPU available: False, using: 0 TPU cores\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: HPU available: False, using: 0 HPUs\n\u001b[36m(ClientAppActor pid=460)\u001b[0m INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\u001b[36m(ClientAppActor pid=459)\u001b[0m \u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n","output_type":"stream"},{"name":"stdout","text":"Result is {'rounds': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'train_accuracy': [0.5397329902871227, 0.5920745988952126, 0.618139439542103, 0.6425090095935724, 0.6662428354681434, 0.695698235140536, 0.7143462560873564, 0.7387158244968244, 0.7660521288296004, 0.7808857814415352], 'train_loss': [0.6954506263689461, 0.6649422445118389, 0.6493892251093728, 0.6334784268120331, 0.6138293668864566, 0.5914670087367101, 0.57215770026288, 0.5540827075968761, 0.5296107274315371, 0.5095909397514676], 'test_accuracy': [0.5745950595802053, 0.5959079376368673, 0.6018755375983261, 0.6138107516983078, 0.6632566127834011, 0.7075873747506105, 0.7280477415468585, 0.7715260072945532, 0.7860187686922605, 0.8226768916626822], 'test_loss': [0.6735665339846338, 0.6602253396086274, 0.6506723929752373, 0.6435601292567078, 0.625996288486962, 0.5983696473224084, 0.5722826218259507, 0.5484245953047672, 0.532280720840228, 0.5023106954490031], 'test_f1': [0.5745950595802053, 0.5959079376368673, 0.6018755375983261, 0.6138107516983078, 0.6632566127834011, 0.7075873747506105, 0.7280477415468585, 0.7715260072945532, 0.7860187686922605, 0.8226768916626822], 'test_precision': [0.5745950595802053, 0.5959079376368673, 0.6018755375983261, 0.6138107516983078, 0.6632566127834011, 0.7075873747506105, 0.7280477415468585, 0.7715260072945532, 0.7860187686922605, 0.8226768916626822], 'test_recall': [0.5745950595802053, 0.5959079376368673, 0.6018755375983261, 0.6138107516983078, 0.6632566127834011, 0.7075873747506105, 0.7280477415468585, 0.7715260072945532, 0.7860187686922605, 0.8226768916626822]}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_dropout_history</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>server_round_eval</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test_accuracy</td><td>▁▂▂▂▄▅▅▇▇█</td></tr><tr><td>test_f1</td><td>▁▂▂▂▄▅▅▇▇█</td></tr><tr><td>test_loss</td><td>█▇▇▇▆▅▄▃▂▁</td></tr><tr><td>test_precision</td><td>▁▂▂▂▄▅▅▇▇█</td></tr><tr><td>test_recall</td><td>▁▂▂▂▄▅▅▇▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▃▄▅▆▆▇██</td></tr><tr><td>train_dropout_history</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train_server_round</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_dropout_history</td><td>0</td></tr><tr><td>server_round_eval</td><td>10</td></tr><tr><td>test_accuracy</td><td>0.82268</td></tr><tr><td>test_f1</td><td>0.82268</td></tr><tr><td>test_loss</td><td>0.50231</td></tr><tr><td>test_precision</td><td>0.82268</td></tr><tr><td>test_recall</td><td>0.82268</td></tr><tr><td>train_accuracy</td><td>0.78089</td></tr><tr><td>train_dropout_history</td><td>0</td></tr><tr><td>train_loss</td><td>0.50959</td></tr><tr><td>train_server_round</td><td>10</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dropout_0.0_2D_FedAR</strong> at: <a href='https://wandb.ai/sang2222004-uet-vnu/federated-mri-server/runs/vbea5c2y' target=\"_blank\">https://wandb.ai/sang2222004-uet-vnu/federated-mri-server/runs/vbea5c2y</a><br> View project at: <a href='https://wandb.ai/sang2222004-uet-vnu/federated-mri-server' target=\"_blank\">https://wandb.ai/sang2222004-uet-vnu/federated-mri-server</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250603_090616-vbea5c2y/logs</code>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"({'rounds': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n  'train_accuracy': [0.5397329902871227,\n   0.5920745988952126,\n   0.618139439542103,\n   0.6425090095935724,\n   0.6662428354681434,\n   0.695698235140536,\n   0.7143462560873564,\n   0.7387158244968244,\n   0.7660521288296004,\n   0.7808857814415352],\n  'train_loss': [0.6954506263689461,\n   0.6649422445118389,\n   0.6493892251093728,\n   0.6334784268120331,\n   0.6138293668864566,\n   0.5914670087367101,\n   0.57215770026288,\n   0.5540827075968761,\n   0.5296107274315371,\n   0.5095909397514676],\n  'test_accuracy': [0.5745950595802053,\n   0.5959079376368673,\n   0.6018755375983261,\n   0.6138107516983078,\n   0.6632566127834011,\n   0.7075873747506105,\n   0.7280477415468585,\n   0.7715260072945532,\n   0.7860187686922605,\n   0.8226768916626822],\n  'test_loss': [0.6735665339846338,\n   0.6602253396086274,\n   0.6506723929752373,\n   0.6435601292567078,\n   0.625996288486962,\n   0.5983696473224084,\n   0.5722826218259507,\n   0.5484245953047672,\n   0.532280720840228,\n   0.5023106954490031],\n  'test_f1': [0.5745950595802053,\n   0.5959079376368673,\n   0.6018755375983261,\n   0.6138107516983078,\n   0.6632566127834011,\n   0.7075873747506105,\n   0.7280477415468585,\n   0.7715260072945532,\n   0.7860187686922605,\n   0.8226768916626822],\n  'test_precision': [0.5745950595802053,\n   0.5959079376368673,\n   0.6018755375983261,\n   0.6138107516983078,\n   0.6632566127834011,\n   0.7075873747506105,\n   0.7280477415468585,\n   0.7715260072945532,\n   0.7860187686922605,\n   0.8226768916626822],\n  'test_recall': [0.5745950595802053,\n   0.5959079376368673,\n   0.6018755375983261,\n   0.6138107516983078,\n   0.6632566127834011,\n   0.7075873747506105,\n   0.7280477415468585,\n   0.7715260072945532,\n   0.7860187686922605,\n   0.8226768916626822]},\n ({1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: []},\n  {1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: []}))"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}